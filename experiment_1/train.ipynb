{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "**Modification:**\n",
    "- Use Bidirectional LSTM \n",
    "\n",
    "```l1 = Bidirectional(LSTM(100, consume_less='gpu', init='glorot_uniform', return_sequences=True, dropout_W=0.2))(main_input)```\n",
    "\n",
    "- Change from target_chars to targetchartoindice (same len but target_chars not exist) \n",
    "\n",
    "```act_output = Dense(len(targetchartoindice), activation='softmax', init='glorot_uniform', name='act_output')(b2_1)```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "# Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import argparse\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using Theano backend.\n"
     ]
    }
   ],
   "source": [
    "from keras.models import Sequential, Model\n",
    "from keras.layers.core import Dense\n",
    "from keras.layers.recurrent import LSTM, GRU, SimpleRNN\n",
    "from keras.layers import Input, merge\n",
    "from keras.layers.wrappers import Bidirectional\n",
    "from keras.utils.data_utils import get_file\n",
    "#from keras.regularizers import WeightRegularizer\n",
    "from keras import optimizers\n",
    "from keras.callbacks import EarlyStopping, ModelCheckpoint, ReduceLROnPlateau\n",
    "from keras.layers.normalization import BatchNormalization\n",
    "from theano.ifelse import ifelse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "name = 'helpdesk'\n",
    "args = {\n",
    "    'inputdir': '../input/{}/'.format(name),   \n",
    "    'outputdir': './output_files/{}/'.format(name)\n",
    "}\n",
    "\n",
    "args = argparse.Namespace(**args)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "if not os.path.isdir(args.outputdir):\n",
    "    os.makedirs(args.outputdir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "with open(args.inputdir + 'parameters.pkl', \"rb\") as f:\n",
    "    maxlen = pickle.load(f)\n",
    "    num_features = pickle.load(f)\n",
    "    chartoindice = pickle.load(f)\n",
    "    targetchartoindice = pickle.load(f)\n",
    "    divisor = pickle.load(f)\n",
    "    divisor2 = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "with open(args.inputdir + 'preprocessed_data.pkl', \"rb\") as f:\n",
    "    X = pickle.load(f)\n",
    "    y_a = pickle.load(f)\n",
    "    y_t = pickle.load(f)\n",
    "    X_test = pickle.load(f)\n",
    "    y_a_test = pickle.load(f)\n",
    "    y_t_test = pickle.load(f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "# Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Build model BLSTM...\n",
      "Train on 7344 samples, validate on 1837 samples\n",
      "Epoch 1/500\n",
      "21s - loss: 2.0070 - act_output_loss: 0.7981 - time_output_loss: 1.2089 - val_loss: 1.6749 - val_act_output_loss: 0.6253 - val_time_output_loss: 1.0496\n",
      "Epoch 2/500\n",
      "22s - loss: 1.6433 - act_output_loss: 0.6108 - time_output_loss: 1.0325 - val_loss: 1.5531 - val_act_output_loss: 0.5734 - val_time_output_loss: 0.9797\n",
      "Epoch 3/500\n",
      "22s - loss: 1.6073 - act_output_loss: 0.5981 - time_output_loss: 1.0092 - val_loss: 1.5958 - val_act_output_loss: 0.6015 - val_time_output_loss: 0.9942\n",
      "Epoch 4/500\n",
      "21s - loss: 1.5915 - act_output_loss: 0.5891 - time_output_loss: 1.0024 - val_loss: 1.5700 - val_act_output_loss: 0.5977 - val_time_output_loss: 0.9722\n",
      "Epoch 5/500\n",
      "22s - loss: 1.5888 - act_output_loss: 0.5904 - time_output_loss: 0.9983 - val_loss: 1.5370 - val_act_output_loss: 0.5666 - val_time_output_loss: 0.9704\n",
      "Epoch 6/500\n",
      "22s - loss: 1.5887 - act_output_loss: 0.5944 - time_output_loss: 0.9944 - val_loss: 1.6063 - val_act_output_loss: 0.6044 - val_time_output_loss: 1.0019\n",
      "Epoch 7/500\n",
      "25s - loss: 1.5724 - act_output_loss: 0.5795 - time_output_loss: 0.9928 - val_loss: 1.6193 - val_act_output_loss: 0.6367 - val_time_output_loss: 0.9825\n",
      "Epoch 8/500\n",
      "29s - loss: 1.5825 - act_output_loss: 0.5842 - time_output_loss: 0.9983 - val_loss: 1.5338 - val_act_output_loss: 0.5741 - val_time_output_loss: 0.9597\n",
      "Epoch 9/500\n",
      "22s - loss: 1.5752 - act_output_loss: 0.5777 - time_output_loss: 0.9976 - val_loss: 1.5749 - val_act_output_loss: 0.6034 - val_time_output_loss: 0.9715\n",
      "Epoch 10/500\n",
      "23s - loss: 1.5857 - act_output_loss: 0.5878 - time_output_loss: 0.9978 - val_loss: 1.5244 - val_act_output_loss: 0.5718 - val_time_output_loss: 0.9526\n",
      "Epoch 11/500\n",
      "22s - loss: 1.5741 - act_output_loss: 0.5839 - time_output_loss: 0.9902 - val_loss: 1.5392 - val_act_output_loss: 0.5714 - val_time_output_loss: 0.9678\n",
      "Epoch 12/500\n",
      "23s - loss: 1.5622 - act_output_loss: 0.5750 - time_output_loss: 0.9872 - val_loss: 1.5133 - val_act_output_loss: 0.5542 - val_time_output_loss: 0.9591\n",
      "Epoch 13/500\n",
      "23s - loss: 1.5688 - act_output_loss: 0.5798 - time_output_loss: 0.9890 - val_loss: 1.5338 - val_act_output_loss: 0.5719 - val_time_output_loss: 0.9619\n",
      "Epoch 14/500\n",
      "22s - loss: 1.5645 - act_output_loss: 0.5763 - time_output_loss: 0.9882 - val_loss: 1.5195 - val_act_output_loss: 0.5542 - val_time_output_loss: 0.9652\n",
      "Epoch 15/500\n",
      "22s - loss: 1.5623 - act_output_loss: 0.5768 - time_output_loss: 0.9855 - val_loss: 1.5342 - val_act_output_loss: 0.5767 - val_time_output_loss: 0.9576\n",
      "Epoch 16/500\n",
      "22s - loss: 1.5606 - act_output_loss: 0.5758 - time_output_loss: 0.9847 - val_loss: 1.5192 - val_act_output_loss: 0.5639 - val_time_output_loss: 0.9554\n",
      "Epoch 17/500\n",
      "22s - loss: 1.5588 - act_output_loss: 0.5711 - time_output_loss: 0.9877 - val_loss: 1.5118 - val_act_output_loss: 0.5609 - val_time_output_loss: 0.9509\n",
      "Epoch 18/500\n",
      "23s - loss: 1.5652 - act_output_loss: 0.5739 - time_output_loss: 0.9914 - val_loss: 1.5127 - val_act_output_loss: 0.5631 - val_time_output_loss: 0.9496\n",
      "Epoch 19/500\n",
      "22s - loss: 1.5532 - act_output_loss: 0.5683 - time_output_loss: 0.9849 - val_loss: 1.5334 - val_act_output_loss: 0.5704 - val_time_output_loss: 0.9630\n",
      "Epoch 20/500\n",
      "22s - loss: 1.5549 - act_output_loss: 0.5695 - time_output_loss: 0.9854 - val_loss: 1.5225 - val_act_output_loss: 0.5675 - val_time_output_loss: 0.9550\n",
      "Epoch 21/500\n",
      "23s - loss: 1.5498 - act_output_loss: 0.5678 - time_output_loss: 0.9820 - val_loss: 1.4992 - val_act_output_loss: 0.5525 - val_time_output_loss: 0.9467\n",
      "Epoch 22/500\n",
      "22s - loss: 1.5494 - act_output_loss: 0.5687 - time_output_loss: 0.9807 - val_loss: 1.5309 - val_act_output_loss: 0.5706 - val_time_output_loss: 0.9603\n",
      "Epoch 23/500\n",
      "21s - loss: 1.5432 - act_output_loss: 0.5630 - time_output_loss: 0.9801 - val_loss: 1.5351 - val_act_output_loss: 0.5803 - val_time_output_loss: 0.9548\n",
      "Epoch 24/500\n",
      "21s - loss: 1.5478 - act_output_loss: 0.5694 - time_output_loss: 0.9784 - val_loss: 1.5271 - val_act_output_loss: 0.5724 - val_time_output_loss: 0.9547\n",
      "Epoch 25/500\n",
      "22s - loss: 1.5498 - act_output_loss: 0.5710 - time_output_loss: 0.9788 - val_loss: 1.5053 - val_act_output_loss: 0.5562 - val_time_output_loss: 0.9491\n",
      "Epoch 26/500\n",
      "21s - loss: 1.5488 - act_output_loss: 0.5661 - time_output_loss: 0.9827 - val_loss: 1.5183 - val_act_output_loss: 0.5597 - val_time_output_loss: 0.9586\n",
      "Epoch 27/500\n",
      "21s - loss: 1.5429 - act_output_loss: 0.5601 - time_output_loss: 0.9828 - val_loss: 1.5136 - val_act_output_loss: 0.5632 - val_time_output_loss: 0.9504\n",
      "Epoch 28/500\n",
      "21s - loss: 1.5465 - act_output_loss: 0.5665 - time_output_loss: 0.9801 - val_loss: 1.5118 - val_act_output_loss: 0.5608 - val_time_output_loss: 0.9510\n",
      "Epoch 29/500\n",
      "21s - loss: 1.5388 - act_output_loss: 0.5599 - time_output_loss: 0.9789 - val_loss: 1.5022 - val_act_output_loss: 0.5560 - val_time_output_loss: 0.9462\n",
      "Epoch 30/500\n",
      "21s - loss: 1.5420 - act_output_loss: 0.5561 - time_output_loss: 0.9859 - val_loss: 1.5053 - val_act_output_loss: 0.5567 - val_time_output_loss: 0.9485\n",
      "Epoch 31/500\n",
      "22s - loss: 1.5386 - act_output_loss: 0.5609 - time_output_loss: 0.9777 - val_loss: 1.5104 - val_act_output_loss: 0.5625 - val_time_output_loss: 0.9479\n",
      "Epoch 32/500\n",
      "21s - loss: 1.5427 - act_output_loss: 0.5649 - time_output_loss: 0.9778 - val_loss: 1.5003 - val_act_output_loss: 0.5577 - val_time_output_loss: 0.9426\n",
      "Epoch 33/500\n",
      "21s - loss: 1.5411 - act_output_loss: 0.5583 - time_output_loss: 0.9828 - val_loss: 1.5000 - val_act_output_loss: 0.5533 - val_time_output_loss: 0.9467\n",
      "Epoch 34/500\n",
      "21s - loss: 1.5243 - act_output_loss: 0.5504 - time_output_loss: 0.9739 - val_loss: 1.5092 - val_act_output_loss: 0.5608 - val_time_output_loss: 0.9484\n",
      "Epoch 35/500\n",
      "23s - loss: 1.5208 - act_output_loss: 0.5475 - time_output_loss: 0.9733 - val_loss: 1.5034 - val_act_output_loss: 0.5562 - val_time_output_loss: 0.9472\n",
      "Epoch 36/500\n",
      "27s - loss: 1.5238 - act_output_loss: 0.5492 - time_output_loss: 0.9745 - val_loss: 1.5049 - val_act_output_loss: 0.5577 - val_time_output_loss: 0.9472\n",
      "Epoch 37/500\n",
      "22s - loss: 1.5298 - act_output_loss: 0.5522 - time_output_loss: 0.9776 - val_loss: 1.5006 - val_act_output_loss: 0.5519 - val_time_output_loss: 0.9488\n",
      "Epoch 38/500\n",
      "22s - loss: 1.5148 - act_output_loss: 0.5419 - time_output_loss: 0.9729 - val_loss: 1.5111 - val_act_output_loss: 0.5605 - val_time_output_loss: 0.9506\n",
      "Epoch 39/500\n",
      "23s - loss: 1.5173 - act_output_loss: 0.5433 - time_output_loss: 0.9740 - val_loss: 1.5114 - val_act_output_loss: 0.5664 - val_time_output_loss: 0.9450\n",
      "Epoch 40/500\n",
      "22s - loss: 1.5190 - act_output_loss: 0.5442 - time_output_loss: 0.9748 - val_loss: 1.5041 - val_act_output_loss: 0.5608 - val_time_output_loss: 0.9433\n",
      "Epoch 41/500\n",
      "22s - loss: 1.5208 - act_output_loss: 0.5454 - time_output_loss: 0.9754 - val_loss: 1.5008 - val_act_output_loss: 0.5585 - val_time_output_loss: 0.9423\n",
      "Epoch 42/500\n",
      "22s - loss: 1.5175 - act_output_loss: 0.5454 - time_output_loss: 0.9721 - val_loss: 1.5050 - val_act_output_loss: 0.5643 - val_time_output_loss: 0.9407\n",
      "Epoch 43/500\n",
      "22s - loss: 1.5117 - act_output_loss: 0.5389 - time_output_loss: 0.9729 - val_loss: 1.5015 - val_act_output_loss: 0.5588 - val_time_output_loss: 0.9427\n",
      "Epoch 44/500\n",
      "22s - loss: 1.5095 - act_output_loss: 0.5389 - time_output_loss: 0.9707 - val_loss: 1.4995 - val_act_output_loss: 0.5592 - val_time_output_loss: 0.9403\n",
      "Epoch 45/500\n",
      "22s - loss: 1.5099 - act_output_loss: 0.5397 - time_output_loss: 0.9702 - val_loss: 1.4976 - val_act_output_loss: 0.5589 - val_time_output_loss: 0.9387\n",
      "Epoch 46/500\n",
      "22s - loss: 1.5079 - act_output_loss: 0.5353 - time_output_loss: 0.9727 - val_loss: 1.5039 - val_act_output_loss: 0.5626 - val_time_output_loss: 0.9414\n",
      "Epoch 47/500\n",
      "22s - loss: 1.5004 - act_output_loss: 0.5349 - time_output_loss: 0.9655 - val_loss: 1.5054 - val_act_output_loss: 0.5625 - val_time_output_loss: 0.9429\n",
      "Epoch 48/500\n",
      "22s - loss: 1.5037 - act_output_loss: 0.5331 - time_output_loss: 0.9706 - val_loss: 1.5086 - val_act_output_loss: 0.5650 - val_time_output_loss: 0.9436\n",
      "Epoch 49/500\n",
      "21s - loss: 1.5070 - act_output_loss: 0.5398 - time_output_loss: 0.9672 - val_loss: 1.5060 - val_act_output_loss: 0.5660 - val_time_output_loss: 0.9401\n",
      "Epoch 50/500\n",
      "22s - loss: 1.5051 - act_output_loss: 0.5326 - time_output_loss: 0.9724 - val_loss: 1.5059 - val_act_output_loss: 0.5644 - val_time_output_loss: 0.9414\n",
      "Epoch 51/500\n",
      "22s - loss: 1.4979 - act_output_loss: 0.5292 - time_output_loss: 0.9687 - val_loss: 1.5131 - val_act_output_loss: 0.5709 - val_time_output_loss: 0.9423\n",
      "Epoch 52/500\n",
      "23s - loss: 1.5018 - act_output_loss: 0.5343 - time_output_loss: 0.9675 - val_loss: 1.5057 - val_act_output_loss: 0.5670 - val_time_output_loss: 0.9387\n",
      "Epoch 53/500\n",
      "22s - loss: 1.4988 - act_output_loss: 0.5319 - time_output_loss: 0.9669 - val_loss: 1.5042 - val_act_output_loss: 0.5637 - val_time_output_loss: 0.9406\n",
      "Epoch 54/500\n",
      "22s - loss: 1.4925 - act_output_loss: 0.5227 - time_output_loss: 0.9698 - val_loss: 1.5093 - val_act_output_loss: 0.5694 - val_time_output_loss: 0.9399\n",
      "Epoch 55/500\n",
      "21s - loss: 1.4980 - act_output_loss: 0.5281 - time_output_loss: 0.9700 - val_loss: 1.5066 - val_act_output_loss: 0.5653 - val_time_output_loss: 0.9412\n",
      "Epoch 56/500\n",
      "27s - loss: 1.4987 - act_output_loss: 0.5297 - time_output_loss: 0.9690 - val_loss: 1.5195 - val_act_output_loss: 0.5733 - val_time_output_loss: 0.9462\n",
      "Epoch 57/500\n",
      "22s - loss: 1.4918 - act_output_loss: 0.5268 - time_output_loss: 0.9650 - val_loss: 1.5115 - val_act_output_loss: 0.5701 - val_time_output_loss: 0.9414\n",
      "Epoch 58/500\n",
      "21s - loss: 1.4928 - act_output_loss: 0.5241 - time_output_loss: 0.9687 - val_loss: 1.5125 - val_act_output_loss: 0.5699 - val_time_output_loss: 0.9426\n",
      "Epoch 59/500\n",
      "21s - loss: 1.4958 - act_output_loss: 0.5273 - time_output_loss: 0.9685 - val_loss: 1.5112 - val_act_output_loss: 0.5691 - val_time_output_loss: 0.9422\n",
      "Epoch 60/500\n",
      "21s - loss: 1.4957 - act_output_loss: 0.5290 - time_output_loss: 0.9668 - val_loss: 1.5117 - val_act_output_loss: 0.5687 - val_time_output_loss: 0.9431\n",
      "Epoch 61/500\n",
      "21s - loss: 1.4865 - act_output_loss: 0.5234 - time_output_loss: 0.9631 - val_loss: 1.5090 - val_act_output_loss: 0.5686 - val_time_output_loss: 0.9404\n",
      "Epoch 62/500\n",
      "21s - loss: 1.4867 - act_output_loss: 0.5245 - time_output_loss: 0.9622 - val_loss: 1.5129 - val_act_output_loss: 0.5710 - val_time_output_loss: 0.9419\n",
      "Epoch 63/500\n",
      "22s - loss: 1.4904 - act_output_loss: 0.5246 - time_output_loss: 0.9659 - val_loss: 1.5127 - val_act_output_loss: 0.5709 - val_time_output_loss: 0.9418\n",
      "Epoch 64/500\n",
      "21s - loss: 1.4876 - act_output_loss: 0.5210 - time_output_loss: 0.9667 - val_loss: 1.5122 - val_act_output_loss: 0.5713 - val_time_output_loss: 0.9409\n",
      "Epoch 65/500\n",
      "21s - loss: 1.4945 - act_output_loss: 0.5222 - time_output_loss: 0.9723 - val_loss: 1.5111 - val_act_output_loss: 0.5693 - val_time_output_loss: 0.9418\n",
      "Epoch 66/500\n",
      "23s - loss: 1.4957 - act_output_loss: 0.5276 - time_output_loss: 0.9681 - val_loss: 1.5119 - val_act_output_loss: 0.5698 - val_time_output_loss: 0.9421\n",
      "Epoch 67/500\n",
      "21s - loss: 1.4789 - act_output_loss: 0.5177 - time_output_loss: 0.9612 - val_loss: 1.5102 - val_act_output_loss: 0.5695 - val_time_output_loss: 0.9406\n",
      "Epoch 68/500\n",
      "21s - loss: 1.4818 - act_output_loss: 0.5195 - time_output_loss: 0.9623 - val_loss: 1.5108 - val_act_output_loss: 0.5701 - val_time_output_loss: 0.9407\n",
      "Epoch 69/500\n",
      "21s - loss: 1.4839 - act_output_loss: 0.5200 - time_output_loss: 0.9639 - val_loss: 1.5142 - val_act_output_loss: 0.5714 - val_time_output_loss: 0.9428\n",
      "Epoch 70/500\n",
      "21s - loss: 1.4821 - act_output_loss: 0.5180 - time_output_loss: 0.9641 - val_loss: 1.5120 - val_act_output_loss: 0.5700 - val_time_output_loss: 0.9420\n",
      "Epoch 71/500\n",
      "21s - loss: 1.4876 - act_output_loss: 0.5213 - time_output_loss: 0.9663 - val_loss: 1.5114 - val_act_output_loss: 0.5695 - val_time_output_loss: 0.9419\n",
      "Epoch 72/500\n",
      "21s - loss: 1.4797 - act_output_loss: 0.5180 - time_output_loss: 0.9616 - val_loss: 1.5106 - val_act_output_loss: 0.5705 - val_time_output_loss: 0.9401\n",
      "Epoch 73/500\n",
      "21s - loss: 1.4828 - act_output_loss: 0.5192 - time_output_loss: 0.9637 - val_loss: 1.5119 - val_act_output_loss: 0.5716 - val_time_output_loss: 0.9403\n",
      "Epoch 74/500\n",
      "21s - loss: 1.4763 - act_output_loss: 0.5163 - time_output_loss: 0.9600 - val_loss: 1.5113 - val_act_output_loss: 0.5710 - val_time_output_loss: 0.9402\n",
      "Epoch 75/500\n",
      "21s - loss: 1.4904 - act_output_loss: 0.5204 - time_output_loss: 0.9700 - val_loss: 1.5150 - val_act_output_loss: 0.5724 - val_time_output_loss: 0.9426\n",
      "Epoch 76/500\n",
      "24s - loss: 1.4823 - act_output_loss: 0.5176 - time_output_loss: 0.9647 - val_loss: 1.5143 - val_act_output_loss: 0.5730 - val_time_output_loss: 0.9413\n",
      "Epoch 77/500\n",
      "23s - loss: 1.4858 - act_output_loss: 0.5193 - time_output_loss: 0.9665 - val_loss: 1.5161 - val_act_output_loss: 0.5727 - val_time_output_loss: 0.9433\n",
      "Epoch 78/500\n",
      "21s - loss: 1.4828 - act_output_loss: 0.5166 - time_output_loss: 0.9662 - val_loss: 1.5160 - val_act_output_loss: 0.5738 - val_time_output_loss: 0.9422\n",
      "Epoch 79/500\n",
      "22s - loss: 1.4838 - act_output_loss: 0.5174 - time_output_loss: 0.9664 - val_loss: 1.5151 - val_act_output_loss: 0.5741 - val_time_output_loss: 0.9410\n",
      "Epoch 80/500\n",
      "22s - loss: 1.4834 - act_output_loss: 0.5207 - time_output_loss: 0.9627 - val_loss: 1.5139 - val_act_output_loss: 0.5737 - val_time_output_loss: 0.9402\n",
      "Epoch 81/500\n",
      "30s - loss: 1.4810 - act_output_loss: 0.5137 - time_output_loss: 0.9673 - val_loss: 1.5154 - val_act_output_loss: 0.5739 - val_time_output_loss: 0.9415\n",
      "Epoch 82/500\n",
      "33s - loss: 1.4857 - act_output_loss: 0.5172 - time_output_loss: 0.9685 - val_loss: 1.5156 - val_act_output_loss: 0.5737 - val_time_output_loss: 0.9419\n",
      "Epoch 83/500\n",
      "34s - loss: 1.4842 - act_output_loss: 0.5175 - time_output_loss: 0.9668 - val_loss: 1.5157 - val_act_output_loss: 0.5744 - val_time_output_loss: 0.9413\n",
      "Epoch 84/500\n",
      "34s - loss: 1.4811 - act_output_loss: 0.5155 - time_output_loss: 0.9656 - val_loss: 1.5164 - val_act_output_loss: 0.5741 - val_time_output_loss: 0.9423\n",
      "Epoch 85/500\n",
      "31s - loss: 1.4818 - act_output_loss: 0.5175 - time_output_loss: 0.9643 - val_loss: 1.5156 - val_act_output_loss: 0.5743 - val_time_output_loss: 0.9413\n",
      "Epoch 86/500\n",
      "21s - loss: 1.4820 - act_output_loss: 0.5136 - time_output_loss: 0.9684 - val_loss: 1.5156 - val_act_output_loss: 0.5749 - val_time_output_loss: 0.9407\n",
      "Epoch 87/500\n",
      "21s - loss: 1.4823 - act_output_loss: 0.5165 - time_output_loss: 0.9659 - val_loss: 1.5166 - val_act_output_loss: 0.5751 - val_time_output_loss: 0.9415\n",
      "Epoch 88/500\n",
      "22s - loss: 1.4750 - act_output_loss: 0.5134 - time_output_loss: 0.9616 - val_loss: 1.5159 - val_act_output_loss: 0.5751 - val_time_output_loss: 0.9407\n",
      "Epoch 89/500\n",
      "21s - loss: 1.4741 - act_output_loss: 0.5134 - time_output_loss: 0.9607 - val_loss: 1.5148 - val_act_output_loss: 0.5750 - val_time_output_loss: 0.9398\n",
      "Epoch 90/500\n",
      "22s - loss: 1.4841 - act_output_loss: 0.5167 - time_output_loss: 0.9674 - val_loss: 1.5151 - val_act_output_loss: 0.5747 - val_time_output_loss: 0.9405\n",
      "Epoch 91/500\n",
      "21s - loss: 1.4777 - act_output_loss: 0.5146 - time_output_loss: 0.9631 - val_loss: 1.5153 - val_act_output_loss: 0.5752 - val_time_output_loss: 0.9402\n",
      "Epoch 92/500\n",
      "21s - loss: 1.4818 - act_output_loss: 0.5144 - time_output_loss: 0.9675 - val_loss: 1.5158 - val_act_output_loss: 0.5751 - val_time_output_loss: 0.9408\n",
      "Epoch 93/500\n",
      "22s - loss: 1.4803 - act_output_loss: 0.5148 - time_output_loss: 0.9655 - val_loss: 1.5150 - val_act_output_loss: 0.5752 - val_time_output_loss: 0.9398\n",
      "Epoch 94/500\n",
      "21s - loss: 1.4775 - act_output_loss: 0.5153 - time_output_loss: 0.9622 - val_loss: 1.5150 - val_act_output_loss: 0.5758 - val_time_output_loss: 0.9392\n",
      "Epoch 95/500\n",
      "21s - loss: 1.4769 - act_output_loss: 0.5132 - time_output_loss: 0.9637 - val_loss: 1.5163 - val_act_output_loss: 0.5752 - val_time_output_loss: 0.9411\n",
      "Epoch 96/500\n",
      "22s - loss: 1.4813 - act_output_loss: 0.5194 - time_output_loss: 0.9620 - val_loss: 1.5140 - val_act_output_loss: 0.5746 - val_time_output_loss: 0.9394\n",
      "Epoch 97/500\n",
      "21s - loss: 1.4782 - act_output_loss: 0.5136 - time_output_loss: 0.9647 - val_loss: 1.5148 - val_act_output_loss: 0.5752 - val_time_output_loss: 0.9396\n",
      "Epoch 98/500\n",
      "21s - loss: 1.4754 - act_output_loss: 0.5144 - time_output_loss: 0.9610 - val_loss: 1.5158 - val_act_output_loss: 0.5749 - val_time_output_loss: 0.9409\n",
      "Epoch 99/500\n",
      "23s - loss: 1.4756 - act_output_loss: 0.5121 - time_output_loss: 0.9636 - val_loss: 1.5155 - val_act_output_loss: 0.5749 - val_time_output_loss: 0.9405\n",
      "Epoch 100/500\n",
      "22s - loss: 1.4782 - act_output_loss: 0.5135 - time_output_loss: 0.9647 - val_loss: 1.5151 - val_act_output_loss: 0.5759 - val_time_output_loss: 0.9392\n",
      "Epoch 101/500\n",
      "22s - loss: 1.4747 - act_output_loss: 0.5125 - time_output_loss: 0.9622 - val_loss: 1.5150 - val_act_output_loss: 0.5756 - val_time_output_loss: 0.9395\n",
      "Epoch 102/500\n",
      "22s - loss: 1.4775 - act_output_loss: 0.5147 - time_output_loss: 0.9629 - val_loss: 1.5158 - val_act_output_loss: 0.5754 - val_time_output_loss: 0.9403\n",
      "Epoch 103/500\n",
      "21s - loss: 1.4779 - act_output_loss: 0.5148 - time_output_loss: 0.9631 - val_loss: 1.5166 - val_act_output_loss: 0.5755 - val_time_output_loss: 0.9411\n",
      "Epoch 104/500\n",
      "23s - loss: 1.4790 - act_output_loss: 0.5185 - time_output_loss: 0.9605 - val_loss: 1.5153 - val_act_output_loss: 0.5750 - val_time_output_loss: 0.9404\n",
      "Epoch 105/500\n",
      "21s - loss: 1.4794 - act_output_loss: 0.5128 - time_output_loss: 0.9666 - val_loss: 1.5153 - val_act_output_loss: 0.5750 - val_time_output_loss: 0.9404\n",
      "Epoch 106/500\n",
      "22s - loss: 1.4841 - act_output_loss: 0.5158 - time_output_loss: 0.9682 - val_loss: 1.5160 - val_act_output_loss: 0.5753 - val_time_output_loss: 0.9407\n",
      "Epoch 107/500\n",
      "21s - loss: 1.4764 - act_output_loss: 0.5132 - time_output_loss: 0.9632 - val_loss: 1.5166 - val_act_output_loss: 0.5749 - val_time_output_loss: 0.9416\n",
      "Epoch 108/500\n",
      "21s - loss: 1.4758 - act_output_loss: 0.5104 - time_output_loss: 0.9654 - val_loss: 1.5153 - val_act_output_loss: 0.5752 - val_time_output_loss: 0.9401\n",
      "Epoch 109/500\n",
      "22s - loss: 1.4805 - act_output_loss: 0.5147 - time_output_loss: 0.9658 - val_loss: 1.5146 - val_act_output_loss: 0.5751 - val_time_output_loss: 0.9395\n",
      "Epoch 110/500\n",
      "21s - loss: 1.4780 - act_output_loss: 0.5114 - time_output_loss: 0.9666 - val_loss: 1.5151 - val_act_output_loss: 0.5757 - val_time_output_loss: 0.9394\n",
      "Epoch 111/500\n",
      "21s - loss: 1.4805 - act_output_loss: 0.5193 - time_output_loss: 0.9612 - val_loss: 1.5157 - val_act_output_loss: 0.5749 - val_time_output_loss: 0.9408\n",
      "Epoch 112/500\n",
      "22s - loss: 1.4730 - act_output_loss: 0.5128 - time_output_loss: 0.9602 - val_loss: 1.5143 - val_act_output_loss: 0.5751 - val_time_output_loss: 0.9392\n",
      "Epoch 113/500\n",
      "21s - loss: 1.4792 - act_output_loss: 0.5147 - time_output_loss: 0.9645 - val_loss: 1.5176 - val_act_output_loss: 0.5747 - val_time_output_loss: 0.9428\n",
      "Epoch 114/500\n",
      "21s - loss: 1.4765 - act_output_loss: 0.5127 - time_output_loss: 0.9638 - val_loss: 1.5156 - val_act_output_loss: 0.5752 - val_time_output_loss: 0.9404\n",
      "Epoch 115/500\n",
      "22s - loss: 1.4730 - act_output_loss: 0.5096 - time_output_loss: 0.9634 - val_loss: 1.5148 - val_act_output_loss: 0.5752 - val_time_output_loss: 0.9396\n",
      "Epoch 116/500\n",
      "21s - loss: 1.4745 - act_output_loss: 0.5126 - time_output_loss: 0.9618 - val_loss: 1.5149 - val_act_output_loss: 0.5754 - val_time_output_loss: 0.9396\n",
      "Epoch 117/500\n",
      "22s - loss: 1.4812 - act_output_loss: 0.5183 - time_output_loss: 0.9629 - val_loss: 1.5162 - val_act_output_loss: 0.5751 - val_time_output_loss: 0.9412\n",
      "Epoch 118/500\n",
      "23s - loss: 1.4804 - act_output_loss: 0.5162 - time_output_loss: 0.9642 - val_loss: 1.5153 - val_act_output_loss: 0.5760 - val_time_output_loss: 0.9393\n",
      "Epoch 119/500\n",
      "22s - loss: 1.4810 - act_output_loss: 0.5154 - time_output_loss: 0.9656 - val_loss: 1.5149 - val_act_output_loss: 0.5750 - val_time_output_loss: 0.9399\n",
      "Epoch 120/500\n",
      "22s - loss: 1.4708 - act_output_loss: 0.5105 - time_output_loss: 0.9604 - val_loss: 1.5158 - val_act_output_loss: 0.5752 - val_time_output_loss: 0.9406\n",
      "Epoch 121/500\n",
      "21s - loss: 1.4826 - act_output_loss: 0.5165 - time_output_loss: 0.9661 - val_loss: 1.5153 - val_act_output_loss: 0.5758 - val_time_output_loss: 0.9395\n",
      "Epoch 122/500\n",
      "22s - loss: 1.4815 - act_output_loss: 0.5177 - time_output_loss: 0.9639 - val_loss: 1.5151 - val_act_output_loss: 0.5750 - val_time_output_loss: 0.9401\n",
      "Epoch 123/500\n",
      "21s - loss: 1.4720 - act_output_loss: 0.5106 - time_output_loss: 0.9613 - val_loss: 1.5160 - val_act_output_loss: 0.5749 - val_time_output_loss: 0.9411\n",
      "Epoch 124/500\n",
      "21s - loss: 1.4789 - act_output_loss: 0.5127 - time_output_loss: 0.9662 - val_loss: 1.5151 - val_act_output_loss: 0.5752 - val_time_output_loss: 0.9399\n",
      "Epoch 125/500\n",
      "21s - loss: 1.4762 - act_output_loss: 0.5135 - time_output_loss: 0.9627 - val_loss: 1.5145 - val_act_output_loss: 0.5754 - val_time_output_loss: 0.9391\n",
      "Epoch 126/500\n",
      "25s - loss: 1.4680 - act_output_loss: 0.5070 - time_output_loss: 0.9610 - val_loss: 1.5148 - val_act_output_loss: 0.5756 - val_time_output_loss: 0.9392\n",
      "Epoch 127/500\n",
      "21s - loss: 1.4743 - act_output_loss: 0.5109 - time_output_loss: 0.9634 - val_loss: 1.5146 - val_act_output_loss: 0.5751 - val_time_output_loss: 0.9396\n",
      "Epoch 128/500\n",
      "21s - loss: 1.4788 - act_output_loss: 0.5152 - time_output_loss: 0.9637 - val_loss: 1.5147 - val_act_output_loss: 0.5749 - val_time_output_loss: 0.9397\n",
      "Epoch 129/500\n",
      "22s - loss: 1.4733 - act_output_loss: 0.5113 - time_output_loss: 0.9621 - val_loss: 1.5146 - val_act_output_loss: 0.5746 - val_time_output_loss: 0.9400\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7ff11cadee10>"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print('Build model BLSTM...')\n",
    "\n",
    "main_input = Input(shape=(maxlen, num_features), name='main_input')\n",
    "\n",
    "# shared layer\n",
    "l1 = Bidirectional(LSTM(50, return_sequences=True, kernel_initializer=\"glorot_uniform\", implementation=2))(main_input) # the shared layer\n",
    "b1 = BatchNormalization()(l1)\n",
    "\n",
    "# layers\n",
    "l2_1 = Bidirectional(LSTM(50, return_sequences=False, kernel_initializer=\"glorot_uniform\", implementation=2, dropout=0.2))(b1) # the layer specialized in activity prediction\n",
    "b2_1 = BatchNormalization()(l2_1)\n",
    "\n",
    "l2_2 = Bidirectional(LSTM(50, return_sequences=False, kernel_initializer=\"glorot_uniform\", implementation=2, dropout=0.5))(b1) # the layer specialized in time prediction\n",
    "b2_2 = BatchNormalization()(l2_2)\n",
    "\n",
    "act_output = Dense(len(targetchartoindice), kernel_initializer='glorot_uniform', activation='softmax', name='act_output')(b2_1)\n",
    "time_output = Dense(1, kernel_initializer='glorot_uniform', name='time_output')(b2_2)\n",
    "\n",
    "model = Model(inputs=[main_input], outputs=[act_output, time_output])\n",
    "\n",
    "#compilations\n",
    "opt = optimizers.Nadam(lr=0.002, beta_1=0.9, beta_2=0.999, epsilon=1e-08, schedule_decay=0.004, clipvalue=3)\n",
    "model.compile(loss={'act_output':'categorical_crossentropy', 'time_output':'mean_absolute_error'}, optimizer=opt)\n",
    "\n",
    "#callbacks\n",
    "early_stopping = EarlyStopping(monitor='val_loss', patience=83)\n",
    "model_checkpoint = ModelCheckpoint(args.outputdir + 'model_{epoch:02d}-{val_loss:.2f}.h5', \n",
    "                                   monitor='val_loss', verbose=0, save_best_only=True, \n",
    "                                   save_weights_only=False, mode='auto')\n",
    "lr_reducer = ReduceLROnPlateau(monitor='val_loss', factor=0.5, patience=10, \n",
    "                               verbose=0, mode='auto', epsilon=0.0001, cooldown=0, min_lr=0)\n",
    "\n",
    "#fit\n",
    "model.fit(X, {'act_output':y_a, 'time_output':y_t}, validation_split=0.2, verbose=2, \n",
    "          callbacks=[early_stopping, model_checkpoint, lr_reducer], batch_size=16, epochs=500)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "____________________________________________________________________________________________________\n",
      "Layer (type)                     Output Shape          Param #     Connected to                     \n",
      "====================================================================================================\n",
      "main_input (InputLayer)          (None, 15, 14)        0                                            \n",
      "____________________________________________________________________________________________________\n",
      "bidirectional_1 (Bidirectional)  (None, 15, 100)       26000       main_input[0][0]                 \n",
      "____________________________________________________________________________________________________\n",
      "batch_normalization_1 (BatchNorm (None, 15, 100)       400         bidirectional_1[0][0]            \n",
      "____________________________________________________________________________________________________\n",
      "bidirectional_2 (Bidirectional)  (None, 100)           60400       batch_normalization_1[0][0]      \n",
      "____________________________________________________________________________________________________\n",
      "bidirectional_3 (Bidirectional)  (None, 100)           60400       batch_normalization_1[0][0]      \n",
      "____________________________________________________________________________________________________\n",
      "batch_normalization_2 (BatchNorm (None, 100)           400         bidirectional_2[0][0]            \n",
      "____________________________________________________________________________________________________\n",
      "batch_normalization_3 (BatchNorm (None, 100)           400         bidirectional_3[0][0]            \n",
      "____________________________________________________________________________________________________\n",
      "act_output (Dense)               (None, 10)            1010        batch_normalization_2[0][0]      \n",
      "____________________________________________________________________________________________________\n",
      "time_output (Dense)              (None, 1)             101         batch_normalization_3[0][0]      \n",
      "====================================================================================================\n",
      "Total params: 149,111\n",
      "Trainable params: 148,511\n",
      "Non-trainable params: 600\n",
      "____________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "source": [
    "# Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "def reshapeOutput(y_a):\n",
    "    pad_output = np.pad(y_a, [(0, 0), (0, num_features-len(targetchartoindice))], mode ='constant', constant_values=0)\n",
    "    out = b.reshape((y_a.shape[0], 1, num_features))\n",
    "    return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "a = reshapeOutput(y_a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "a.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "Concatenate([X, a])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "from keras.layers.core import Reshape\n",
    "from keras.layers.convolutional import ZeroPadding1D\n",
    "import keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "from keras.layers import Input, Embedding, LSTM, Dense\n",
    "from keras.models import Model\n",
    "\n",
    "# Headline input: meant to receive sequences of 100 integers, between 1 and 10000.\n",
    "# Note that we can name any layer by passing it a \"name\" argument.\n",
    "main_input = Input(shape=(100,), dtype='int32', name='main_input')\n",
    "\n",
    "# This embedding layer will encode the input sequence\n",
    "# into a sequence of dense 512-dimensional vectors.\n",
    "x = Embedding(output_dim=512, input_dim=10000, input_length=100)(main_input)\n",
    "\n",
    "# A LSTM will transform the vector sequence into a single vector,\n",
    "# containing information about the entire sequence\n",
    "lstm_out = LSTM(32)(x)\n",
    "\n",
    "auxiliary_output = Dense(1, activation='sigmoid', name='aux_output')(lstm_out)\n",
    "auxiliary_input = Input(shape=(5,), name='aux_input')\n",
    "x = keras.layers.concatenate([lstm_out, auxiliary_input])\n",
    "\n",
    "# We stack a deep densely-connected network on top\n",
    "x = Dense(64, activation='relu')(x)\n",
    "x = Dense(64, activation='relu')(x)\n",
    "x = Dense(64, activation='relu')(x)\n",
    "\n",
    "# And finally we add the main logistic regression layer\n",
    "main_output = Dense(1, activation='sigmoid', name='main_output')(x)\n",
    "model = Model(inputs=[main_input, auxiliary_input], outputs=[main_output, auxiliary_output])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.3"
  },
  "toc": {
   "colors": {
    "hover_highlight": "#DAA520",
    "running_highlight": "#FF0000",
    "selected_highlight": "#FFD700"
   },
   "moveMenuLeft": true,
   "nav_menu": {
    "height": "66px",
    "width": "252px"
   },
   "navigate_menu": true,
   "number_sections": true,
   "sideBar": true,
   "threshold": 4,
   "toc_cell": false,
   "toc_section_display": "block",
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
