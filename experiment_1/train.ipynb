{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Modification:**\n",
    "- Use Bidirectional LSTM \n",
    "\n",
    "```l1 = Bidirectional(LSTM(100, consume_less='gpu', init='glorot_uniform', return_sequences=True, dropout_W=0.2))(main_input)```\n",
    "\n",
    "- Change from target_chars to targetchartoindice (same len but target_chars not exist) \n",
    "\n",
    "```act_output = Dense(len(targetchartoindice), activation='softmax', init='glorot_uniform', name='act_output')(b2_1)```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import argparse\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using Theano backend.\n",
      "ERROR (theano.sandbox.cuda): Failed to compile cuda_ndarray.cu: libcublas.so.8.0: cannot open shared object file: No such file or directory\n"
     ]
    }
   ],
   "source": [
    "from keras.models import Sequential, Model\n",
    "from keras.layers.core import Dense\n",
    "from keras.layers.recurrent import LSTM, GRU, SimpleRNN\n",
    "from keras.layers import Input\n",
    "from keras.layers.wrappers import Bidirectional\n",
    "from keras.utils.data_utils import get_file\n",
    "from keras.regularizers import WeightRegularizer\n",
    "from keras.optimizers import Nadam\n",
    "from keras.callbacks import EarlyStopping, ModelCheckpoint, ReduceLROnPlateau\n",
    "from keras.layers.normalization import BatchNormalization\n",
    "from theano.ifelse import ifelse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "name = 'helpdesk'\n",
    "args = {\n",
    "    'inputdir': '../input/{}/'.format(name),   \n",
    "    'outputdir': './output_files/{}/'.format(name)\n",
    "}\n",
    "\n",
    "args = argparse.Namespace(**args)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "if not os.path.isdir(args.outputdir):\n",
    "    os.makedirs(args.outputdir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(args.inputdir + 'parameters.pkl', \"rb\") as f:\n",
    "    maxlen = pickle.load(f)\n",
    "    num_features = pickle.load(f)\n",
    "    chartoindice = pickle.load(f)\n",
    "    targetchartoindice = pickle.load(f)\n",
    "    divisor = pickle.load(f)\n",
    "    divisor2 = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "with open(args.inputdir + 'preprocessed_data.pkl', \"rb\") as f:\n",
    "    X = pickle.load(f)\n",
    "    y_a = pickle.load(f)\n",
    "    y_t = pickle.load(f)\n",
    "    X_test = pickle.load(f)\n",
    "    y_a_test = pickle.load(f)\n",
    "    y_t_test = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Build model...\n",
      "Train on 7344 samples, validate on 1837 samples\n",
      "Epoch 1/500\n",
      "28s - loss: 2.0344 - act_output_loss: 0.8110 - time_output_loss: 1.2234 - val_loss: 1.6764 - val_act_output_loss: 0.6359 - val_time_output_loss: 1.0405\n",
      "Epoch 2/500\n",
      "32s - loss: 1.6682 - act_output_loss: 0.6292 - time_output_loss: 1.0390 - val_loss: 1.6836 - val_act_output_loss: 0.6735 - val_time_output_loss: 1.0100\n",
      "Epoch 3/500\n",
      "32s - loss: 1.6325 - act_output_loss: 0.6145 - time_output_loss: 1.0180 - val_loss: 1.5922 - val_act_output_loss: 0.5998 - val_time_output_loss: 0.9923\n",
      "Epoch 4/500\n",
      "32s - loss: 1.6175 - act_output_loss: 0.6051 - time_output_loss: 1.0124 - val_loss: 1.6028 - val_act_output_loss: 0.6078 - val_time_output_loss: 0.9950\n",
      "Epoch 5/500\n",
      "32s - loss: 1.6186 - act_output_loss: 0.6111 - time_output_loss: 1.0074 - val_loss: 1.5900 - val_act_output_loss: 0.6158 - val_time_output_loss: 0.9742\n",
      "Epoch 6/500\n",
      "32s - loss: 1.6033 - act_output_loss: 0.5975 - time_output_loss: 1.0058 - val_loss: 1.5905 - val_act_output_loss: 0.6050 - val_time_output_loss: 0.9855\n",
      "Epoch 7/500\n",
      "32s - loss: 1.6070 - act_output_loss: 0.6048 - time_output_loss: 1.0022 - val_loss: 1.5580 - val_act_output_loss: 0.5778 - val_time_output_loss: 0.9801\n",
      "Epoch 8/500\n",
      "32s - loss: 1.5865 - act_output_loss: 0.5888 - time_output_loss: 0.9977 - val_loss: 1.5466 - val_act_output_loss: 0.5765 - val_time_output_loss: 0.9701\n",
      "Epoch 9/500\n",
      "32s - loss: 1.5889 - act_output_loss: 0.5925 - time_output_loss: 0.9964 - val_loss: 1.5454 - val_act_output_loss: 0.5953 - val_time_output_loss: 0.9501\n",
      "Epoch 10/500\n",
      "32s - loss: 1.5896 - act_output_loss: 0.5893 - time_output_loss: 1.0003 - val_loss: 1.6150 - val_act_output_loss: 0.6085 - val_time_output_loss: 1.0065\n",
      "Epoch 11/500\n",
      "33s - loss: 1.5843 - act_output_loss: 0.5875 - time_output_loss: 0.9968 - val_loss: 1.5548 - val_act_output_loss: 0.5732 - val_time_output_loss: 0.9816\n",
      "Epoch 12/500\n",
      "33s - loss: 1.5924 - act_output_loss: 0.5980 - time_output_loss: 0.9944 - val_loss: 1.5477 - val_act_output_loss: 0.5745 - val_time_output_loss: 0.9732\n",
      "Epoch 13/500\n",
      "34s - loss: 1.5741 - act_output_loss: 0.5823 - time_output_loss: 0.9918 - val_loss: 1.5240 - val_act_output_loss: 0.5714 - val_time_output_loss: 0.9526\n",
      "Epoch 14/500\n",
      "34s - loss: 1.5778 - act_output_loss: 0.5871 - time_output_loss: 0.9907 - val_loss: 1.5288 - val_act_output_loss: 0.5650 - val_time_output_loss: 0.9638\n",
      "Epoch 15/500\n",
      "34s - loss: 1.5765 - act_output_loss: 0.5866 - time_output_loss: 0.9898 - val_loss: 1.5370 - val_act_output_loss: 0.5791 - val_time_output_loss: 0.9579\n",
      "Epoch 16/500\n",
      "34s - loss: 1.5780 - act_output_loss: 0.5894 - time_output_loss: 0.9886 - val_loss: 1.5517 - val_act_output_loss: 0.5880 - val_time_output_loss: 0.9637\n",
      "Epoch 17/500\n",
      "34s - loss: 1.5722 - act_output_loss: 0.5810 - time_output_loss: 0.9911 - val_loss: 1.5657 - val_act_output_loss: 0.5818 - val_time_output_loss: 0.9839\n",
      "Epoch 18/500\n",
      "34s - loss: 1.5670 - act_output_loss: 0.5770 - time_output_loss: 0.9900 - val_loss: 1.5293 - val_act_output_loss: 0.5754 - val_time_output_loss: 0.9539\n",
      "Epoch 19/500\n",
      "32s - loss: 1.5681 - act_output_loss: 0.5801 - time_output_loss: 0.9880 - val_loss: 1.5249 - val_act_output_loss: 0.5677 - val_time_output_loss: 0.9572\n",
      "Epoch 20/500\n",
      "32s - loss: 1.5635 - act_output_loss: 0.5748 - time_output_loss: 0.9887 - val_loss: 1.5317 - val_act_output_loss: 0.5654 - val_time_output_loss: 0.9663\n",
      "Epoch 21/500\n",
      "31s - loss: 1.5611 - act_output_loss: 0.5745 - time_output_loss: 0.9865 - val_loss: 1.5022 - val_act_output_loss: 0.5533 - val_time_output_loss: 0.9489\n",
      "Epoch 22/500\n",
      "32s - loss: 1.5631 - act_output_loss: 0.5763 - time_output_loss: 0.9868 - val_loss: 1.5247 - val_act_output_loss: 0.5710 - val_time_output_loss: 0.9537\n",
      "Epoch 23/500\n",
      "31s - loss: 1.5652 - act_output_loss: 0.5804 - time_output_loss: 0.9848 - val_loss: 1.5333 - val_act_output_loss: 0.5798 - val_time_output_loss: 0.9535\n",
      "Epoch 24/500\n",
      "31s - loss: 1.5632 - act_output_loss: 0.5783 - time_output_loss: 0.9849 - val_loss: 1.5383 - val_act_output_loss: 0.5742 - val_time_output_loss: 0.9640\n",
      "Epoch 25/500\n",
      "31s - loss: 1.5615 - act_output_loss: 0.5778 - time_output_loss: 0.9837 - val_loss: 1.5349 - val_act_output_loss: 0.5771 - val_time_output_loss: 0.9578\n",
      "Epoch 26/500\n",
      "31s - loss: 1.5593 - act_output_loss: 0.5761 - time_output_loss: 0.9832 - val_loss: 1.5338 - val_act_output_loss: 0.5764 - val_time_output_loss: 0.9574\n",
      "Epoch 27/500\n",
      "31s - loss: 1.5576 - act_output_loss: 0.5716 - time_output_loss: 0.9860 - val_loss: 1.5058 - val_act_output_loss: 0.5602 - val_time_output_loss: 0.9456\n",
      "Epoch 28/500\n",
      "31s - loss: 1.5547 - act_output_loss: 0.5704 - time_output_loss: 0.9842 - val_loss: 1.5110 - val_act_output_loss: 0.5599 - val_time_output_loss: 0.9511\n",
      "Epoch 29/500\n",
      "31s - loss: 1.5561 - act_output_loss: 0.5717 - time_output_loss: 0.9845 - val_loss: 1.5382 - val_act_output_loss: 0.5782 - val_time_output_loss: 0.9600\n",
      "Epoch 30/500\n",
      "31s - loss: 1.5571 - act_output_loss: 0.5781 - time_output_loss: 0.9791 - val_loss: 1.5278 - val_act_output_loss: 0.5763 - val_time_output_loss: 0.9516\n",
      "Epoch 31/500\n",
      "31s - loss: 1.5516 - act_output_loss: 0.5680 - time_output_loss: 0.9836 - val_loss: 1.5127 - val_act_output_loss: 0.5627 - val_time_output_loss: 0.9500\n",
      "Epoch 32/500\n",
      "31s - loss: 1.5596 - act_output_loss: 0.5737 - time_output_loss: 0.9859 - val_loss: 1.5307 - val_act_output_loss: 0.5826 - val_time_output_loss: 0.9482\n",
      "Epoch 33/500\n",
      "31s - loss: 1.5364 - act_output_loss: 0.5589 - time_output_loss: 0.9775 - val_loss: 1.5179 - val_act_output_loss: 0.5664 - val_time_output_loss: 0.9515\n",
      "Epoch 34/500\n",
      "31s - loss: 1.5362 - act_output_loss: 0.5584 - time_output_loss: 0.9778 - val_loss: 1.5163 - val_act_output_loss: 0.5665 - val_time_output_loss: 0.9498\n",
      "Epoch 35/500\n",
      "31s - loss: 1.5354 - act_output_loss: 0.5575 - time_output_loss: 0.9780 - val_loss: 1.5155 - val_act_output_loss: 0.5578 - val_time_output_loss: 0.9577\n",
      "Epoch 36/500\n",
      "31s - loss: 1.5270 - act_output_loss: 0.5523 - time_output_loss: 0.9747 - val_loss: 1.5208 - val_act_output_loss: 0.5710 - val_time_output_loss: 0.9497\n",
      "Epoch 37/500\n",
      "31s - loss: 1.5317 - act_output_loss: 0.5544 - time_output_loss: 0.9773 - val_loss: 1.5172 - val_act_output_loss: 0.5629 - val_time_output_loss: 0.9544\n",
      "Epoch 38/500\n",
      "31s - loss: 1.5288 - act_output_loss: 0.5504 - time_output_loss: 0.9784 - val_loss: 1.5190 - val_act_output_loss: 0.5730 - val_time_output_loss: 0.9460\n",
      "Epoch 39/500\n",
      "31s - loss: 1.5311 - act_output_loss: 0.5513 - time_output_loss: 0.9798 - val_loss: 1.5143 - val_act_output_loss: 0.5635 - val_time_output_loss: 0.9509\n",
      "Epoch 40/500\n",
      "31s - loss: 1.5322 - act_output_loss: 0.5524 - time_output_loss: 0.9798 - val_loss: 1.5123 - val_act_output_loss: 0.5664 - val_time_output_loss: 0.9459\n",
      "Epoch 41/500\n",
      "31s - loss: 1.5264 - act_output_loss: 0.5495 - time_output_loss: 0.9770 - val_loss: 1.5054 - val_act_output_loss: 0.5597 - val_time_output_loss: 0.9458\n",
      "Epoch 42/500\n",
      "23s - loss: 1.5280 - act_output_loss: 0.5524 - time_output_loss: 0.9756 - val_loss: 1.5265 - val_act_output_loss: 0.5714 - val_time_output_loss: 0.9551\n",
      "Epoch 43/500\n",
      "21s - loss: 1.5277 - act_output_loss: 0.5494 - time_output_loss: 0.9783 - val_loss: 1.5031 - val_act_output_loss: 0.5602 - val_time_output_loss: 0.9429\n",
      "Epoch 44/500\n",
      "21s - loss: 1.5107 - act_output_loss: 0.5378 - time_output_loss: 0.9729 - val_loss: 1.5065 - val_act_output_loss: 0.5649 - val_time_output_loss: 0.9416\n",
      "Epoch 45/500\n",
      "20s - loss: 1.5114 - act_output_loss: 0.5393 - time_output_loss: 0.9721 - val_loss: 1.5085 - val_act_output_loss: 0.5672 - val_time_output_loss: 0.9413\n",
      "Epoch 46/500\n",
      "20s - loss: 1.5102 - act_output_loss: 0.5374 - time_output_loss: 0.9728 - val_loss: 1.5047 - val_act_output_loss: 0.5625 - val_time_output_loss: 0.9422\n",
      "Epoch 47/500\n",
      "21s - loss: 1.5124 - act_output_loss: 0.5388 - time_output_loss: 0.9736 - val_loss: 1.5134 - val_act_output_loss: 0.5624 - val_time_output_loss: 0.9511\n",
      "Epoch 48/500\n",
      "20s - loss: 1.5136 - act_output_loss: 0.5418 - time_output_loss: 0.9718 - val_loss: 1.5099 - val_act_output_loss: 0.5644 - val_time_output_loss: 0.9454\n",
      "Epoch 49/500\n",
      "21s - loss: 1.5078 - act_output_loss: 0.5364 - time_output_loss: 0.9715 - val_loss: 1.5038 - val_act_output_loss: 0.5624 - val_time_output_loss: 0.9415\n",
      "Epoch 50/500\n",
      "21s - loss: 1.5164 - act_output_loss: 0.5421 - time_output_loss: 0.9743 - val_loss: 1.5105 - val_act_output_loss: 0.5676 - val_time_output_loss: 0.9429\n",
      "Epoch 51/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "21s - loss: 1.5081 - act_output_loss: 0.5392 - time_output_loss: 0.9688 - val_loss: 1.5134 - val_act_output_loss: 0.5700 - val_time_output_loss: 0.9435\n",
      "Epoch 52/500\n",
      "21s - loss: 1.5083 - act_output_loss: 0.5382 - time_output_loss: 0.9701 - val_loss: 1.5097 - val_act_output_loss: 0.5690 - val_time_output_loss: 0.9407\n",
      "Epoch 53/500\n",
      "21s - loss: 1.4973 - act_output_loss: 0.5325 - time_output_loss: 0.9647 - val_loss: 1.5057 - val_act_output_loss: 0.5656 - val_time_output_loss: 0.9401\n",
      "Epoch 54/500\n",
      "21s - loss: 1.5052 - act_output_loss: 0.5353 - time_output_loss: 0.9699 - val_loss: 1.5048 - val_act_output_loss: 0.5632 - val_time_output_loss: 0.9416\n",
      "Epoch 55/500\n",
      "21s - loss: 1.4956 - act_output_loss: 0.5283 - time_output_loss: 0.9673 - val_loss: 1.5076 - val_act_output_loss: 0.5675 - val_time_output_loss: 0.9400\n",
      "Epoch 56/500\n",
      "20s - loss: 1.5050 - act_output_loss: 0.5319 - time_output_loss: 0.9730 - val_loss: 1.5103 - val_act_output_loss: 0.5679 - val_time_output_loss: 0.9424\n",
      "Epoch 57/500\n",
      "21s - loss: 1.4978 - act_output_loss: 0.5282 - time_output_loss: 0.9696 - val_loss: 1.5089 - val_act_output_loss: 0.5702 - val_time_output_loss: 0.9387\n",
      "Epoch 58/500\n",
      "20s - loss: 1.5024 - act_output_loss: 0.5294 - time_output_loss: 0.9730 - val_loss: 1.5143 - val_act_output_loss: 0.5721 - val_time_output_loss: 0.9423\n",
      "Epoch 59/500\n",
      "20s - loss: 1.4998 - act_output_loss: 0.5287 - time_output_loss: 0.9710 - val_loss: 1.5102 - val_act_output_loss: 0.5677 - val_time_output_loss: 0.9425\n",
      "Epoch 60/500\n",
      "20s - loss: 1.4939 - act_output_loss: 0.5254 - time_output_loss: 0.9685 - val_loss: 1.5143 - val_act_output_loss: 0.5723 - val_time_output_loss: 0.9420\n",
      "Epoch 61/500\n",
      "21s - loss: 1.5007 - act_output_loss: 0.5302 - time_output_loss: 0.9705 - val_loss: 1.5122 - val_act_output_loss: 0.5728 - val_time_output_loss: 0.9394\n",
      "Epoch 62/500\n",
      "21s - loss: 1.4946 - act_output_loss: 0.5268 - time_output_loss: 0.9678 - val_loss: 1.5046 - val_act_output_loss: 0.5660 - val_time_output_loss: 0.9386\n",
      "Epoch 63/500\n",
      "21s - loss: 1.4957 - act_output_loss: 0.5258 - time_output_loss: 0.9699 - val_loss: 1.5086 - val_act_output_loss: 0.5671 - val_time_output_loss: 0.9415\n",
      "Epoch 64/500\n",
      "21s - loss: 1.4907 - act_output_loss: 0.5227 - time_output_loss: 0.9680 - val_loss: 1.5077 - val_act_output_loss: 0.5682 - val_time_output_loss: 0.9395\n",
      "Epoch 65/500\n",
      "21s - loss: 1.4837 - act_output_loss: 0.5207 - time_output_loss: 0.9629 - val_loss: 1.5106 - val_act_output_loss: 0.5695 - val_time_output_loss: 0.9411\n",
      "Epoch 66/500\n",
      "21s - loss: 1.4885 - act_output_loss: 0.5235 - time_output_loss: 0.9650 - val_loss: 1.5134 - val_act_output_loss: 0.5710 - val_time_output_loss: 0.9424\n",
      "Epoch 67/500\n",
      "21s - loss: 1.4878 - act_output_loss: 0.5199 - time_output_loss: 0.9678 - val_loss: 1.5100 - val_act_output_loss: 0.5706 - val_time_output_loss: 0.9393\n",
      "Epoch 68/500\n",
      "21s - loss: 1.4904 - act_output_loss: 0.5235 - time_output_loss: 0.9669 - val_loss: 1.5095 - val_act_output_loss: 0.5708 - val_time_output_loss: 0.9388\n",
      "Epoch 69/500\n",
      "21s - loss: 1.4892 - act_output_loss: 0.5190 - time_output_loss: 0.9701 - val_loss: 1.5094 - val_act_output_loss: 0.5696 - val_time_output_loss: 0.9398\n",
      "Epoch 70/500\n",
      "21s - loss: 1.4919 - act_output_loss: 0.5236 - time_output_loss: 0.9683 - val_loss: 1.5108 - val_act_output_loss: 0.5712 - val_time_output_loss: 0.9396\n",
      "Epoch 71/500\n",
      "21s - loss: 1.4874 - act_output_loss: 0.5204 - time_output_loss: 0.9671 - val_loss: 1.5123 - val_act_output_loss: 0.5716 - val_time_output_loss: 0.9408\n",
      "Epoch 72/500\n",
      "21s - loss: 1.4886 - act_output_loss: 0.5214 - time_output_loss: 0.9673 - val_loss: 1.5115 - val_act_output_loss: 0.5703 - val_time_output_loss: 0.9411\n",
      "Epoch 73/500\n",
      "20s - loss: 1.4876 - act_output_loss: 0.5223 - time_output_loss: 0.9653 - val_loss: 1.5107 - val_act_output_loss: 0.5705 - val_time_output_loss: 0.9403\n",
      "Epoch 74/500\n",
      "21s - loss: 1.4764 - act_output_loss: 0.5161 - time_output_loss: 0.9602 - val_loss: 1.5112 - val_act_output_loss: 0.5702 - val_time_output_loss: 0.9410\n",
      "Epoch 75/500\n",
      "21s - loss: 1.4891 - act_output_loss: 0.5230 - time_output_loss: 0.9661 - val_loss: 1.5118 - val_act_output_loss: 0.5711 - val_time_output_loss: 0.9406\n",
      "Epoch 76/500\n",
      "21s - loss: 1.4834 - act_output_loss: 0.5173 - time_output_loss: 0.9660 - val_loss: 1.5104 - val_act_output_loss: 0.5704 - val_time_output_loss: 0.9400\n",
      "Epoch 77/500\n",
      "21s - loss: 1.4937 - act_output_loss: 0.5227 - time_output_loss: 0.9710 - val_loss: 1.5104 - val_act_output_loss: 0.5704 - val_time_output_loss: 0.9400\n",
      "Epoch 78/500\n",
      "21s - loss: 1.4889 - act_output_loss: 0.5177 - time_output_loss: 0.9712 - val_loss: 1.5118 - val_act_output_loss: 0.5704 - val_time_output_loss: 0.9415\n",
      "Epoch 79/500\n",
      "20s - loss: 1.4873 - act_output_loss: 0.5200 - time_output_loss: 0.9673 - val_loss: 1.5116 - val_act_output_loss: 0.5711 - val_time_output_loss: 0.9405\n",
      "Epoch 80/500\n",
      "20s - loss: 1.4802 - act_output_loss: 0.5131 - time_output_loss: 0.9671 - val_loss: 1.5119 - val_act_output_loss: 0.5718 - val_time_output_loss: 0.9401\n",
      "Epoch 81/500\n",
      "20s - loss: 1.4831 - act_output_loss: 0.5168 - time_output_loss: 0.9663 - val_loss: 1.5135 - val_act_output_loss: 0.5720 - val_time_output_loss: 0.9415\n",
      "Epoch 82/500\n",
      "20s - loss: 1.4838 - act_output_loss: 0.5161 - time_output_loss: 0.9677 - val_loss: 1.5118 - val_act_output_loss: 0.5717 - val_time_output_loss: 0.9401\n",
      "Epoch 83/500\n",
      "20s - loss: 1.4832 - act_output_loss: 0.5137 - time_output_loss: 0.9695 - val_loss: 1.5114 - val_act_output_loss: 0.5714 - val_time_output_loss: 0.9400\n",
      "Epoch 84/500\n",
      "21s - loss: 1.4841 - act_output_loss: 0.5172 - time_output_loss: 0.9669 - val_loss: 1.5124 - val_act_output_loss: 0.5722 - val_time_output_loss: 0.9402\n",
      "Epoch 85/500\n",
      "20s - loss: 1.4809 - act_output_loss: 0.5152 - time_output_loss: 0.9657 - val_loss: 1.5113 - val_act_output_loss: 0.5718 - val_time_output_loss: 0.9395\n",
      "Epoch 86/500\n",
      "20s - loss: 1.4862 - act_output_loss: 0.5173 - time_output_loss: 0.9689 - val_loss: 1.5113 - val_act_output_loss: 0.5716 - val_time_output_loss: 0.9397\n",
      "Epoch 87/500\n",
      "20s - loss: 1.4844 - act_output_loss: 0.5160 - time_output_loss: 0.9684 - val_loss: 1.5125 - val_act_output_loss: 0.5720 - val_time_output_loss: 0.9405\n",
      "Epoch 88/500\n",
      "20s - loss: 1.4860 - act_output_loss: 0.5192 - time_output_loss: 0.9667 - val_loss: 1.5129 - val_act_output_loss: 0.5728 - val_time_output_loss: 0.9401\n",
      "Epoch 89/500\n",
      "20s - loss: 1.4787 - act_output_loss: 0.5140 - time_output_loss: 0.9647 - val_loss: 1.5120 - val_act_output_loss: 0.5722 - val_time_output_loss: 0.9397\n",
      "Epoch 90/500\n",
      "21s - loss: 1.4791 - act_output_loss: 0.5128 - time_output_loss: 0.9662 - val_loss: 1.5130 - val_act_output_loss: 0.5725 - val_time_output_loss: 0.9405\n",
      "Epoch 91/500\n",
      "21s - loss: 1.4821 - act_output_loss: 0.5181 - time_output_loss: 0.9640 - val_loss: 1.5117 - val_act_output_loss: 0.5722 - val_time_output_loss: 0.9395\n",
      "Epoch 92/500\n",
      "20s - loss: 1.4878 - act_output_loss: 0.5163 - time_output_loss: 0.9715 - val_loss: 1.5135 - val_act_output_loss: 0.5729 - val_time_output_loss: 0.9406\n",
      "Epoch 93/500\n",
      "20s - loss: 1.4756 - act_output_loss: 0.5118 - time_output_loss: 0.9638 - val_loss: 1.5112 - val_act_output_loss: 0.5725 - val_time_output_loss: 0.9387\n",
      "Epoch 94/500\n",
      "20s - loss: 1.4843 - act_output_loss: 0.5173 - time_output_loss: 0.9669 - val_loss: 1.5127 - val_act_output_loss: 0.5728 - val_time_output_loss: 0.9400\n",
      "Epoch 95/500\n",
      "20s - loss: 1.4815 - act_output_loss: 0.5130 - time_output_loss: 0.9685 - val_loss: 1.5133 - val_act_output_loss: 0.5726 - val_time_output_loss: 0.9406\n",
      "Epoch 96/500\n",
      "20s - loss: 1.4863 - act_output_loss: 0.5134 - time_output_loss: 0.9729 - val_loss: 1.5118 - val_act_output_loss: 0.5720 - val_time_output_loss: 0.9398\n",
      "Epoch 97/500\n",
      "20s - loss: 1.4821 - act_output_loss: 0.5140 - time_output_loss: 0.9681 - val_loss: 1.5106 - val_act_output_loss: 0.5721 - val_time_output_loss: 0.9384\n",
      "Epoch 98/500\n",
      "20s - loss: 1.4752 - act_output_loss: 0.5104 - time_output_loss: 0.9648 - val_loss: 1.5105 - val_act_output_loss: 0.5717 - val_time_output_loss: 0.9388\n",
      "Epoch 99/500\n",
      "20s - loss: 1.4808 - act_output_loss: 0.5142 - time_output_loss: 0.9666 - val_loss: 1.5102 - val_act_output_loss: 0.5718 - val_time_output_loss: 0.9384\n",
      "Epoch 100/500\n",
      "20s - loss: 1.4797 - act_output_loss: 0.5161 - time_output_loss: 0.9636 - val_loss: 1.5101 - val_act_output_loss: 0.5718 - val_time_output_loss: 0.9383\n",
      "Epoch 101/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "20s - loss: 1.4809 - act_output_loss: 0.5128 - time_output_loss: 0.9681 - val_loss: 1.5102 - val_act_output_loss: 0.5718 - val_time_output_loss: 0.9384\n",
      "Epoch 102/500\n",
      "20s - loss: 1.4854 - act_output_loss: 0.5171 - time_output_loss: 0.9682 - val_loss: 1.5133 - val_act_output_loss: 0.5730 - val_time_output_loss: 0.9403\n",
      "Epoch 103/500\n",
      "20s - loss: 1.4749 - act_output_loss: 0.5075 - time_output_loss: 0.9674 - val_loss: 1.5118 - val_act_output_loss: 0.5725 - val_time_output_loss: 0.9393\n",
      "Epoch 104/500\n",
      "20s - loss: 1.4795 - act_output_loss: 0.5133 - time_output_loss: 0.9662 - val_loss: 1.5132 - val_act_output_loss: 0.5727 - val_time_output_loss: 0.9404\n",
      "Epoch 105/500\n",
      "20s - loss: 1.4818 - act_output_loss: 0.5132 - time_output_loss: 0.9686 - val_loss: 1.5140 - val_act_output_loss: 0.5735 - val_time_output_loss: 0.9405\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7ff1c44f3c50>"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# build the model: \n",
    "print('Build model...')\n",
    "main_input = Input(shape=(maxlen, num_features), name='main_input')\n",
    "# shared layer\n",
    "l1 = Bidirectional(LSTM(100, consume_less='gpu', init='glorot_uniform', return_sequences=True))(main_input) # the shared layer\n",
    "b1 = BatchNormalization()(l1)\n",
    "\n",
    "# layers\n",
    "l2_1 = Bidirectional(LSTM(100, consume_less='gpu', init='glorot_uniform', return_sequences=False, dropout_W=0.2))(b1) # the layer specialized in activity prediction\n",
    "b2_1 = BatchNormalization()(l2_1)\n",
    "l2_2 = Bidirectional(LSTM(75, consume_less='gpu', init='glorot_uniform', return_sequences=False, dropout_W=0.5))(b1) # the layer specialized in time prediction\n",
    "b2_2 = BatchNormalization()(l2_2)\n",
    "\n",
    "act_output = Dense(len(targetchartoindice), activation='softmax', init='glorot_uniform', name='act_output')(b2_1)\n",
    "time_output = Dense(1, init='glorot_uniform', name='time_output')(b2_2)\n",
    "\n",
    "model = Model(input=[main_input], output=[act_output, time_output])\n",
    "\n",
    "opt = Nadam(lr=0.002, beta_1=0.9, beta_2=0.999, epsilon=1e-08, schedule_decay=0.004, clipvalue=3)\n",
    "\n",
    "model.compile(loss={'act_output':'categorical_crossentropy', 'time_output':'mae'}, optimizer=opt)\n",
    "early_stopping = EarlyStopping(monitor='val_loss', patience=83)\n",
    "model_checkpoint = ModelCheckpoint(args.outputdir + 'model_{epoch:02d}-{val_loss:.2f}.h5', monitor='val_loss', verbose=0, save_best_only=True, save_weights_only=False, mode='auto')\n",
    "lr_reducer = ReduceLROnPlateau(monitor='val_loss', factor=0.5, patience=10, verbose=0, mode='auto', epsilon=0.0001, cooldown=0, min_lr=0)\n",
    "\n",
    "model.fit(X, {'act_output':y_a, 'time_output':y_t}, validation_split=0.2, verbose=2, callbacks=[early_stopping, model_checkpoint, lr_reducer], batch_size=maxlen, nb_epoch=500)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "____________________________________________________________________________________________________\n",
      "Layer (type)                     Output Shape          Param #     Connected to                     \n",
      "====================================================================================================\n",
      "main_input (InputLayer)          (None, 15, 14)        0                                            \n",
      "____________________________________________________________________________________________________\n",
      "bidirectional_10 (Bidirectional) (None, 15, 200)       92000       main_input[0][0]                 \n",
      "____________________________________________________________________________________________________\n",
      "batchnormalization_10 (BatchNorm (None, 15, 200)       800         bidirectional_10[0][0]           \n",
      "____________________________________________________________________________________________________\n",
      "bidirectional_11 (Bidirectional) (None, 200)           240800      batchnormalization_10[0][0]      \n",
      "____________________________________________________________________________________________________\n",
      "bidirectional_12 (Bidirectional) (None, 150)           165600      batchnormalization_10[0][0]      \n",
      "____________________________________________________________________________________________________\n",
      "batchnormalization_11 (BatchNorm (None, 200)           800         bidirectional_11[0][0]           \n",
      "____________________________________________________________________________________________________\n",
      "batchnormalization_12 (BatchNorm (None, 150)           600         bidirectional_12[0][0]           \n",
      "____________________________________________________________________________________________________\n",
      "act_output (Dense)               (None, 10)            2010        batchnormalization_11[0][0]      \n",
      "____________________________________________________________________________________________________\n",
      "time_output (Dense)              (None, 1)             151         batchnormalization_12[0][0]      \n",
      "====================================================================================================\n",
      "Total params: 502,761\n",
      "Trainable params: 501,661\n",
      "Non-trainable params: 1,100\n",
      "____________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  },
  "toc": {
   "colors": {
    "hover_highlight": "#DAA520",
    "running_highlight": "#FF0000",
    "selected_highlight": "#FFD700"
   },
   "moveMenuLeft": true,
   "nav_menu": {
    "height": "66px",
    "width": "252px"
   },
   "navigate_menu": true,
   "number_sections": true,
   "sideBar": true,
   "threshold": 4,
   "toc_cell": false,
   "toc_section_display": "block",
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
