{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "**Modification:**\n",
    "- Use Bidirectional LSTM \n",
    "\n",
    "```l1 = Bidirectional(LSTM(100, consume_less='gpu', init='glorot_uniform', return_sequences=True, dropout_W=0.2))(main_input)```\n",
    "\n",
    "- Change from target_chars to targetchartoindice (same len but target_chars not exist) \n",
    "\n",
    "```act_output = Dense(len(targetchartoindice), activation='softmax', init='glorot_uniform', name='act_output')(b2_1)```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "# Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import argparse\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import pickle\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using Theano backend.\n"
     ]
    }
   ],
   "source": [
    "from keras.models import Sequential, Model\n",
    "from keras.layers.core import Dense\n",
    "from keras.layers.recurrent import LSTM, GRU, SimpleRNN\n",
    "from keras.layers import Input, merge\n",
    "from keras.layers.wrappers import Bidirectional\n",
    "from keras import optimizers\n",
    "from keras.callbacks import EarlyStopping, ModelCheckpoint, ReduceLROnPlateau, History\n",
    "from keras.layers.normalization import BatchNormalization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "#name = 'bpi_12_w'\n",
    "name = 'helpdesk'\n",
    "args = {\n",
    "    'inputdir': '../input/{}/'.format(name),   \n",
    "    'outputdir': './output_files/{}/'.format(name)\n",
    "}\n",
    "\n",
    "args = argparse.Namespace(**args)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "if not os.path.isdir(args.outputdir):\n",
    "    os.makedirs(args.outputdir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "with open(args.inputdir + 'parameters.pkl', \"rb\") as f:\n",
    "    maxlen = pickle.load(f)\n",
    "    num_features = pickle.load(f)\n",
    "    chartoindice = pickle.load(f)\n",
    "    targetchartoindice = pickle.load(f)\n",
    "    divisor = pickle.load(f)\n",
    "    divisor2 = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "with open(args.inputdir + 'preprocessed_data.pkl', \"rb\") as f:\n",
    "    X = pickle.load(f)\n",
    "    y_a = pickle.load(f)\n",
    "    y_t = pickle.load(f)\n",
    "    X_test = pickle.load(f)\n",
    "    y_a_test = pickle.load(f)\n",
    "    y_t_test = pickle.load(f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "# Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Build model BLSTM...\n",
      "Train on 7344 samples, validate on 1837 samples\n",
      "Epoch 1/10000\n",
      "20s - loss: 1.9370 - act_output_loss: 0.8260 - time_output_loss: 1.1110 - act_output_acc: 0.7726 - time_output_acc: 0.2470 - val_loss: 1.7186 - val_act_output_loss: 0.6477 - val_time_output_loss: 1.0709 - val_act_output_acc: 0.8187 - val_time_output_acc: 0.2842\n",
      "Epoch 2/10000\n",
      "23s - loss: 1.6423 - act_output_loss: 0.6116 - time_output_loss: 1.0307 - act_output_acc: 0.8107 - time_output_acc: 0.2801 - val_loss: 1.5850 - val_act_output_loss: 0.5737 - val_time_output_loss: 1.0113 - val_act_output_acc: 0.8214 - val_time_output_acc: 0.2842\n",
      "Epoch 3/10000\n",
      "21s - loss: 1.6097 - act_output_loss: 0.5999 - time_output_loss: 1.0098 - act_output_acc: 0.8166 - time_output_acc: 0.2815 - val_loss: 1.5894 - val_act_output_loss: 0.5896 - val_time_output_loss: 0.9998 - val_act_output_acc: 0.8236 - val_time_output_acc: 0.2852\n",
      "Epoch 4/10000\n",
      "20s - loss: 1.6033 - act_output_loss: 0.5968 - time_output_loss: 1.0065 - act_output_acc: 0.8181 - time_output_acc: 0.2815 - val_loss: 1.5399 - val_act_output_loss: 0.5697 - val_time_output_loss: 0.9702 - val_act_output_acc: 0.8307 - val_time_output_acc: 0.2858\n",
      "Epoch 5/10000\n",
      "21s - loss: 1.5961 - act_output_loss: 0.5931 - time_output_loss: 1.0030 - act_output_acc: 0.8154 - time_output_acc: 0.2802 - val_loss: 1.5983 - val_act_output_loss: 0.5956 - val_time_output_loss: 1.0028 - val_act_output_acc: 0.8209 - val_time_output_acc: 0.2852\n",
      "Epoch 6/10000\n",
      "21s - loss: 1.5820 - act_output_loss: 0.5887 - time_output_loss: 0.9932 - act_output_acc: 0.8178 - time_output_acc: 0.2810 - val_loss: 1.5750 - val_act_output_loss: 0.5802 - val_time_output_loss: 0.9948 - val_act_output_acc: 0.8302 - val_time_output_acc: 0.2858\n",
      "Epoch 7/10000\n",
      "20s - loss: 1.5782 - act_output_loss: 0.5884 - time_output_loss: 0.9897 - act_output_acc: 0.8193 - time_output_acc: 0.2815 - val_loss: 1.5478 - val_act_output_loss: 0.5685 - val_time_output_loss: 0.9793 - val_act_output_acc: 0.8318 - val_time_output_acc: 0.2852\n",
      "Epoch 8/10000\n",
      "21s - loss: 1.5687 - act_output_loss: 0.5799 - time_output_loss: 0.9888 - act_output_acc: 0.8184 - time_output_acc: 0.2813 - val_loss: 1.5485 - val_act_output_loss: 0.5724 - val_time_output_loss: 0.9761 - val_act_output_acc: 0.8247 - val_time_output_acc: 0.2852\n",
      "Epoch 9/10000\n",
      "20s - loss: 1.5693 - act_output_loss: 0.5819 - time_output_loss: 0.9874 - act_output_acc: 0.8193 - time_output_acc: 0.2813 - val_loss: 1.5585 - val_act_output_loss: 0.5687 - val_time_output_loss: 0.9898 - val_act_output_acc: 0.8307 - val_time_output_acc: 0.2852\n",
      "Epoch 10/10000\n",
      "27s - loss: 1.5706 - act_output_loss: 0.5786 - time_output_loss: 0.9920 - act_output_acc: 0.8192 - time_output_acc: 0.2815 - val_loss: 1.5810 - val_act_output_loss: 0.5578 - val_time_output_loss: 1.0232 - val_act_output_acc: 0.8323 - val_time_output_acc: 0.2858\n",
      "Epoch 11/10000\n",
      "27s - loss: 1.5706 - act_output_loss: 0.5793 - time_output_loss: 0.9913 - act_output_acc: 0.8222 - time_output_acc: 0.2812 - val_loss: 1.5282 - val_act_output_loss: 0.5552 - val_time_output_loss: 0.9731 - val_act_output_acc: 0.8318 - val_time_output_acc: 0.2852\n",
      "Epoch 12/10000\n",
      "21s - loss: 1.5592 - act_output_loss: 0.5760 - time_output_loss: 0.9832 - act_output_acc: 0.8209 - time_output_acc: 0.2813 - val_loss: 1.8928 - val_act_output_loss: 0.5777 - val_time_output_loss: 1.3151 - val_act_output_acc: 0.8253 - val_time_output_acc: 0.2858\n",
      "Epoch 13/10000\n",
      "21s - loss: 1.5557 - act_output_loss: 0.5720 - time_output_loss: 0.9837 - act_output_acc: 0.8208 - time_output_acc: 0.2816 - val_loss: 1.7041 - val_act_output_loss: 0.5807 - val_time_output_loss: 1.1234 - val_act_output_acc: 0.8302 - val_time_output_acc: 0.2858\n",
      "Epoch 14/10000\n",
      "21s - loss: 1.5561 - act_output_loss: 0.5694 - time_output_loss: 0.9867 - act_output_acc: 0.8228 - time_output_acc: 0.2813 - val_loss: 1.5950 - val_act_output_loss: 0.5772 - val_time_output_loss: 1.0178 - val_act_output_acc: 0.8334 - val_time_output_acc: 0.2858\n",
      "Epoch 15/10000\n",
      "23s - loss: 1.5503 - act_output_loss: 0.5662 - time_output_loss: 0.9840 - act_output_acc: 0.8212 - time_output_acc: 0.2813 - val_loss: 1.5766 - val_act_output_loss: 0.5793 - val_time_output_loss: 0.9972 - val_act_output_acc: 0.8242 - val_time_output_acc: 0.2858\n",
      "Epoch 16/10000\n",
      "22s - loss: 1.5554 - act_output_loss: 0.5705 - time_output_loss: 0.9848 - act_output_acc: 0.8203 - time_output_acc: 0.2816 - val_loss: 1.6004 - val_act_output_loss: 0.5850 - val_time_output_loss: 1.0154 - val_act_output_acc: 0.8258 - val_time_output_acc: 0.2852\n",
      "Epoch 17/10000\n",
      "21s - loss: 1.5525 - act_output_loss: 0.5691 - time_output_loss: 0.9834 - act_output_acc: 0.8233 - time_output_acc: 0.2813 - val_loss: 1.5425 - val_act_output_loss: 0.5652 - val_time_output_loss: 0.9773 - val_act_output_acc: 0.8247 - val_time_output_acc: 0.2858\n",
      "Epoch 18/10000\n",
      "21s - loss: 1.5458 - act_output_loss: 0.5649 - time_output_loss: 0.9808 - act_output_acc: 0.8218 - time_output_acc: 0.2815 - val_loss: 1.5418 - val_act_output_loss: 0.5572 - val_time_output_loss: 0.9847 - val_act_output_acc: 0.8302 - val_time_output_acc: 0.2852\n",
      "Epoch 19/10000\n",
      "21s - loss: 1.5530 - act_output_loss: 0.5726 - time_output_loss: 0.9804 - act_output_acc: 0.8207 - time_output_acc: 0.2816 - val_loss: 1.5190 - val_act_output_loss: 0.5588 - val_time_output_loss: 0.9602 - val_act_output_acc: 0.8291 - val_time_output_acc: 0.2852\n",
      "Epoch 20/10000\n",
      "22s - loss: 1.5404 - act_output_loss: 0.5634 - time_output_loss: 0.9771 - act_output_acc: 0.8208 - time_output_acc: 0.2816 - val_loss: 1.5956 - val_act_output_loss: 0.5627 - val_time_output_loss: 1.0329 - val_act_output_acc: 0.8302 - val_time_output_acc: 0.2847\n",
      "Epoch 21/10000\n",
      "21s - loss: 1.5444 - act_output_loss: 0.5649 - time_output_loss: 0.9794 - act_output_acc: 0.8212 - time_output_acc: 0.2816 - val_loss: 1.5063 - val_act_output_loss: 0.5625 - val_time_output_loss: 0.9438 - val_act_output_acc: 0.8296 - val_time_output_acc: 0.2852\n",
      "Epoch 22/10000\n",
      "22s - loss: 1.5394 - act_output_loss: 0.5639 - time_output_loss: 0.9755 - act_output_acc: 0.8237 - time_output_acc: 0.2816 - val_loss: 1.5227 - val_act_output_loss: 0.5639 - val_time_output_loss: 0.9588 - val_act_output_acc: 0.8291 - val_time_output_acc: 0.2852\n",
      "Epoch 23/10000\n",
      "21s - loss: 1.5392 - act_output_loss: 0.5636 - time_output_loss: 0.9756 - act_output_acc: 0.8224 - time_output_acc: 0.2816 - val_loss: 1.5114 - val_act_output_loss: 0.5597 - val_time_output_loss: 0.9517 - val_act_output_acc: 0.8302 - val_time_output_acc: 0.2852\n",
      "Epoch 24/10000\n",
      "21s - loss: 1.5473 - act_output_loss: 0.5713 - time_output_loss: 0.9760 - act_output_acc: 0.8214 - time_output_acc: 0.2817 - val_loss: 1.5355 - val_act_output_loss: 0.5684 - val_time_output_loss: 0.9671 - val_act_output_acc: 0.8225 - val_time_output_acc: 0.2852\n",
      "Epoch 25/10000\n",
      "24s - loss: 1.5352 - act_output_loss: 0.5631 - time_output_loss: 0.9721 - act_output_acc: 0.8226 - time_output_acc: 0.2816 - val_loss: 1.4929 - val_act_output_loss: 0.5497 - val_time_output_loss: 0.9433 - val_act_output_acc: 0.8291 - val_time_output_acc: 0.2852\n",
      "Epoch 26/10000\n",
      "21s - loss: 1.5422 - act_output_loss: 0.5619 - time_output_loss: 0.9803 - act_output_acc: 0.8227 - time_output_acc: 0.2815 - val_loss: 1.5240 - val_act_output_loss: 0.5658 - val_time_output_loss: 0.9582 - val_act_output_acc: 0.8296 - val_time_output_acc: 0.2852\n",
      "Epoch 27/10000\n",
      "21s - loss: 1.5346 - act_output_loss: 0.5594 - time_output_loss: 0.9753 - act_output_acc: 0.8248 - time_output_acc: 0.2816 - val_loss: 1.5111 - val_act_output_loss: 0.5691 - val_time_output_loss: 0.9420 - val_act_output_acc: 0.8291 - val_time_output_acc: 0.2852\n",
      "Epoch 28/10000\n",
      "20s - loss: 1.5308 - act_output_loss: 0.5565 - time_output_loss: 0.9742 - act_output_acc: 0.8212 - time_output_acc: 0.2817 - val_loss: 1.5200 - val_act_output_loss: 0.5663 - val_time_output_loss: 0.9536 - val_act_output_acc: 0.8253 - val_time_output_acc: 0.2852\n",
      "Epoch 29/10000\n",
      "21s - loss: 1.5367 - act_output_loss: 0.5606 - time_output_loss: 0.9762 - act_output_acc: 0.8220 - time_output_acc: 0.2816 - val_loss: 1.5094 - val_act_output_loss: 0.5643 - val_time_output_loss: 0.9450 - val_act_output_acc: 0.8285 - val_time_output_acc: 0.2852\n",
      "Epoch 30/10000\n",
      "20s - loss: 1.5303 - act_output_loss: 0.5555 - time_output_loss: 0.9747 - act_output_acc: 0.8223 - time_output_acc: 0.2816 - val_loss: 1.5101 - val_act_output_loss: 0.5663 - val_time_output_loss: 0.9438 - val_act_output_acc: 0.8318 - val_time_output_acc: 0.2852\n",
      "Epoch 31/10000\n",
      "20s - loss: 1.5343 - act_output_loss: 0.5607 - time_output_loss: 0.9736 - act_output_acc: 0.8237 - time_output_acc: 0.2816 - val_loss: 1.5205 - val_act_output_loss: 0.5673 - val_time_output_loss: 0.9533 - val_act_output_acc: 0.8253 - val_time_output_acc: 0.2852\n",
      "Epoch 32/10000\n",
      "21s - loss: 1.5279 - act_output_loss: 0.5555 - time_output_loss: 0.9724 - act_output_acc: 0.8222 - time_output_acc: 0.2816 - val_loss: 1.5291 - val_act_output_loss: 0.5846 - val_time_output_loss: 0.9445 - val_act_output_acc: 0.8253 - val_time_output_acc: 0.2852\n",
      "Epoch 33/10000\n",
      "22s - loss: 1.5341 - act_output_loss: 0.5596 - time_output_loss: 0.9745 - act_output_acc: 0.8248 - time_output_acc: 0.2816 - val_loss: 1.5089 - val_act_output_loss: 0.5626 - val_time_output_loss: 0.9463 - val_act_output_acc: 0.8274 - val_time_output_acc: 0.2852\n",
      "Epoch 34/10000\n",
      "20s - loss: 1.5275 - act_output_loss: 0.5551 - time_output_loss: 0.9723 - act_output_acc: 0.8239 - time_output_acc: 0.2816 - val_loss: 1.5292 - val_act_output_loss: 0.5742 - val_time_output_loss: 0.9550 - val_act_output_acc: 0.8302 - val_time_output_acc: 0.2858\n",
      "Epoch 35/10000\n",
      "20s - loss: 1.5325 - act_output_loss: 0.5582 - time_output_loss: 0.9743 - act_output_acc: 0.8248 - time_output_acc: 0.2816 - val_loss: 1.5125 - val_act_output_loss: 0.5547 - val_time_output_loss: 0.9577 - val_act_output_acc: 0.8312 - val_time_output_acc: 0.2858\n",
      "Epoch 36/10000\n",
      "20s - loss: 1.5203 - act_output_loss: 0.5503 - time_output_loss: 0.9700 - act_output_acc: 0.8242 - time_output_acc: 0.2816 - val_loss: 1.5159 - val_act_output_loss: 0.5662 - val_time_output_loss: 0.9496 - val_act_output_acc: 0.8242 - val_time_output_acc: 0.2852\n",
      "Epoch 37/10000\n",
      "20s - loss: 1.5179 - act_output_loss: 0.5444 - time_output_loss: 0.9735 - act_output_acc: 0.8256 - time_output_acc: 0.2816 - val_loss: 1.5092 - val_act_output_loss: 0.5646 - val_time_output_loss: 0.9447 - val_act_output_acc: 0.8209 - val_time_output_acc: 0.2858\n",
      "Epoch 38/10000\n",
      "20s - loss: 1.5127 - act_output_loss: 0.5420 - time_output_loss: 0.9707 - act_output_acc: 0.8253 - time_output_acc: 0.2816 - val_loss: 1.5013 - val_act_output_loss: 0.5581 - val_time_output_loss: 0.9432 - val_act_output_acc: 0.8296 - val_time_output_acc: 0.2852\n",
      "Epoch 39/10000\n",
      "21s - loss: 1.5132 - act_output_loss: 0.5439 - time_output_loss: 0.9693 - act_output_acc: 0.8256 - time_output_acc: 0.2816 - val_loss: 1.5055 - val_act_output_loss: 0.5572 - val_time_output_loss: 0.9482 - val_act_output_acc: 0.8263 - val_time_output_acc: 0.2852\n",
      "Epoch 40/10000\n",
      "20s - loss: 1.4997 - act_output_loss: 0.5376 - time_output_loss: 0.9620 - act_output_acc: 0.8269 - time_output_acc: 0.2816 - val_loss: 1.5031 - val_act_output_loss: 0.5569 - val_time_output_loss: 0.9462 - val_act_output_acc: 0.8280 - val_time_output_acc: 0.2852\n",
      "Epoch 41/10000\n",
      "20s - loss: 1.5086 - act_output_loss: 0.5390 - time_output_loss: 0.9696 - act_output_acc: 0.8260 - time_output_acc: 0.2816 - val_loss: 1.5011 - val_act_output_loss: 0.5546 - val_time_output_loss: 0.9465 - val_act_output_acc: 0.8274 - val_time_output_acc: 0.2852\n",
      "Epoch 42/10000\n",
      "20s - loss: 1.4995 - act_output_loss: 0.5321 - time_output_loss: 0.9674 - act_output_acc: 0.8302 - time_output_acc: 0.2816 - val_loss: 1.5061 - val_act_output_loss: 0.5613 - val_time_output_loss: 0.9448 - val_act_output_acc: 0.8274 - val_time_output_acc: 0.2852\n",
      "Epoch 43/10000\n",
      "21s - loss: 1.5025 - act_output_loss: 0.5405 - time_output_loss: 0.9621 - act_output_acc: 0.8269 - time_output_acc: 0.2816 - val_loss: 1.5050 - val_act_output_loss: 0.5592 - val_time_output_loss: 0.9459 - val_act_output_acc: 0.8291 - val_time_output_acc: 0.2852\n",
      "Epoch 44/10000\n",
      "21s - loss: 1.5055 - act_output_loss: 0.5376 - time_output_loss: 0.9679 - act_output_acc: 0.8265 - time_output_acc: 0.2816 - val_loss: 1.5020 - val_act_output_loss: 0.5579 - val_time_output_loss: 0.9441 - val_act_output_acc: 0.8263 - val_time_output_acc: 0.2852\n",
      "Epoch 45/10000\n",
      "21s - loss: 1.4967 - act_output_loss: 0.5331 - time_output_loss: 0.9636 - act_output_acc: 0.8276 - time_output_acc: 0.2816 - val_loss: 1.5137 - val_act_output_loss: 0.5589 - val_time_output_loss: 0.9548 - val_act_output_acc: 0.8247 - val_time_output_acc: 0.2852\n",
      "Epoch 46/10000\n",
      "20s - loss: 1.4986 - act_output_loss: 0.5352 - time_output_loss: 0.9634 - act_output_acc: 0.8306 - time_output_acc: 0.2816 - val_loss: 1.5019 - val_act_output_loss: 0.5569 - val_time_output_loss: 0.9451 - val_act_output_acc: 0.8291 - val_time_output_acc: 0.2852\n",
      "Epoch 47/10000\n",
      "20s - loss: 1.4866 - act_output_loss: 0.5278 - time_output_loss: 0.9588 - act_output_acc: 0.8302 - time_output_acc: 0.2816 - val_loss: 1.5091 - val_act_output_loss: 0.5583 - val_time_output_loss: 0.9507 - val_act_output_acc: 0.8291 - val_time_output_acc: 0.2852\n",
      "Epoch 48/10000\n",
      "28s - loss: 1.4864 - act_output_loss: 0.5257 - time_output_loss: 0.9607 - act_output_acc: 0.8324 - time_output_acc: 0.2816 - val_loss: 1.5106 - val_act_output_loss: 0.5581 - val_time_output_loss: 0.9526 - val_act_output_acc: 0.8296 - val_time_output_acc: 0.2852\n",
      "Epoch 49/10000\n",
      "21s - loss: 1.4841 - act_output_loss: 0.5254 - time_output_loss: 0.9587 - act_output_acc: 0.8305 - time_output_acc: 0.2816 - val_loss: 1.5136 - val_act_output_loss: 0.5628 - val_time_output_loss: 0.9508 - val_act_output_acc: 0.8285 - val_time_output_acc: 0.2852\n",
      "Epoch 50/10000\n",
      "21s - loss: 1.4820 - act_output_loss: 0.5235 - time_output_loss: 0.9585 - act_output_acc: 0.8316 - time_output_acc: 0.2816 - val_loss: 1.5180 - val_act_output_loss: 0.5663 - val_time_output_loss: 0.9517 - val_act_output_acc: 0.8269 - val_time_output_acc: 0.2852\n",
      "Epoch 51/10000\n",
      "21s - loss: 1.4855 - act_output_loss: 0.5254 - time_output_loss: 0.9601 - act_output_acc: 0.8324 - time_output_acc: 0.2816 - val_loss: 1.5107 - val_act_output_loss: 0.5629 - val_time_output_loss: 0.9478 - val_act_output_acc: 0.8280 - val_time_output_acc: 0.2852\n",
      "Epoch 52/10000\n",
      "21s - loss: 1.4817 - act_output_loss: 0.5209 - time_output_loss: 0.9608 - act_output_acc: 0.8327 - time_output_acc: 0.2816 - val_loss: 1.5177 - val_act_output_loss: 0.5647 - val_time_output_loss: 0.9530 - val_act_output_acc: 0.8280 - val_time_output_acc: 0.2852\n",
      "Epoch 53/10000\n",
      "21s - loss: 1.4867 - act_output_loss: 0.5255 - time_output_loss: 0.9612 - act_output_acc: 0.8295 - time_output_acc: 0.2815 - val_loss: 1.5091 - val_act_output_loss: 0.5642 - val_time_output_loss: 0.9449 - val_act_output_acc: 0.8258 - val_time_output_acc: 0.2852\n",
      "Epoch 54/10000\n",
      "21s - loss: 1.4752 - act_output_loss: 0.5182 - time_output_loss: 0.9571 - act_output_acc: 0.8343 - time_output_acc: 0.2816 - val_loss: 1.5095 - val_act_output_loss: 0.5637 - val_time_output_loss: 0.9458 - val_act_output_acc: 0.8296 - val_time_output_acc: 0.2852\n",
      "Epoch 55/10000\n",
      "21s - loss: 1.4807 - act_output_loss: 0.5240 - time_output_loss: 0.9567 - act_output_acc: 0.8306 - time_output_acc: 0.2816 - val_loss: 1.5094 - val_act_output_loss: 0.5634 - val_time_output_loss: 0.9460 - val_act_output_acc: 0.8291 - val_time_output_acc: 0.2852\n",
      "Epoch 56/10000\n",
      "21s - loss: 1.4737 - act_output_loss: 0.5141 - time_output_loss: 0.9596 - act_output_acc: 0.8329 - time_output_acc: 0.2816 - val_loss: 1.5134 - val_act_output_loss: 0.5663 - val_time_output_loss: 0.9472 - val_act_output_acc: 0.8263 - val_time_output_acc: 0.2852\n",
      "Epoch 57/10000\n",
      "22s - loss: 1.4672 - act_output_loss: 0.5139 - time_output_loss: 0.9534 - act_output_acc: 0.8327 - time_output_acc: 0.2815 - val_loss: 1.5107 - val_act_output_loss: 0.5639 - val_time_output_loss: 0.9468 - val_act_output_acc: 0.8274 - val_time_output_acc: 0.2852\n",
      "Epoch 58/10000\n",
      "21s - loss: 1.4716 - act_output_loss: 0.5170 - time_output_loss: 0.9546 - act_output_acc: 0.8335 - time_output_acc: 0.2815 - val_loss: 1.5132 - val_act_output_loss: 0.5655 - val_time_output_loss: 0.9477 - val_act_output_acc: 0.8274 - val_time_output_acc: 0.2852\n",
      "Epoch 59/10000\n",
      "21s - loss: 1.4679 - act_output_loss: 0.5115 - time_output_loss: 0.9564 - act_output_acc: 0.8309 - time_output_acc: 0.2816 - val_loss: 1.5131 - val_act_output_loss: 0.5640 - val_time_output_loss: 0.9491 - val_act_output_acc: 0.8291 - val_time_output_acc: 0.2852\n",
      "Epoch 60/10000\n",
      "21s - loss: 1.4611 - act_output_loss: 0.5110 - time_output_loss: 0.9502 - act_output_acc: 0.8333 - time_output_acc: 0.2815 - val_loss: 1.5142 - val_act_output_loss: 0.5681 - val_time_output_loss: 0.9461 - val_act_output_acc: 0.8263 - val_time_output_acc: 0.2852\n",
      "Epoch 61/10000\n",
      "21s - loss: 1.4606 - act_output_loss: 0.5101 - time_output_loss: 0.9505 - act_output_acc: 0.8328 - time_output_acc: 0.2816 - val_loss: 1.5168 - val_act_output_loss: 0.5703 - val_time_output_loss: 0.9465 - val_act_output_acc: 0.8258 - val_time_output_acc: 0.2852\n",
      "Epoch 62/10000\n",
      "24s - loss: 1.4602 - act_output_loss: 0.5086 - time_output_loss: 0.9516 - act_output_acc: 0.8347 - time_output_acc: 0.2816 - val_loss: 1.5172 - val_act_output_loss: 0.5688 - val_time_output_loss: 0.9484 - val_act_output_acc: 0.8263 - val_time_output_acc: 0.2852\n",
      "Epoch 63/10000\n",
      "21s - loss: 1.4649 - act_output_loss: 0.5077 - time_output_loss: 0.9572 - act_output_acc: 0.8356 - time_output_acc: 0.2816 - val_loss: 1.5138 - val_act_output_loss: 0.5701 - val_time_output_loss: 0.9436 - val_act_output_acc: 0.8242 - val_time_output_acc: 0.2852\n",
      "Epoch 64/10000\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-7-de45709ec859>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     35\u001b[0m \u001b[0;31m#fit\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     36\u001b[0m model.fit(X, {'act_output':y_a, 'time_output':y_t}, validation_split=0.2, verbose=2, \n\u001b[0;32m---> 37\u001b[0;31m           callbacks=[early_stopping, model_checkpoint, lr_reducer, history], batch_size=16, epochs=10000)\n\u001b[0m",
      "\u001b[0;32m/home/hoang/miniconda2/envs/pydata/lib/python3.5/site-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, **kwargs)\u001b[0m\n\u001b[1;32m   1496\u001b[0m                               \u001b[0mval_f\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mval_f\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mval_ins\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mval_ins\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mshuffle\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mshuffle\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1497\u001b[0m                               \u001b[0mcallback_metrics\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcallback_metrics\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1498\u001b[0;31m                               initial_epoch=initial_epoch)\n\u001b[0m\u001b[1;32m   1499\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1500\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mevaluate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m32\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msample_weight\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/hoang/miniconda2/envs/pydata/lib/python3.5/site-packages/keras/engine/training.py\u001b[0m in \u001b[0;36m_fit_loop\u001b[0;34m(self, f, ins, out_labels, batch_size, epochs, verbose, callbacks, val_f, val_ins, shuffle, callback_metrics, initial_epoch)\u001b[0m\n\u001b[1;32m   1150\u001b[0m                 \u001b[0mbatch_logs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'size'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch_ids\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1151\u001b[0m                 \u001b[0mcallbacks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_batch_begin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch_index\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_logs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1152\u001b[0;31m                 \u001b[0mouts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mins_batch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1153\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mouts\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1154\u001b[0m                     \u001b[0mouts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mouts\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/hoang/miniconda2/envs/pydata/lib/python3.5/site-packages/keras/backend/theano_backend.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m   1156\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__call__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1157\u001b[0m         \u001b[0;32massert\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mlist\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtuple\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1158\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfunction\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1159\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1160\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/hoang/miniconda2/envs/pydata/lib/python3.5/site-packages/theano/compile/function_module.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    882\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    883\u001b[0m             \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m\u001b[0;31m\\\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 884\u001b[0;31m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0moutput_subset\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32melse\u001b[0m\u001b[0;31m\\\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    885\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput_subset\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0moutput_subset\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    886\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/hoang/miniconda2/envs/pydata/lib/python3.5/site-packages/theano/scan_module/scan_op.py\u001b[0m in \u001b[0;36mrval\u001b[0;34m(p, i, o, n, allow_gc)\u001b[0m\n\u001b[1;32m    987\u001b[0m         def rval(p=p, i=node_input_storage, o=node_output_storage, n=node,\n\u001b[1;32m    988\u001b[0m                  allow_gc=allow_gc):\n\u001b[0;32m--> 989\u001b[0;31m             \u001b[0mr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mp\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mo\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    990\u001b[0m             \u001b[0;32mfor\u001b[0m \u001b[0mo\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mnode\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    991\u001b[0m                 \u001b[0mcompute_map\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mo\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/hoang/miniconda2/envs/pydata/lib/python3.5/site-packages/theano/scan_module/scan_op.py\u001b[0m in \u001b[0;36mp\u001b[0;34m(node, args, outs)\u001b[0m\n\u001b[1;32m    976\u001b[0m                                                 \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    977\u001b[0m                                                 \u001b[0mouts\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 978\u001b[0;31m                                                 self, node)\n\u001b[0m\u001b[1;32m    979\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mImportError\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtheano\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgof\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcmodule\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mMissingGXX\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    980\u001b[0m             \u001b[0mp\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexecute\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mtheano/scan_module/scan_perform.pyx\u001b[0m in \u001b[0;36mtheano.scan_module.scan_perform.perform (/home/hoang/.theano/compiledir_Linux-4.8--generic-x86_64-with-debian-stretch-sid-x86_64-3.5.3-64/scan_perform/mod.cpp:7110)\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32m/home/hoang/miniconda2/envs/pydata/lib/python3.5/site-packages/theano/tensor/type.py\u001b[0m in \u001b[0;36mvalue_zeros\u001b[0;34m(self, shape)\u001b[0m\n\u001b[1;32m    549\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    550\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 551\u001b[0;31m     \u001b[0;32mdef\u001b[0m \u001b[0mvalue_zeros\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mshape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    552\u001b[0m         \"\"\"\n\u001b[1;32m    553\u001b[0m         \u001b[0mCreate\u001b[0m \u001b[0man\u001b[0m \u001b[0mnumpy\u001b[0m \u001b[0mndarray\u001b[0m \u001b[0mfull\u001b[0m \u001b[0mof\u001b[0m \u001b[0;36m0\u001b[0m \u001b[0mvalues\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "print('Build model BLSTM...')\n",
    "\n",
    "main_input = Input(shape=(maxlen, num_features), name='main_input')\n",
    "\n",
    "# shared layer\n",
    "l1 = Bidirectional(LSTM(50, return_sequences=True, kernel_initializer=\"glorot_uniform\", implementation=2))(main_input) # the shared layer\n",
    "b1 = BatchNormalization()(l1)\n",
    "\n",
    "# layers\n",
    "l2_1 = Bidirectional(LSTM(50, return_sequences=False, kernel_initializer=\"glorot_uniform\", implementation=2, dropout=0.2))(b1) # the layer specialized in activity prediction\n",
    "b2_1 = BatchNormalization()(l2_1)\n",
    "\n",
    "l2_2 = Bidirectional(LSTM(50, return_sequences=False, kernel_initializer=\"glorot_uniform\", implementation=2))(b1) # the layer specialized in time prediction\n",
    "b2_2 = BatchNormalization()(l2_2)\n",
    "\n",
    "act_output = Dense(len(targetchartoindice), kernel_initializer='glorot_uniform', activation='softmax', name='act_output')(b2_1)\n",
    "time_output = Dense(1, kernel_initializer='glorot_uniform', name='time_output')(b2_2)\n",
    "\n",
    "model = Model(inputs=[main_input], outputs=[act_output, time_output])\n",
    "\n",
    "#compilations\n",
    "opt = optimizers.Nadam(lr=0.002, beta_1=0.9, beta_2=0.999, epsilon=1e-08, schedule_decay=0.004, clipvalue=3)\n",
    "model.compile(loss={'act_output':'categorical_crossentropy', 'time_output':'mean_absolute_error'}, \n",
    "              optimizer=opt, metrics=['accuracy'])\n",
    "\n",
    "#callbacks\n",
    "early_stopping = EarlyStopping(monitor='val_loss', patience=500)\n",
    "model_checkpoint = ModelCheckpoint(args.outputdir + 'model_{epoch:02d}-{val_loss:.2f}.h5', \n",
    "                                   monitor='val_loss', verbose=0, save_best_only=True, \n",
    "                                   save_weights_only=False, mode='auto')\n",
    "lr_reducer = ReduceLROnPlateau(monitor='val_loss', factor=0.5, patience=10, \n",
    "                               verbose=0, mode='auto', epsilon=0.0001, cooldown=0, min_lr=0)\n",
    "history = History()\n",
    "\n",
    "#fit\n",
    "model.fit(X, {'act_output':y_a, 'time_output':y_t}, validation_split=0.2, verbose=2, \n",
    "          callbacks=[early_stopping, model_checkpoint, lr_reducer, history], batch_size=16, epochs=10000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "history.history.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "# summarize history for activity accuracy\n",
    "plt.plot(history.history['act_output_acc'])\n",
    "plt.plot(history.history['val_act_output_acc'])\n",
    "plt.title('Activity accuracy')\n",
    "plt.ylabel('accuracy')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['train', 'val'], loc='upper right')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# summarize history for activity loss\n",
    "plt.plot(history.history['act_output_loss'])\n",
    "plt.plot(history.history['val_act_output_loss'])\n",
    "plt.title('Activity loss')\n",
    "plt.ylabel('loss')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['train', 'val'], loc='upper right')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "# summarize history for time loss\n",
    "plt.plot(history.history['time_output_loss'])\n",
    "plt.plot(history.history['val_time_output_loss'])\n",
    "plt.title('Time loss')\n",
    "plt.ylabel('loss')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['train', 'val'], loc='upper right')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "# summarize history for model loss\n",
    "plt.plot(history.history['loss'])\n",
    "plt.plot(history.history['val_loss'])\n",
    "plt.title('Model loss')\n",
    "plt.ylabel('loss')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['train', 'val'], loc='upper right')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.3"
  },
  "toc": {
   "colors": {
    "hover_highlight": "#DAA520",
    "running_highlight": "#FF0000",
    "selected_highlight": "#FFD700"
   },
   "moveMenuLeft": true,
   "nav_menu": {
    "height": "66px",
    "width": "252px"
   },
   "navigate_menu": true,
   "number_sections": true,
   "sideBar": true,
   "threshold": 4,
   "toc_cell": false,
   "toc_section_display": "block",
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
