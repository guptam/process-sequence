{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import argparse\n",
    "import time\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import pickle\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.init as init\n",
    "from torch.nn.utils import clip_grad_norm\n",
    "from torch.autograd import Variable\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader\n",
    "import torchvision.datasets as datasets\n",
    "import torchvision.transforms as transforms\n",
    "from torchvision.utils import save_image\n",
    "from torchnet.meter import AverageValueMeter"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "# Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "name = 'helpdesk'\n",
    "parser = {\n",
    "    'inputdir': '../input/{}/'.format(name),   \n",
    "    'outputdir': './output_files/{0}/'.format(name),\n",
    "}\n",
    "\n",
    "dirs = argparse.Namespace(**parser)\n",
    "\n",
    "if not os.path.isdir(dirs.outputdir):\n",
    "    os.makedirs(dirs.outputdir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "# load parameters\n",
    "with open(dirs.inputdir + 'parameters.pkl', \"rb\") as f:\n",
    "    maxlen = pickle.load(f)\n",
    "    num_features = pickle.load(f)\n",
    "    chartoindice = pickle.load(f)\n",
    "    targetchartoindice = pickle.load(f)\n",
    "    divisor = pickle.load(f)\n",
    "    divisor2 = pickle.load(f)\n",
    "\n",
    "# load data\n",
    "with open(dirs.inputdir + 'preprocessed_data.pkl', \"rb\") as f:\n",
    "    X = pickle.load(f)\n",
    "    y_a = pickle.load(f)\n",
    "    y_t = pickle.load(f)\n",
    "    X_test = pickle.load(f)\n",
    "    y_a_test = pickle.load(f)\n",
    "    y_t_test = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "#X = np.reshape(X, (X.shape[1],X.shape[0],X.shape[2]))\n",
    "#X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "args = {\n",
    "    'epochs': 100,\n",
    "    'batch_size': 64,\n",
    "    'lr': 0.0002,\n",
    "    'optim': 'adam',\n",
    "    'beta1': 0.5,\n",
    "    'weight_decay': 1e-4,\n",
    "    'features': X.shape[2],\n",
    "    'h_dim1': 100,\n",
    "    'h_dim2a': 100,\n",
    "    'h_dim2t': 100,\n",
    "    'num_layer1': 1,\n",
    "    'num_layer2a': 1,\n",
    "    'num_layer2t': 1,\n",
    "    'outdim_a': len(targetchartoindice), \n",
    "    'outdim_t': 1,\n",
    "    'clip': 3,\n",
    "    'cuda': False,\n",
    "    'seed': 7,\n",
    "    'workers': 2,\n",
    "}\n",
    "\n",
    "args = argparse.Namespace(**args)\n",
    "\n",
    "torch.manual_seed(args.seed)\n",
    "if args.cuda:\n",
    "    torch.cuda.manual_seed(args.seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "data_loader_x = DataLoader(dataset=X, batch_size=args.batch_size, shuffle=False, num_workers=args.workers)\n",
    "data_loader_y_a = DataLoader(dataset=y_a, batch_size=args.batch_size, shuffle=False, num_workers=args.workers)\n",
    "data_loader_y_t = DataLoader(dataset=y_t, batch_size=args.batch_size, shuffle=False, num_workers=args.workers)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "# Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "class LSTMModel(nn.Module):\n",
    "    \n",
    "    def __init__(self, features, h_dim1, h_dim2a, h_dim2t, num_layer1, \n",
    "                 num_layer2a, num_layer2t, outdim_a, outdim_t,\n",
    "                 batch_size=64, seq_length=15, cuda=args.cuda):\n",
    "        super(LSTMModel, self).__init__()\n",
    "        # no seq length when init LSTM \n",
    "        self.lstm1 = nn.LSTM(features, h_dim1, num_layer1)\n",
    "        self.lstm2a = nn.LSTM(h_dim1, h_dim2a, num_layer2a)\n",
    "        self.lstm2t = nn.LSTM(h_dim1, h_dim2t, num_layer2t)\n",
    "        self.linear3a = nn.Linear(h_dim2a, outdim_a)\n",
    "        self.linear3t = nn.Linear(h_dim2t, outdim_t)\n",
    "        \n",
    "        self.num_layer1 = num_layer1\n",
    "        self.num_layer2a = num_layer2a\n",
    "        self.num_layer2t = num_layer2t\n",
    "        self.h_dim1 = h_dim1\n",
    "        self.h_dim2a = h_dim2a\n",
    "        self.h_dim2t = h_dim2t\n",
    "        self.batch_size = batch_size\n",
    "        self.seq_length = seq_length\n",
    "        self.cuda = cuda\n",
    "\n",
    "    def forward(self, x):\n",
    "        assert (x.size(1) == self.batch_size)\n",
    "        \n",
    "        tt = torch.cuda if self.cuda else torch\n",
    "        \n",
    "        # shared layer\n",
    "        h1 = Variable(tt.FloatTensor(self.num_layer1, x.size(1), self.h_dim1).zero_(), requires_grad=False)\n",
    "        c1 = Variable(tt.FloatTensor(self.num_layer1, x.size(1), self.h_dim1).zero_(), requires_grad=False)\n",
    "        out1, _ = self.lstm1(x, (h1, c1)) # out1 dim : seq x batch x h_dim\n",
    "        \n",
    "        # activity layer\n",
    "        h2a = Variable(tt.FloatTensor(self.num_layer2a, out1.size(1), self.h_dim2a).zero_(), requires_grad=False)\n",
    "        c2a = Variable(tt.FloatTensor(self.num_layer2a, out1.size(1), self.h_dim2a).zero_(), requires_grad=False)\n",
    "        _, (h_t2a, _) = self.lstm2a(out1, (h2a, c2a))\n",
    "        h_t2a = h_t2a.squeeze(0) # remove size 0: h_t2a dim: numlayer x batch x hidden --> batch x hidden\n",
    "        \n",
    "        # time layer\n",
    "        h2t = Variable(tt.FloatTensor(self.num_layer2t, out1.size(1), self.h_dim2t).zero_(), requires_grad=False)\n",
    "        c2t = Variable(tt.FloatTensor(self.num_layer2t, out1.size(1), self.h_dim2t).zero_(), requires_grad=False)\n",
    "        _, (h_t2t, _) = self.lstm2t(out1, (h2t, c2t))\n",
    "        h_t2t = h_t2t.squeeze(0) # remove size 0\n",
    "        \n",
    "        # output\n",
    "        out_a = self.linear3a(h_t2a)\n",
    "        out_t = self.linear3t(h_t2t)\n",
    "        return (out_a, out_t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "model = LSTMModel(features=args.features, h_dim1=args.h_dim1, h_dim2a=args.h_dim2a, h_dim2t=args.h_dim2t, \n",
    "                  num_layer1=args.num_layer1, num_layer2a=args.num_layer2a, num_layer2t=args.num_layer2t, \n",
    "                  outdim_a=args.outdim_a, outdim_t=args.outdim_t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<bound method Module.parameters of LSTMModel (\n",
       "  (lstm1): LSTM(14, 100)\n",
       "  (lstm2a): LSTM(100, 100)\n",
       "  (lstm2t): LSTM(100, 100)\n",
       "  (linear3a): Linear (100 -> 10)\n",
       "  (linear3t): Linear (100 -> 1)\n",
       ")>"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.parameters"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "# Utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "def adjust_learning_rate(optimizer, lr_decay):\n",
    "    for param_group in optimizer.param_groups:\n",
    "        param_group['lr'] *= lr_decay"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "def save_checkpoint(state, is_best, filename=\"checkpoint.pth.tar\"):\n",
    "    checkpoint_filepath = os.path.join(dirs.outputdir, filename)\n",
    "    torch.save(state, checkpoint_filepath)\n",
    "    if is_best:\n",
    "        shutil.copyfile(checkpoint_filepath, model_best_filepath)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def accuracy(outputs, targets):\n",
    "    _, predicted = torch.max(outputs.data, 1)\n",
    "    total += targets.size(0)\n",
    "    #correct += predicted.eq(targets.data).cpu().sum()\n",
    "    correct += (predicted == labels).sum()\n",
    "    return correct*100/total"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "class Results():\n",
    "    def __init__(self, results_path):\n",
    "        self.losses_a = []\n",
    "        self.losses_t = []\n",
    "        self.losses_model = []\n",
    "        self.accuracy_a = []\n",
    "        self.results_path = results_path\n",
    "    \n",
    "    def save_losses(self, loss_a, loss_t, loss_model, accuracy):\n",
    "        self.losses_a.append(loss_a)\n",
    "        self.losses_t.append(loss_t)\n",
    "        self.losses_model.append(loss_model)\n",
    "        self.accuracy_a.append(accuracy)\n",
    "        \n",
    "    def save_to_disk(self):\n",
    "        f = open(self.results_path + \"losses_a.pkl\", \"wb\")\n",
    "        pickle.dump(self.D_losses, f)\n",
    "        f= open(self.results_path + \"losses_t.pkl\", \"wb\")\n",
    "        pickle.dump(self.G_losses, f)\n",
    "        f = open(self.results_path + \"losses_model.pkl\", \"wb\")\n",
    "        pickle.dump(self.D_reals, f)\n",
    "        f = open(self.results_path + \"accuracy_a.pkl\", \"wb\")\n",
    "        pickle.dump(self.D_fakes, f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "# Define train/validate function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "def train(epoch, data_loader_x, data_loader_y_a, data_loader_y_t, model, optimizer, criterion_a, criterion_t, args, result_losses):\n",
    "    print(\"=> EPOCH {}\".format(epoch))\n",
    "    losses_a = AverageValueMeter()\n",
    "    losses_t = AverageValueMeter()\n",
    "    losses_model = AverageValueMeter()\n",
    "    accuracy_a = AverageValueMeter()\n",
    "    \n",
    "    tt = torch.cuda if args.cuda else torch\n",
    "    model.train()\n",
    "    start = time.time()\n",
    "    \n",
    "    for inputs, y_a, y_t in zip(data_loader_x, data_loader_y_a, data_loader_y_t): # shape: (batch_size, seq len, features)\n",
    "        # input\n",
    "        batch_size = inputs.size(0)\n",
    "        inputs = np.reshape(X, (X.shape[1],X.shape[0],X.shape[2])) # shape: (seq len, batch_size, features)\n",
    "        inputs = tt.FloatTensor(inputs)\n",
    "        y_a = tt.FloatTensor(y_a)\n",
    "        y_t = tt.FloatTensor(y_t)\n",
    "        \n",
    "        if args.cuda:\n",
    "            inputs = inputs.cuda()\n",
    "            y_a = y_a.cuda()\n",
    "            y_t = y_t.cuda()\n",
    "            \n",
    "        inputs = Variable(inputs)\n",
    "        y_a = Variable(y_a)\n",
    "        y_t = Variable(y_t)\n",
    "        \n",
    "        # output\n",
    "        output_a, output_t = model(inputs)\n",
    "        \n",
    "        # loss\n",
    "        loss_a = criterion_a(output_a, y_a)\n",
    "        loss_t = criterion_t(output_t, y_t)\n",
    "        loss_model = loss_a + loss_t\n",
    "        accuracy = accuracy(output_a, y_a)\n",
    "        \n",
    "        # update\n",
    "        model.zero_grad()\n",
    "        loss_model.backward()\n",
    "        clip_grad_norm(model.parameters(), args.clip, 'inf')\n",
    "        optimizer.step()\n",
    "        \n",
    "        losses_a.add(loss_a.data.cpu()[0] * batch_size, batch_size)\n",
    "        losses_t.add(loss_t.data.cpu()[0] * batch_size, batch_size)\n",
    "        losses_model.add(loss_model.data.cpu()[0] * batch_size, batch_size)\n",
    "      \n",
    "    # Show and save result after each epoch\n",
    "    print(\"=> EPOCH {} | Time: {}s | Activity loss: {:.4f} | Time loss: {:.4f}\"\n",
    "          \" | Model loss: {:.4f} | Activity accuracy: {:.4f}\"\n",
    "          .format(epoch, round(time.time()-start), losses_a.value()[0],\n",
    "                  losses_t.value()[0], losses_model.value()[0], accuracy_a.value()[0]))\n",
    "    \n",
    "    result_losses.save_losses(losses_a.value()[0], losses_t.value()[0], \n",
    "                              losses_model.value()[0], accuracy_a.value()[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "def validate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "def test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "# Loss function and optimizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "# define loss function\n",
    "criterion_a = nn.CrossEntropyLoss()\n",
    "criterion_t = nn.MSELoss()\n",
    "criterion = [criterion_a, criterion_t]\n",
    "\n",
    "# define optimizer\n",
    "if args.cuda:\n",
    "    criterion.cuda()\n",
    "\n",
    "# define optimizer\n",
    "if args.optim == \"sgd\":\n",
    "    optimizer = optim.SGD(model.parameters(),\n",
    "                          lr=args.lr,\n",
    "                          momentum=args.momentum,\n",
    "                          weight_decay=args.weight_decay)\n",
    "    \n",
    "elif args.optim == \"adam\":\n",
    "    optimizer = optim.Adam(model.parameters(),\n",
    "                           lr=args.lr,\n",
    "                           weight_decay=args.weight_decay)\n",
    "    \n",
    "elif args.optim == \"rmsprop\":\n",
    "    optimizer = optim.RMSprop(model.parameters(),\n",
    "                              lr=args.lr,\n",
    "                              weight_decay=args.weight_decay)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "# Train model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=> EPOCH 1\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "torch.FloatTensor constructor received an invalid combination of arguments - got (torch.DoubleTensor), but expected one of:\n * no arguments\n * (int ...)\n      didn't match because some of the arguments have invalid types: (\u001b[31;1mtorch.DoubleTensor\u001b[0m)\n * (torch.FloatTensor viewed_tensor)\n      didn't match because some of the arguments have invalid types: (\u001b[31;1mtorch.DoubleTensor\u001b[0m)\n * (torch.Size size)\n      didn't match because some of the arguments have invalid types: (\u001b[31;1mtorch.DoubleTensor\u001b[0m)\n * (torch.FloatStorage data)\n      didn't match because some of the arguments have invalid types: (\u001b[31;1mtorch.DoubleTensor\u001b[0m)\n * (Sequence data)\n      didn't match because some of the arguments have invalid types: (\u001b[31;1mtorch.DoubleTensor\u001b[0m)\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-32-fb7272ac8f9d>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mresult_losses\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mResults\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdirs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moutputdir\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mepoch\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mepochs\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m     \u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mepoch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata_loader_x\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata_loader_y_a\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata_loader_y_t\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptimizer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcriterion_a\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcriterion_t\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult_losses\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m     \u001b[0;32mbreak\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-30-d414738ca948>\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(epoch, data_loader_x, data_loader_y_a, data_loader_y_t, model, optimizer, criterion_a, criterion_t, args, result_losses)\u001b[0m\n\u001b[1;32m     16\u001b[0m         \u001b[0minputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mFloatTensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m         \u001b[0my_a\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mFloatTensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_a\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 18\u001b[0;31m         \u001b[0my_t\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mFloatTensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_t\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     19\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     20\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcuda\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: torch.FloatTensor constructor received an invalid combination of arguments - got (torch.DoubleTensor), but expected one of:\n * no arguments\n * (int ...)\n      didn't match because some of the arguments have invalid types: (\u001b[31;1mtorch.DoubleTensor\u001b[0m)\n * (torch.FloatTensor viewed_tensor)\n      didn't match because some of the arguments have invalid types: (\u001b[31;1mtorch.DoubleTensor\u001b[0m)\n * (torch.Size size)\n      didn't match because some of the arguments have invalid types: (\u001b[31;1mtorch.DoubleTensor\u001b[0m)\n * (torch.FloatStorage data)\n      didn't match because some of the arguments have invalid types: (\u001b[31;1mtorch.DoubleTensor\u001b[0m)\n * (Sequence data)\n      didn't match because some of the arguments have invalid types: (\u001b[31;1mtorch.DoubleTensor\u001b[0m)\n"
     ]
    }
   ],
   "source": [
    "result_losses = Results(dirs.outputdir)\n",
    "for epoch in range(1, args.epochs+1):\n",
    "    train(epoch, data_loader_x, data_loader_y_a, data_loader_y_t, model, optimizer, criterion_a, criterion_t, args, result_losses)\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([  7.11185218e-05,   8.24970111e-01,   0.00000000e+00, ...,\n",
       "         7.11185218e-05,   4.12487426e-04,   0.00000000e+00])"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_t"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\n",
       "  0.0001\n",
       "  0.8250\n",
       "  0.0000\n",
       "   ⋮    \n",
       "  0.0001\n",
       "  0.0004\n",
       "  0.0000\n",
       "[torch.FloatTensor of size 9181]"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.FloatTensor(y_t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([  7.11185218e-05,   8.24970111e-01,   0.00000000e+00, ...,\n",
       "         7.11185218e-05,   4.12487426e-04,   0.00000000e+00])"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_t"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  },
  "toc": {
   "colors": {
    "hover_highlight": "#DAA520",
    "running_highlight": "#FF0000",
    "selected_highlight": "#FFD700"
   },
   "moveMenuLeft": true,
   "nav_menu": {
    "height": "12px",
    "width": "252px"
   },
   "navigate_menu": true,
   "number_sections": true,
   "sideBar": true,
   "threshold": 4,
   "toc_cell": false,
   "toc_section_display": "block",
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
