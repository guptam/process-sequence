{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is the original model, run in Python 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import argparse\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using Theano backend.\n"
     ]
    }
   ],
   "source": [
    "from keras.models import Sequential, Model\n",
    "from keras.layers.core import Dense\n",
    "from keras.layers.recurrent import LSTM, GRU, SimpleRNN\n",
    "from keras.layers import Input\n",
    "from keras.layers.wrappers import Bidirectional\n",
    "from keras.utils.data_utils import get_file\n",
    "from keras.regularizers import WeightRegularizer\n",
    "from keras.optimizers import Nadam\n",
    "from keras.callbacks import EarlyStopping, ModelCheckpoint, ReduceLROnPlateau\n",
    "from keras.layers.normalization import BatchNormalization\n",
    "from theano.ifelse import ifelse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "name = 'helpdesk'\n",
    "args = {\n",
    "    'inputdir': '../input/{}/'.format(name),   \n",
    "    'outputdir': './output_files/{}/'.format(name)\n",
    "}\n",
    "\n",
    "args = argparse.Namespace(**args)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "if not os.path.isdir(args.outputdir):\n",
    "    os.makedirs(args.outputdir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "with open(args.inputdir + 'parameters.pkl', \"rb\") as f:\n",
    "    maxlen = pickle.load(f)\n",
    "    num_features = pickle.load(f)\n",
    "    chartoindice = pickle.load(f)\n",
    "    targetchartoindice = pickle.load(f)\n",
    "    divisor = pickle.load(f)\n",
    "    divisor2 = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "with open(args.inputdir + 'preprocessed_data.pkl', \"rb\") as f:\n",
    "    X = pickle.load(f)\n",
    "    y_a = pickle.load(f)\n",
    "    y_t = pickle.load(f)\n",
    "    X_test = pickle.load(f)\n",
    "    y_a_test = pickle.load(f)\n",
    "    y_t_test = pickle.load(f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Build model...\n",
      "Train on 7344 samples, validate on 1837 samples\n",
      "Epoch 1/500\n",
      "17s - loss: 2.1357 - act_output_loss: 0.9691 - time_output_loss: 1.1666 - val_loss: 1.7252 - val_act_output_loss: 0.6687 - val_time_output_loss: 1.0565\n",
      "Epoch 2/500\n",
      "18s - loss: 1.7551 - act_output_loss: 0.7126 - time_output_loss: 1.0425 - val_loss: 1.5890 - val_act_output_loss: 0.6077 - val_time_output_loss: 0.9813\n",
      "Epoch 3/500\n",
      "18s - loss: 1.7108 - act_output_loss: 0.6927 - time_output_loss: 1.0181 - val_loss: 1.6556 - val_act_output_loss: 0.6539 - val_time_output_loss: 1.0017\n",
      "Epoch 4/500\n",
      "17s - loss: 1.6910 - act_output_loss: 0.6768 - time_output_loss: 1.0142 - val_loss: 1.5662 - val_act_output_loss: 0.5818 - val_time_output_loss: 0.9845\n",
      "Epoch 5/500\n",
      "17s - loss: 1.6850 - act_output_loss: 0.6777 - time_output_loss: 1.0073 - val_loss: 1.5739 - val_act_output_loss: 0.5804 - val_time_output_loss: 0.9935\n",
      "Epoch 6/500\n",
      "17s - loss: 1.6667 - act_output_loss: 0.6627 - time_output_loss: 1.0040 - val_loss: 1.5550 - val_act_output_loss: 0.5807 - val_time_output_loss: 0.9743\n",
      "Epoch 7/500\n",
      "18s - loss: 1.6550 - act_output_loss: 0.6549 - time_output_loss: 1.0001 - val_loss: 1.5556 - val_act_output_loss: 0.5653 - val_time_output_loss: 0.9903\n",
      "Epoch 8/500\n",
      "18s - loss: 1.6509 - act_output_loss: 0.6504 - time_output_loss: 1.0006 - val_loss: 1.5315 - val_act_output_loss: 0.5706 - val_time_output_loss: 0.9608\n",
      "Epoch 9/500\n",
      "18s - loss: 1.6551 - act_output_loss: 0.6552 - time_output_loss: 0.9999 - val_loss: 1.5626 - val_act_output_loss: 0.5794 - val_time_output_loss: 0.9832\n",
      "Epoch 10/500\n",
      "17s - loss: 1.6471 - act_output_loss: 0.6499 - time_output_loss: 0.9971 - val_loss: 1.5291 - val_act_output_loss: 0.5643 - val_time_output_loss: 0.9647\n",
      "Epoch 11/500\n",
      "18s - loss: 1.6448 - act_output_loss: 0.6467 - time_output_loss: 0.9981 - val_loss: 1.5253 - val_act_output_loss: 0.5608 - val_time_output_loss: 0.9645\n",
      "Epoch 12/500\n",
      "18s - loss: 1.6471 - act_output_loss: 0.6516 - time_output_loss: 0.9955 - val_loss: 1.5351 - val_act_output_loss: 0.5728 - val_time_output_loss: 0.9623\n",
      "Epoch 13/500\n",
      "17s - loss: 1.6402 - act_output_loss: 0.6424 - time_output_loss: 0.9978 - val_loss: 1.5350 - val_act_output_loss: 0.5630 - val_time_output_loss: 0.9721\n",
      "Epoch 14/500\n",
      "17s - loss: 1.6318 - act_output_loss: 0.6390 - time_output_loss: 0.9928 - val_loss: 1.5252 - val_act_output_loss: 0.5676 - val_time_output_loss: 0.9576\n",
      "Epoch 15/500\n",
      "24s - loss: 1.6393 - act_output_loss: 0.6454 - time_output_loss: 0.9939 - val_loss: 1.5285 - val_act_output_loss: 0.5617 - val_time_output_loss: 0.9668\n",
      "Epoch 16/500\n",
      "18s - loss: 1.6372 - act_output_loss: 0.6490 - time_output_loss: 0.9882 - val_loss: 1.5244 - val_act_output_loss: 0.5696 - val_time_output_loss: 0.9548\n",
      "Epoch 17/500\n",
      "18s - loss: 1.6347 - act_output_loss: 0.6464 - time_output_loss: 0.9884 - val_loss: 1.5187 - val_act_output_loss: 0.5613 - val_time_output_loss: 0.9575\n",
      "Epoch 18/500\n",
      "18s - loss: 1.6316 - act_output_loss: 0.6416 - time_output_loss: 0.9900 - val_loss: 1.5258 - val_act_output_loss: 0.5687 - val_time_output_loss: 0.9572\n",
      "Epoch 19/500\n",
      "17s - loss: 1.6238 - act_output_loss: 0.6326 - time_output_loss: 0.9913 - val_loss: 1.5340 - val_act_output_loss: 0.5764 - val_time_output_loss: 0.9576\n",
      "Epoch 20/500\n",
      "18s - loss: 1.6331 - act_output_loss: 0.6386 - time_output_loss: 0.9945 - val_loss: 1.5393 - val_act_output_loss: 0.5689 - val_time_output_loss: 0.9704\n",
      "Epoch 21/500\n",
      "18s - loss: 1.6285 - act_output_loss: 0.6373 - time_output_loss: 0.9912 - val_loss: 1.5178 - val_act_output_loss: 0.5628 - val_time_output_loss: 0.9551\n",
      "Epoch 22/500\n",
      "19s - loss: 1.6338 - act_output_loss: 0.6409 - time_output_loss: 0.9928 - val_loss: 1.5199 - val_act_output_loss: 0.5635 - val_time_output_loss: 0.9563\n",
      "Epoch 23/500\n",
      "18s - loss: 1.6394 - act_output_loss: 0.6481 - time_output_loss: 0.9913 - val_loss: 1.5280 - val_act_output_loss: 0.5747 - val_time_output_loss: 0.9534\n",
      "Epoch 24/500\n",
      "19s - loss: 1.6306 - act_output_loss: 0.6370 - time_output_loss: 0.9936 - val_loss: 1.5336 - val_act_output_loss: 0.5702 - val_time_output_loss: 0.9634\n",
      "Epoch 25/500\n",
      "18s - loss: 1.6194 - act_output_loss: 0.6300 - time_output_loss: 0.9894 - val_loss: 1.5216 - val_act_output_loss: 0.5700 - val_time_output_loss: 0.9516\n",
      "Epoch 26/500\n",
      "17s - loss: 1.6241 - act_output_loss: 0.6336 - time_output_loss: 0.9905 - val_loss: 1.5222 - val_act_output_loss: 0.5651 - val_time_output_loss: 0.9571\n",
      "Epoch 27/500\n",
      "18s - loss: 1.6206 - act_output_loss: 0.6308 - time_output_loss: 0.9899 - val_loss: 1.5357 - val_act_output_loss: 0.5695 - val_time_output_loss: 0.9662\n",
      "Epoch 28/500\n",
      "18s - loss: 1.6147 - act_output_loss: 0.6261 - time_output_loss: 0.9886 - val_loss: 1.5332 - val_act_output_loss: 0.5750 - val_time_output_loss: 0.9583\n",
      "Epoch 29/500\n",
      "18s - loss: 1.6245 - act_output_loss: 0.6336 - time_output_loss: 0.9910 - val_loss: 1.5221 - val_act_output_loss: 0.5714 - val_time_output_loss: 0.9507\n",
      "Epoch 30/500\n",
      "17s - loss: 1.6282 - act_output_loss: 0.6395 - time_output_loss: 0.9887 - val_loss: 1.5225 - val_act_output_loss: 0.5666 - val_time_output_loss: 0.9559\n",
      "Epoch 31/500\n",
      "17s - loss: 1.6207 - act_output_loss: 0.6282 - time_output_loss: 0.9925 - val_loss: 1.5269 - val_act_output_loss: 0.5677 - val_time_output_loss: 0.9592\n",
      "Epoch 32/500\n",
      "18s - loss: 1.6215 - act_output_loss: 0.6271 - time_output_loss: 0.9944 - val_loss: 1.5288 - val_act_output_loss: 0.5719 - val_time_output_loss: 0.9568\n",
      "Epoch 33/500\n",
      "17s - loss: 1.6160 - act_output_loss: 0.6304 - time_output_loss: 0.9856 - val_loss: 1.5174 - val_act_output_loss: 0.5691 - val_time_output_loss: 0.9483\n",
      "Epoch 34/500\n",
      "18s - loss: 1.6065 - act_output_loss: 0.6172 - time_output_loss: 0.9893 - val_loss: 1.5210 - val_act_output_loss: 0.5680 - val_time_output_loss: 0.9530\n",
      "Epoch 35/500\n",
      "18s - loss: 1.6093 - act_output_loss: 0.6207 - time_output_loss: 0.9885 - val_loss: 1.5132 - val_act_output_loss: 0.5622 - val_time_output_loss: 0.9510\n",
      "Epoch 36/500\n",
      "18s - loss: 1.6045 - act_output_loss: 0.6170 - time_output_loss: 0.9874 - val_loss: 1.5216 - val_act_output_loss: 0.5668 - val_time_output_loss: 0.9548\n",
      "Epoch 37/500\n",
      "17s - loss: 1.6076 - act_output_loss: 0.6181 - time_output_loss: 0.9895 - val_loss: 1.5214 - val_act_output_loss: 0.5653 - val_time_output_loss: 0.9562\n",
      "Epoch 38/500\n",
      "17s - loss: 1.6063 - act_output_loss: 0.6192 - time_output_loss: 0.9872 - val_loss: 1.5225 - val_act_output_loss: 0.5661 - val_time_output_loss: 0.9564\n",
      "Epoch 39/500\n",
      "17s - loss: 1.6007 - act_output_loss: 0.6150 - time_output_loss: 0.9857 - val_loss: 1.5171 - val_act_output_loss: 0.5631 - val_time_output_loss: 0.9540\n",
      "Epoch 40/500\n",
      "18s - loss: 1.5996 - act_output_loss: 0.6117 - time_output_loss: 0.9879 - val_loss: 1.5227 - val_act_output_loss: 0.5708 - val_time_output_loss: 0.9519\n",
      "Epoch 41/500\n",
      "17s - loss: 1.6008 - act_output_loss: 0.6172 - time_output_loss: 0.9837 - val_loss: 1.5175 - val_act_output_loss: 0.5665 - val_time_output_loss: 0.9510\n",
      "Epoch 42/500\n",
      "18s - loss: 1.6036 - act_output_loss: 0.6143 - time_output_loss: 0.9892 - val_loss: 1.5157 - val_act_output_loss: 0.5615 - val_time_output_loss: 0.9542\n",
      "Epoch 43/500\n",
      "21s - loss: 1.5998 - act_output_loss: 0.6121 - time_output_loss: 0.9876 - val_loss: 1.5244 - val_act_output_loss: 0.5684 - val_time_output_loss: 0.9560\n",
      "Epoch 44/500\n",
      "17s - loss: 1.6031 - act_output_loss: 0.6168 - time_output_loss: 0.9863 - val_loss: 1.5234 - val_act_output_loss: 0.5694 - val_time_output_loss: 0.9541\n",
      "Epoch 45/500\n",
      "17s - loss: 1.6075 - act_output_loss: 0.6190 - time_output_loss: 0.9885 - val_loss: 1.5326 - val_act_output_loss: 0.5740 - val_time_output_loss: 0.9587\n",
      "Epoch 46/500\n",
      "17s - loss: 1.5951 - act_output_loss: 0.6068 - time_output_loss: 0.9883 - val_loss: 1.5231 - val_act_output_loss: 0.5647 - val_time_output_loss: 0.9584\n",
      "Epoch 47/500\n",
      "17s - loss: 1.5987 - act_output_loss: 0.6093 - time_output_loss: 0.9894 - val_loss: 1.5299 - val_act_output_loss: 0.5732 - val_time_output_loss: 0.9567\n",
      "Epoch 48/500\n",
      "17s - loss: 1.5999 - act_output_loss: 0.6128 - time_output_loss: 0.9870 - val_loss: 1.5200 - val_act_output_loss: 0.5646 - val_time_output_loss: 0.9554\n",
      "Epoch 49/500\n",
      "17s - loss: 1.5897 - act_output_loss: 0.6037 - time_output_loss: 0.9860 - val_loss: 1.5235 - val_act_output_loss: 0.5667 - val_time_output_loss: 0.9569\n",
      "Epoch 50/500\n",
      "17s - loss: 1.6048 - act_output_loss: 0.6142 - time_output_loss: 0.9906 - val_loss: 1.5262 - val_act_output_loss: 0.5685 - val_time_output_loss: 0.9577\n",
      "Epoch 51/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "17s - loss: 1.5935 - act_output_loss: 0.6070 - time_output_loss: 0.9865 - val_loss: 1.5225 - val_act_output_loss: 0.5657 - val_time_output_loss: 0.9568\n",
      "Epoch 52/500\n",
      "17s - loss: 1.5912 - act_output_loss: 0.6052 - time_output_loss: 0.9860 - val_loss: 1.5263 - val_act_output_loss: 0.5673 - val_time_output_loss: 0.9590\n",
      "Epoch 53/500\n",
      "17s - loss: 1.5929 - act_output_loss: 0.6085 - time_output_loss: 0.9844 - val_loss: 1.5223 - val_act_output_loss: 0.5660 - val_time_output_loss: 0.9562\n",
      "Epoch 54/500\n",
      "17s - loss: 1.5886 - act_output_loss: 0.6077 - time_output_loss: 0.9809 - val_loss: 1.5192 - val_act_output_loss: 0.5657 - val_time_output_loss: 0.9535\n",
      "Epoch 55/500\n",
      "17s - loss: 1.5928 - act_output_loss: 0.6064 - time_output_loss: 0.9863 - val_loss: 1.5185 - val_act_output_loss: 0.5644 - val_time_output_loss: 0.9541\n",
      "Epoch 56/500\n",
      "20s - loss: 1.5965 - act_output_loss: 0.6095 - time_output_loss: 0.9871 - val_loss: 1.5271 - val_act_output_loss: 0.5738 - val_time_output_loss: 0.9533\n",
      "Epoch 57/500\n",
      "18s - loss: 1.5899 - act_output_loss: 0.6029 - time_output_loss: 0.9870 - val_loss: 1.5154 - val_act_output_loss: 0.5657 - val_time_output_loss: 0.9498\n",
      "Epoch 58/500\n",
      "17s - loss: 1.5776 - act_output_loss: 0.5959 - time_output_loss: 0.9817 - val_loss: 1.5207 - val_act_output_loss: 0.5674 - val_time_output_loss: 0.9533\n",
      "Epoch 59/500\n",
      "17s - loss: 1.5851 - act_output_loss: 0.6008 - time_output_loss: 0.9844 - val_loss: 1.5170 - val_act_output_loss: 0.5659 - val_time_output_loss: 0.9511\n",
      "Epoch 60/500\n",
      "17s - loss: 1.5866 - act_output_loss: 0.6052 - time_output_loss: 0.9814 - val_loss: 1.5206 - val_act_output_loss: 0.5690 - val_time_output_loss: 0.9516\n",
      "Epoch 61/500\n",
      "17s - loss: 1.5940 - act_output_loss: 0.6044 - time_output_loss: 0.9896 - val_loss: 1.5195 - val_act_output_loss: 0.5682 - val_time_output_loss: 0.9514\n",
      "Epoch 62/500\n",
      "18s - loss: 1.5934 - act_output_loss: 0.6119 - time_output_loss: 0.9815 - val_loss: 1.5199 - val_act_output_loss: 0.5673 - val_time_output_loss: 0.9527\n",
      "Epoch 63/500\n",
      "17s - loss: 1.5939 - act_output_loss: 0.6090 - time_output_loss: 0.9849 - val_loss: 1.5183 - val_act_output_loss: 0.5673 - val_time_output_loss: 0.9510\n",
      "Epoch 64/500\n",
      "17s - loss: 1.5825 - act_output_loss: 0.5974 - time_output_loss: 0.9851 - val_loss: 1.5202 - val_act_output_loss: 0.5699 - val_time_output_loss: 0.9503\n",
      "Epoch 65/500\n",
      "17s - loss: 1.5842 - act_output_loss: 0.5998 - time_output_loss: 0.9844 - val_loss: 1.5202 - val_act_output_loss: 0.5695 - val_time_output_loss: 0.9506\n",
      "Epoch 66/500\n",
      "17s - loss: 1.5819 - act_output_loss: 0.5987 - time_output_loss: 0.9832 - val_loss: 1.5194 - val_act_output_loss: 0.5701 - val_time_output_loss: 0.9493\n",
      "Epoch 67/500\n",
      "17s - loss: 1.5822 - act_output_loss: 0.5961 - time_output_loss: 0.9861 - val_loss: 1.5170 - val_act_output_loss: 0.5668 - val_time_output_loss: 0.9502\n",
      "Epoch 68/500\n",
      "17s - loss: 1.5875 - act_output_loss: 0.6027 - time_output_loss: 0.9848 - val_loss: 1.5178 - val_act_output_loss: 0.5673 - val_time_output_loss: 0.9505\n",
      "Epoch 69/500\n",
      "18s - loss: 1.5898 - act_output_loss: 0.6046 - time_output_loss: 0.9852 - val_loss: 1.5171 - val_act_output_loss: 0.5680 - val_time_output_loss: 0.9491\n",
      "Epoch 70/500\n",
      "17s - loss: 1.5917 - act_output_loss: 0.6059 - time_output_loss: 0.9858 - val_loss: 1.5161 - val_act_output_loss: 0.5671 - val_time_output_loss: 0.9489\n",
      "Epoch 71/500\n",
      "17s - loss: 1.5863 - act_output_loss: 0.6043 - time_output_loss: 0.9820 - val_loss: 1.5168 - val_act_output_loss: 0.5667 - val_time_output_loss: 0.9502\n",
      "Epoch 72/500\n",
      "17s - loss: 1.5913 - act_output_loss: 0.6053 - time_output_loss: 0.9860 - val_loss: 1.5159 - val_act_output_loss: 0.5646 - val_time_output_loss: 0.9514\n",
      "Epoch 73/500\n",
      "17s - loss: 1.5920 - act_output_loss: 0.6049 - time_output_loss: 0.9870 - val_loss: 1.5154 - val_act_output_loss: 0.5660 - val_time_output_loss: 0.9494\n",
      "Epoch 74/500\n",
      "24s - loss: 1.5870 - act_output_loss: 0.6023 - time_output_loss: 0.9847 - val_loss: 1.5151 - val_act_output_loss: 0.5643 - val_time_output_loss: 0.9507\n",
      "Epoch 75/500\n",
      "18s - loss: 1.5836 - act_output_loss: 0.6032 - time_output_loss: 0.9804 - val_loss: 1.5148 - val_act_output_loss: 0.5653 - val_time_output_loss: 0.9496\n",
      "Epoch 76/500\n",
      "17s - loss: 1.5863 - act_output_loss: 0.6035 - time_output_loss: 0.9829 - val_loss: 1.5152 - val_act_output_loss: 0.5653 - val_time_output_loss: 0.9499\n",
      "Epoch 77/500\n",
      "17s - loss: 1.5776 - act_output_loss: 0.5949 - time_output_loss: 0.9827 - val_loss: 1.5161 - val_act_output_loss: 0.5656 - val_time_output_loss: 0.9505\n",
      "Epoch 78/500\n",
      "17s - loss: 1.5827 - act_output_loss: 0.5976 - time_output_loss: 0.9852 - val_loss: 1.5128 - val_act_output_loss: 0.5645 - val_time_output_loss: 0.9483\n",
      "Epoch 79/500\n",
      "18s - loss: 1.5789 - act_output_loss: 0.6018 - time_output_loss: 0.9771 - val_loss: 1.5142 - val_act_output_loss: 0.5651 - val_time_output_loss: 0.9491\n",
      "Epoch 80/500\n",
      "17s - loss: 1.5852 - act_output_loss: 0.6009 - time_output_loss: 0.9843 - val_loss: 1.5135 - val_act_output_loss: 0.5636 - val_time_output_loss: 0.9500\n",
      "Epoch 81/500\n",
      "17s - loss: 1.5815 - act_output_loss: 0.6012 - time_output_loss: 0.9803 - val_loss: 1.5147 - val_act_output_loss: 0.5654 - val_time_output_loss: 0.9492\n",
      "Epoch 82/500\n",
      "18s - loss: 1.5753 - act_output_loss: 0.5911 - time_output_loss: 0.9842 - val_loss: 1.5162 - val_act_output_loss: 0.5657 - val_time_output_loss: 0.9505\n",
      "Epoch 83/500\n",
      "17s - loss: 1.5800 - act_output_loss: 0.5976 - time_output_loss: 0.9824 - val_loss: 1.5165 - val_act_output_loss: 0.5665 - val_time_output_loss: 0.9500\n",
      "Epoch 84/500\n",
      "21s - loss: 1.5811 - act_output_loss: 0.5993 - time_output_loss: 0.9819 - val_loss: 1.5163 - val_act_output_loss: 0.5664 - val_time_output_loss: 0.9499\n",
      "Epoch 85/500\n",
      "17s - loss: 1.5815 - act_output_loss: 0.5959 - time_output_loss: 0.9856 - val_loss: 1.5166 - val_act_output_loss: 0.5671 - val_time_output_loss: 0.9496\n",
      "Epoch 86/500\n",
      "17s - loss: 1.5912 - act_output_loss: 0.6062 - time_output_loss: 0.9850 - val_loss: 1.5165 - val_act_output_loss: 0.5663 - val_time_output_loss: 0.9503\n",
      "Epoch 87/500\n",
      "17s - loss: 1.5798 - act_output_loss: 0.5966 - time_output_loss: 0.9832 - val_loss: 1.5185 - val_act_output_loss: 0.5677 - val_time_output_loss: 0.9508\n",
      "Epoch 88/500\n",
      "18s - loss: 1.5756 - act_output_loss: 0.5948 - time_output_loss: 0.9807 - val_loss: 1.5163 - val_act_output_loss: 0.5669 - val_time_output_loss: 0.9494\n",
      "Epoch 89/500\n",
      "17s - loss: 1.5817 - act_output_loss: 0.5967 - time_output_loss: 0.9849 - val_loss: 1.5172 - val_act_output_loss: 0.5669 - val_time_output_loss: 0.9503\n",
      "Epoch 90/500\n",
      "19s - loss: 1.5758 - act_output_loss: 0.5936 - time_output_loss: 0.9822 - val_loss: 1.5180 - val_act_output_loss: 0.5670 - val_time_output_loss: 0.9510\n",
      "Epoch 91/500\n",
      "17s - loss: 1.5756 - act_output_loss: 0.5909 - time_output_loss: 0.9847 - val_loss: 1.5180 - val_act_output_loss: 0.5666 - val_time_output_loss: 0.9514\n",
      "Epoch 92/500\n",
      "17s - loss: 1.5842 - act_output_loss: 0.6008 - time_output_loss: 0.9834 - val_loss: 1.5172 - val_act_output_loss: 0.5668 - val_time_output_loss: 0.9504\n",
      "Epoch 93/500\n",
      "17s - loss: 1.5802 - act_output_loss: 0.6021 - time_output_loss: 0.9781 - val_loss: 1.5160 - val_act_output_loss: 0.5659 - val_time_output_loss: 0.9501\n",
      "Epoch 94/500\n",
      "18s - loss: 1.5798 - act_output_loss: 0.5953 - time_output_loss: 0.9845 - val_loss: 1.5173 - val_act_output_loss: 0.5672 - val_time_output_loss: 0.9500\n",
      "Epoch 95/500\n",
      "18s - loss: 1.5799 - act_output_loss: 0.5934 - time_output_loss: 0.9865 - val_loss: 1.5163 - val_act_output_loss: 0.5661 - val_time_output_loss: 0.9502\n",
      "Epoch 96/500\n",
      "17s - loss: 1.5827 - act_output_loss: 0.5997 - time_output_loss: 0.9830 - val_loss: 1.5171 - val_act_output_loss: 0.5670 - val_time_output_loss: 0.9501\n",
      "Epoch 97/500\n",
      "17s - loss: 1.5753 - act_output_loss: 0.5938 - time_output_loss: 0.9815 - val_loss: 1.5180 - val_act_output_loss: 0.5680 - val_time_output_loss: 0.9500\n",
      "Epoch 98/500\n",
      "17s - loss: 1.5763 - act_output_loss: 0.5901 - time_output_loss: 0.9862 - val_loss: 1.5173 - val_act_output_loss: 0.5666 - val_time_output_loss: 0.9507\n",
      "Epoch 99/500\n",
      "17s - loss: 1.5726 - act_output_loss: 0.5903 - time_output_loss: 0.9822 - val_loss: 1.5170 - val_act_output_loss: 0.5666 - val_time_output_loss: 0.9504\n",
      "Epoch 100/500\n",
      "17s - loss: 1.5787 - act_output_loss: 0.5977 - time_output_loss: 0.9810 - val_loss: 1.5173 - val_act_output_loss: 0.5674 - val_time_output_loss: 0.9500\n",
      "Epoch 101/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "17s - loss: 1.5770 - act_output_loss: 0.5974 - time_output_loss: 0.9796 - val_loss: 1.5172 - val_act_output_loss: 0.5672 - val_time_output_loss: 0.9500\n",
      "Epoch 102/500\n",
      "18s - loss: 1.5825 - act_output_loss: 0.5968 - time_output_loss: 0.9857 - val_loss: 1.5178 - val_act_output_loss: 0.5678 - val_time_output_loss: 0.9500\n",
      "Epoch 103/500\n",
      "17s - loss: 1.5809 - act_output_loss: 0.5963 - time_output_loss: 0.9846 - val_loss: 1.5167 - val_act_output_loss: 0.5662 - val_time_output_loss: 0.9504\n",
      "Epoch 104/500\n",
      "17s - loss: 1.5816 - act_output_loss: 0.6010 - time_output_loss: 0.9806 - val_loss: 1.5172 - val_act_output_loss: 0.5667 - val_time_output_loss: 0.9505\n",
      "Epoch 105/500\n",
      "17s - loss: 1.5731 - act_output_loss: 0.5921 - time_output_loss: 0.9810 - val_loss: 1.5161 - val_act_output_loss: 0.5657 - val_time_output_loss: 0.9504\n",
      "Epoch 106/500\n",
      "17s - loss: 1.5765 - act_output_loss: 0.5969 - time_output_loss: 0.9797 - val_loss: 1.5160 - val_act_output_loss: 0.5666 - val_time_output_loss: 0.9494\n",
      "Epoch 107/500\n",
      "18s - loss: 1.5751 - act_output_loss: 0.5933 - time_output_loss: 0.9818 - val_loss: 1.5163 - val_act_output_loss: 0.5667 - val_time_output_loss: 0.9495\n",
      "Epoch 108/500\n",
      "17s - loss: 1.5794 - act_output_loss: 0.5943 - time_output_loss: 0.9852 - val_loss: 1.5176 - val_act_output_loss: 0.5673 - val_time_output_loss: 0.9503\n",
      "Epoch 109/500\n",
      "17s - loss: 1.5853 - act_output_loss: 0.6012 - time_output_loss: 0.9841 - val_loss: 1.5186 - val_act_output_loss: 0.5670 - val_time_output_loss: 0.9516\n",
      "Epoch 110/500\n",
      "17s - loss: 1.5837 - act_output_loss: 0.6028 - time_output_loss: 0.9809 - val_loss: 1.5170 - val_act_output_loss: 0.5669 - val_time_output_loss: 0.9500\n",
      "Epoch 111/500\n",
      "17s - loss: 1.5716 - act_output_loss: 0.5919 - time_output_loss: 0.9797 - val_loss: 1.5172 - val_act_output_loss: 0.5666 - val_time_output_loss: 0.9505\n",
      "Epoch 112/500\n",
      "17s - loss: 1.5891 - act_output_loss: 0.6037 - time_output_loss: 0.9853 - val_loss: 1.5164 - val_act_output_loss: 0.5665 - val_time_output_loss: 0.9499\n",
      "Epoch 113/500\n",
      "17s - loss: 1.5823 - act_output_loss: 0.5981 - time_output_loss: 0.9842 - val_loss: 1.5166 - val_act_output_loss: 0.5666 - val_time_output_loss: 0.9500\n",
      "Epoch 114/500\n",
      "17s - loss: 1.5896 - act_output_loss: 0.6073 - time_output_loss: 0.9823 - val_loss: 1.5162 - val_act_output_loss: 0.5664 - val_time_output_loss: 0.9499\n",
      "Epoch 115/500\n",
      "20s - loss: 1.5808 - act_output_loss: 0.5944 - time_output_loss: 0.9865 - val_loss: 1.5165 - val_act_output_loss: 0.5663 - val_time_output_loss: 0.9502\n",
      "Epoch 116/500\n",
      "17s - loss: 1.5787 - act_output_loss: 0.5973 - time_output_loss: 0.9814 - val_loss: 1.5162 - val_act_output_loss: 0.5663 - val_time_output_loss: 0.9499\n",
      "Epoch 117/500\n",
      "17s - loss: 1.5833 - act_output_loss: 0.5981 - time_output_loss: 0.9852 - val_loss: 1.5176 - val_act_output_loss: 0.5667 - val_time_output_loss: 0.9509\n",
      "Epoch 118/500\n",
      "17s - loss: 1.5817 - act_output_loss: 0.6004 - time_output_loss: 0.9812 - val_loss: 1.5158 - val_act_output_loss: 0.5657 - val_time_output_loss: 0.9501\n",
      "Epoch 119/500\n",
      "17s - loss: 1.5772 - act_output_loss: 0.5950 - time_output_loss: 0.9822 - val_loss: 1.5162 - val_act_output_loss: 0.5666 - val_time_output_loss: 0.9496\n",
      "Epoch 120/500\n",
      "17s - loss: 1.5809 - act_output_loss: 0.5997 - time_output_loss: 0.9812 - val_loss: 1.5163 - val_act_output_loss: 0.5663 - val_time_output_loss: 0.9500\n",
      "Epoch 121/500\n",
      "17s - loss: 1.5798 - act_output_loss: 0.5979 - time_output_loss: 0.9818 - val_loss: 1.5181 - val_act_output_loss: 0.5664 - val_time_output_loss: 0.9516\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f75fcee1950>"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# build the model: \n",
    "print('Build model...')\n",
    "main_input = Input(shape=(maxlen, num_features), name='main_input')\n",
    "\n",
    "# train a 2-layer LSTM with one shared layer\n",
    "l1 = LSTM(100, consume_less='gpu', init='glorot_uniform', return_sequences=True, dropout_W=0.2)(main_input) # the shared layer\n",
    "b1 = BatchNormalization()(l1)\n",
    "\n",
    "l2_1 = LSTM(100, consume_less='gpu', init='glorot_uniform', return_sequences=False, dropout_W=0.2)(b1) # the layer specialized in activity prediction\n",
    "b2_1 = BatchNormalization()(l2_1)\n",
    "l2_2 = LSTM(100, consume_less='gpu', init='glorot_uniform', return_sequences=False, dropout_W=0.2)(b1) # the layer specialized in time prediction\n",
    "b2_2 = BatchNormalization()(l2_2)\n",
    "\n",
    "act_output = Dense(len(targetchartoindice), activation='softmax', init='glorot_uniform', name='act_output')(b2_1)\n",
    "time_output = Dense(1, init='glorot_uniform', name='time_output')(b2_2)\n",
    "\n",
    "model = Model(input=[main_input], output=[act_output, time_output])\n",
    "\n",
    "opt = Nadam(lr=0.002, beta_1=0.9, beta_2=0.999, epsilon=1e-08, schedule_decay=0.004, clipvalue=3)\n",
    "\n",
    "model.compile(loss={'act_output':'categorical_crossentropy', 'time_output':'mae'}, optimizer=opt)\n",
    "early_stopping = EarlyStopping(monitor='val_loss', patience=42)\n",
    "model_checkpoint = ModelCheckpoint(args.outputdir + 'model_{epoch:02d}-{val_loss:.2f}.h5', \n",
    "                                   monitor='val_loss', verbose=0, save_best_only=True, \n",
    "                                   save_weights_only=False, mode='auto')\n",
    "lr_reducer = ReduceLROnPlateau(monitor='val_loss', factor=0.5, patience=10, verbose=0, \n",
    "                               mode='auto', epsilon=0.0001, cooldown=0, min_lr=0)\n",
    "\n",
    "model.fit(X, {'act_output':y_a, 'time_output':y_t}, validation_split=0.2, verbose=2, \n",
    "          callbacks=[early_stopping, model_checkpoint, lr_reducer], batch_size=maxlen, nb_epoch=500)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "____________________________________________________________________________________________________\n",
      "Layer (type)                     Output Shape          Param #     Connected to                     \n",
      "====================================================================================================\n",
      "main_input (InputLayer)          (None, 15, 14)        0                                            \n",
      "____________________________________________________________________________________________________\n",
      "lstm_1 (LSTM)                    (None, 15, 100)       46000       main_input[0][0]                 \n",
      "____________________________________________________________________________________________________\n",
      "batchnormalization_1 (BatchNorma (None, 15, 100)       400         lstm_1[0][0]                     \n",
      "____________________________________________________________________________________________________\n",
      "lstm_2 (LSTM)                    (None, 100)           80400       batchnormalization_1[0][0]       \n",
      "____________________________________________________________________________________________________\n",
      "lstm_3 (LSTM)                    (None, 100)           80400       batchnormalization_1[0][0]       \n",
      "____________________________________________________________________________________________________\n",
      "batchnormalization_2 (BatchNorma (None, 100)           400         lstm_2[0][0]                     \n",
      "____________________________________________________________________________________________________\n",
      "batchnormalization_3 (BatchNorma (None, 100)           400         lstm_3[0][0]                     \n",
      "____________________________________________________________________________________________________\n",
      "act_output (Dense)               (None, 10)            1010        batchnormalization_2[0][0]       \n",
      "____________________________________________________________________________________________________\n",
      "time_output (Dense)              (None, 1)             101         batchnormalization_3[0][0]       \n",
      "====================================================================================================\n",
      "Total params: 209,111\n",
      "Trainable params: 208,511\n",
      "Non-trainable params: 600\n",
      "____________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  },
  "toc": {
   "colors": {
    "hover_highlight": "#DAA520",
    "running_highlight": "#FF0000",
    "selected_highlight": "#FFD700"
   },
   "moveMenuLeft": true,
   "nav_menu": {
    "height": "66px",
    "width": "252px"
   },
   "navigate_menu": true,
   "number_sections": true,
   "sideBar": true,
   "threshold": 4,
   "toc_cell": false,
   "toc_section_display": "block",
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
