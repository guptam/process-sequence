{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is the original model, run in Python 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import argparse\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using Theano backend.\n",
      "ERROR (theano.sandbox.cuda): Failed to compile cuda_ndarray.cu: libcublas.so.8.0: cannot open shared object file: No such file or directory\n"
     ]
    }
   ],
   "source": [
    "from keras.models import Sequential, Model\n",
    "from keras.layers.core import Dense\n",
    "from keras.layers.recurrent import LSTM, GRU, SimpleRNN\n",
    "from keras.layers import Input\n",
    "from keras.layers.wrappers import Bidirectional\n",
    "from keras.utils.data_utils import get_file\n",
    "from keras.regularizers import WeightRegularizer\n",
    "from keras.optimizers import Nadam\n",
    "from keras.callbacks import EarlyStopping, ModelCheckpoint, ReduceLROnPlateau\n",
    "from keras.layers.normalization import BatchNormalization\n",
    "from theano.ifelse import ifelse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "name = 'helpdesk'\n",
    "args = {\n",
    "    'inputdir': '../input/{}/'.format(name),   \n",
    "    'outputdir': './output_files/{}/'.format(name)\n",
    "}\n",
    "\n",
    "args = argparse.Namespace(**args)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "if not os.path.isdir(args.outputdir):\n",
    "    os.makedirs(args.outputdir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "with open(args.inputdir + 'parameters.pkl', \"rb\") as f:\n",
    "    maxlen = pickle.load(f)\n",
    "    num_features = pickle.load(f)\n",
    "    chartoindice = pickle.load(f)\n",
    "    targetchartoindice = pickle.load(f)\n",
    "    divisor = pickle.load(f)\n",
    "    divisor2 = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "with open(args.inputdir + 'preprocessed_data.pkl', \"rb\") as f:\n",
    "    X = pickle.load(f)\n",
    "    y_a = pickle.load(f)\n",
    "    y_t = pickle.load(f)\n",
    "    X_test = pickle.load(f)\n",
    "    y_a_test = pickle.load(f)\n",
    "    y_t_test = pickle.load(f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Build model...\n",
      "Train on 7344 samples, validate on 1837 samples\n",
      "Epoch 1/500\n",
      "15s - loss: 2.1482 - act_output_loss: 0.9557 - time_output_loss: 1.1925 - val_loss: 1.7238 - val_act_output_loss: 0.6957 - val_time_output_loss: 1.0282\n",
      "Epoch 2/500\n",
      "15s - loss: 1.7612 - act_output_loss: 0.7136 - time_output_loss: 1.0476 - val_loss: 1.5787 - val_act_output_loss: 0.5862 - val_time_output_loss: 0.9925\n",
      "Epoch 3/500\n",
      "15s - loss: 1.7087 - act_output_loss: 0.6898 - time_output_loss: 1.0189 - val_loss: 1.5766 - val_act_output_loss: 0.5931 - val_time_output_loss: 0.9834\n",
      "Epoch 4/500\n",
      "15s - loss: 1.6867 - act_output_loss: 0.6771 - time_output_loss: 1.0096 - val_loss: 1.5426 - val_act_output_loss: 0.5759 - val_time_output_loss: 0.9667\n",
      "Epoch 5/500\n",
      "15s - loss: 1.6818 - act_output_loss: 0.6742 - time_output_loss: 1.0076 - val_loss: 1.5329 - val_act_output_loss: 0.5705 - val_time_output_loss: 0.9624\n",
      "Epoch 6/500\n",
      "15s - loss: 1.6693 - act_output_loss: 0.6661 - time_output_loss: 1.0032 - val_loss: 1.5562 - val_act_output_loss: 0.5833 - val_time_output_loss: 0.9730\n",
      "Epoch 7/500\n",
      "15s - loss: 1.6699 - act_output_loss: 0.6667 - time_output_loss: 1.0032 - val_loss: 1.5360 - val_act_output_loss: 0.5727 - val_time_output_loss: 0.9633\n",
      "Epoch 8/500\n",
      "15s - loss: 1.6572 - act_output_loss: 0.6580 - time_output_loss: 0.9992 - val_loss: 1.5363 - val_act_output_loss: 0.5628 - val_time_output_loss: 0.9735\n",
      "Epoch 9/500\n",
      "15s - loss: 1.6517 - act_output_loss: 0.6562 - time_output_loss: 0.9956 - val_loss: 1.5463 - val_act_output_loss: 0.5739 - val_time_output_loss: 0.9724\n",
      "Epoch 10/500\n",
      "15s - loss: 1.6487 - act_output_loss: 0.6533 - time_output_loss: 0.9954 - val_loss: 1.5497 - val_act_output_loss: 0.5762 - val_time_output_loss: 0.9735\n",
      "Epoch 11/500\n",
      "15s - loss: 1.6307 - act_output_loss: 0.6362 - time_output_loss: 0.9945 - val_loss: 1.5300 - val_act_output_loss: 0.5651 - val_time_output_loss: 0.9649\n",
      "Epoch 12/500\n",
      "15s - loss: 1.6502 - act_output_loss: 0.6539 - time_output_loss: 0.9963 - val_loss: 1.5369 - val_act_output_loss: 0.5716 - val_time_output_loss: 0.9653\n",
      "Epoch 13/500\n",
      "15s - loss: 1.6327 - act_output_loss: 0.6377 - time_output_loss: 0.9950 - val_loss: 1.5632 - val_act_output_loss: 0.5845 - val_time_output_loss: 0.9787\n",
      "Epoch 14/500\n",
      "15s - loss: 1.6430 - act_output_loss: 0.6491 - time_output_loss: 0.9939 - val_loss: 1.5393 - val_act_output_loss: 0.5720 - val_time_output_loss: 0.9673\n",
      "Epoch 15/500\n",
      "15s - loss: 1.6411 - act_output_loss: 0.6476 - time_output_loss: 0.9935 - val_loss: 1.5270 - val_act_output_loss: 0.5711 - val_time_output_loss: 0.9559\n",
      "Epoch 16/500\n",
      "15s - loss: 1.6382 - act_output_loss: 0.6489 - time_output_loss: 0.9893 - val_loss: 1.5353 - val_act_output_loss: 0.5737 - val_time_output_loss: 0.9616\n",
      "Epoch 17/500\n",
      "15s - loss: 1.6304 - act_output_loss: 0.6397 - time_output_loss: 0.9907 - val_loss: 1.5422 - val_act_output_loss: 0.5844 - val_time_output_loss: 0.9578\n",
      "Epoch 18/500\n",
      "15s - loss: 1.6359 - act_output_loss: 0.6438 - time_output_loss: 0.9921 - val_loss: 1.5340 - val_act_output_loss: 0.5702 - val_time_output_loss: 0.9638\n",
      "Epoch 19/500\n",
      "15s - loss: 1.6314 - act_output_loss: 0.6395 - time_output_loss: 0.9919 - val_loss: 1.5266 - val_act_output_loss: 0.5693 - val_time_output_loss: 0.9573\n",
      "Epoch 20/500\n",
      "15s - loss: 1.6336 - act_output_loss: 0.6430 - time_output_loss: 0.9906 - val_loss: 1.5113 - val_act_output_loss: 0.5620 - val_time_output_loss: 0.9492\n",
      "Epoch 21/500\n",
      "15s - loss: 1.6345 - act_output_loss: 0.6397 - time_output_loss: 0.9947 - val_loss: 1.5423 - val_act_output_loss: 0.5698 - val_time_output_loss: 0.9725\n",
      "Epoch 22/500\n",
      "15s - loss: 1.6362 - act_output_loss: 0.6445 - time_output_loss: 0.9917 - val_loss: 1.5190 - val_act_output_loss: 0.5664 - val_time_output_loss: 0.9526\n",
      "Epoch 23/500\n",
      "15s - loss: 1.6163 - act_output_loss: 0.6281 - time_output_loss: 0.9882 - val_loss: 1.5607 - val_act_output_loss: 0.5731 - val_time_output_loss: 0.9875\n",
      "Epoch 24/500\n",
      "16s - loss: 1.6408 - act_output_loss: 0.6476 - time_output_loss: 0.9931 - val_loss: 1.5278 - val_act_output_loss: 0.5793 - val_time_output_loss: 0.9485\n",
      "Epoch 25/500\n",
      "17s - loss: 1.6174 - act_output_loss: 0.6301 - time_output_loss: 0.9872 - val_loss: 1.5334 - val_act_output_loss: 0.5765 - val_time_output_loss: 0.9569\n",
      "Epoch 26/500\n",
      "17s - loss: 1.6193 - act_output_loss: 0.6304 - time_output_loss: 0.9890 - val_loss: 1.5540 - val_act_output_loss: 0.5843 - val_time_output_loss: 0.9696\n",
      "Epoch 27/500\n",
      "17s - loss: 1.6291 - act_output_loss: 0.6370 - time_output_loss: 0.9922 - val_loss: 1.5498 - val_act_output_loss: 0.5796 - val_time_output_loss: 0.9702\n",
      "Epoch 28/500\n",
      "17s - loss: 1.6370 - act_output_loss: 0.6470 - time_output_loss: 0.9900 - val_loss: 1.5306 - val_act_output_loss: 0.5708 - val_time_output_loss: 0.9597\n",
      "Epoch 29/500\n",
      "17s - loss: 1.6270 - act_output_loss: 0.6367 - time_output_loss: 0.9904 - val_loss: 1.5366 - val_act_output_loss: 0.5827 - val_time_output_loss: 0.9539\n",
      "Epoch 30/500\n",
      "17s - loss: 1.6141 - act_output_loss: 0.6248 - time_output_loss: 0.9894 - val_loss: 1.5282 - val_act_output_loss: 0.5731 - val_time_output_loss: 0.9550\n",
      "Epoch 31/500\n",
      "17s - loss: 1.6248 - act_output_loss: 0.6342 - time_output_loss: 0.9906 - val_loss: 1.5222 - val_act_output_loss: 0.5680 - val_time_output_loss: 0.9542\n",
      "Epoch 32/500\n",
      "16s - loss: 1.6133 - act_output_loss: 0.6250 - time_output_loss: 0.9884 - val_loss: 1.5202 - val_act_output_loss: 0.5722 - val_time_output_loss: 0.9481\n",
      "Epoch 33/500\n",
      "17s - loss: 1.6149 - act_output_loss: 0.6273 - time_output_loss: 0.9876 - val_loss: 1.5293 - val_act_output_loss: 0.5745 - val_time_output_loss: 0.9547\n",
      "Epoch 34/500\n",
      "16s - loss: 1.6129 - act_output_loss: 0.6283 - time_output_loss: 0.9847 - val_loss: 1.5208 - val_act_output_loss: 0.5724 - val_time_output_loss: 0.9485\n",
      "Epoch 35/500\n",
      "16s - loss: 1.6037 - act_output_loss: 0.6152 - time_output_loss: 0.9885 - val_loss: 1.5178 - val_act_output_loss: 0.5688 - val_time_output_loss: 0.9490\n",
      "Epoch 36/500\n",
      "16s - loss: 1.6017 - act_output_loss: 0.6148 - time_output_loss: 0.9869 - val_loss: 1.5165 - val_act_output_loss: 0.5633 - val_time_output_loss: 0.9532\n",
      "Epoch 37/500\n",
      "16s - loss: 1.6079 - act_output_loss: 0.6188 - time_output_loss: 0.9890 - val_loss: 1.5111 - val_act_output_loss: 0.5650 - val_time_output_loss: 0.9461\n",
      "Epoch 38/500\n",
      "15s - loss: 1.6081 - act_output_loss: 0.6199 - time_output_loss: 0.9882 - val_loss: 1.5134 - val_act_output_loss: 0.5630 - val_time_output_loss: 0.9504\n",
      "Epoch 39/500\n",
      "15s - loss: 1.6105 - act_output_loss: 0.6213 - time_output_loss: 0.9892 - val_loss: 1.5179 - val_act_output_loss: 0.5646 - val_time_output_loss: 0.9534\n",
      "Epoch 40/500\n",
      "16s - loss: 1.6136 - act_output_loss: 0.6243 - time_output_loss: 0.9893 - val_loss: 1.5110 - val_act_output_loss: 0.5610 - val_time_output_loss: 0.9500\n",
      "Epoch 41/500\n",
      "15s - loss: 1.5988 - act_output_loss: 0.6092 - time_output_loss: 0.9896 - val_loss: 1.5141 - val_act_output_loss: 0.5664 - val_time_output_loss: 0.9478\n",
      "Epoch 42/500\n",
      "15s - loss: 1.5944 - act_output_loss: 0.6113 - time_output_loss: 0.9831 - val_loss: 1.5339 - val_act_output_loss: 0.5720 - val_time_output_loss: 0.9618\n",
      "Epoch 43/500\n",
      "15s - loss: 1.6080 - act_output_loss: 0.6209 - time_output_loss: 0.9871 - val_loss: 1.5325 - val_act_output_loss: 0.5741 - val_time_output_loss: 0.9584\n",
      "Epoch 44/500\n",
      "15s - loss: 1.6031 - act_output_loss: 0.6175 - time_output_loss: 0.9857 - val_loss: 1.5242 - val_act_output_loss: 0.5714 - val_time_output_loss: 0.9528\n",
      "Epoch 45/500\n",
      "15s - loss: 1.6007 - act_output_loss: 0.6178 - time_output_loss: 0.9829 - val_loss: 1.5986 - val_act_output_loss: 0.5707 - val_time_output_loss: 1.0279\n",
      "Epoch 46/500\n",
      "15s - loss: 1.6033 - act_output_loss: 0.6147 - time_output_loss: 0.9886 - val_loss: 1.5149 - val_act_output_loss: 0.5682 - val_time_output_loss: 0.9466\n",
      "Epoch 47/500\n",
      "15s - loss: 1.5989 - act_output_loss: 0.6120 - time_output_loss: 0.9869 - val_loss: 1.5255 - val_act_output_loss: 0.5700 - val_time_output_loss: 0.9555\n",
      "Epoch 48/500\n",
      "15s - loss: 1.6026 - act_output_loss: 0.6154 - time_output_loss: 0.9872 - val_loss: 1.5242 - val_act_output_loss: 0.5708 - val_time_output_loss: 0.9534\n",
      "Epoch 49/500\n",
      "15s - loss: 1.5972 - act_output_loss: 0.6132 - time_output_loss: 0.9840 - val_loss: 1.5146 - val_act_output_loss: 0.5607 - val_time_output_loss: 0.9539\n",
      "Epoch 50/500\n",
      "15s - loss: 1.6045 - act_output_loss: 0.6192 - time_output_loss: 0.9853 - val_loss: 1.5206 - val_act_output_loss: 0.5648 - val_time_output_loss: 0.9558\n",
      "Epoch 51/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "15s - loss: 1.5933 - act_output_loss: 0.6101 - time_output_loss: 0.9832 - val_loss: 1.5309 - val_act_output_loss: 0.5710 - val_time_output_loss: 0.9599\n",
      "Epoch 52/500\n",
      "15s - loss: 1.6000 - act_output_loss: 0.6149 - time_output_loss: 0.9851 - val_loss: 1.5209 - val_act_output_loss: 0.5676 - val_time_output_loss: 0.9533\n",
      "Epoch 53/500\n",
      "15s - loss: 1.5974 - act_output_loss: 0.6134 - time_output_loss: 0.9840 - val_loss: 1.5178 - val_act_output_loss: 0.5654 - val_time_output_loss: 0.9524\n",
      "Epoch 54/500\n",
      "15s - loss: 1.5997 - act_output_loss: 0.6138 - time_output_loss: 0.9859 - val_loss: 1.5223 - val_act_output_loss: 0.5681 - val_time_output_loss: 0.9542\n",
      "Epoch 55/500\n",
      "15s - loss: 1.5945 - act_output_loss: 0.6108 - time_output_loss: 0.9836 - val_loss: 1.5191 - val_act_output_loss: 0.5665 - val_time_output_loss: 0.9526\n",
      "Epoch 56/500\n",
      "15s - loss: 1.5956 - act_output_loss: 0.6122 - time_output_loss: 0.9834 - val_loss: 1.5190 - val_act_output_loss: 0.5649 - val_time_output_loss: 0.9540\n",
      "Epoch 57/500\n",
      "15s - loss: 1.5944 - act_output_loss: 0.6135 - time_output_loss: 0.9809 - val_loss: 1.5180 - val_act_output_loss: 0.5669 - val_time_output_loss: 0.9511\n",
      "Epoch 58/500\n",
      "15s - loss: 1.5881 - act_output_loss: 0.6037 - time_output_loss: 0.9844 - val_loss: 1.5195 - val_act_output_loss: 0.5673 - val_time_output_loss: 0.9522\n",
      "Epoch 59/500\n",
      "15s - loss: 1.5994 - act_output_loss: 0.6125 - time_output_loss: 0.9869 - val_loss: 1.5228 - val_act_output_loss: 0.5676 - val_time_output_loss: 0.9552\n",
      "Epoch 60/500\n",
      "15s - loss: 1.5860 - act_output_loss: 0.6023 - time_output_loss: 0.9837 - val_loss: 1.5205 - val_act_output_loss: 0.5654 - val_time_output_loss: 0.9551\n",
      "Epoch 61/500\n",
      "15s - loss: 1.5881 - act_output_loss: 0.6017 - time_output_loss: 0.9864 - val_loss: 1.5188 - val_act_output_loss: 0.5649 - val_time_output_loss: 0.9539\n",
      "Epoch 62/500\n",
      "15s - loss: 1.5993 - act_output_loss: 0.6115 - time_output_loss: 0.9878 - val_loss: 1.5240 - val_act_output_loss: 0.5662 - val_time_output_loss: 0.9578\n",
      "Epoch 63/500\n",
      "15s - loss: 1.5851 - act_output_loss: 0.6037 - time_output_loss: 0.9814 - val_loss: 1.5201 - val_act_output_loss: 0.5647 - val_time_output_loss: 0.9554\n",
      "Epoch 64/500\n",
      "15s - loss: 1.5944 - act_output_loss: 0.6103 - time_output_loss: 0.9841 - val_loss: 1.5172 - val_act_output_loss: 0.5650 - val_time_output_loss: 0.9521\n",
      "Epoch 65/500\n",
      "15s - loss: 1.5820 - act_output_loss: 0.5987 - time_output_loss: 0.9832 - val_loss: 1.5215 - val_act_output_loss: 0.5681 - val_time_output_loss: 0.9534\n",
      "Epoch 66/500\n",
      "15s - loss: 1.5858 - act_output_loss: 0.5992 - time_output_loss: 0.9866 - val_loss: 1.5203 - val_act_output_loss: 0.5649 - val_time_output_loss: 0.9555\n",
      "Epoch 67/500\n",
      "15s - loss: 1.5888 - act_output_loss: 0.6047 - time_output_loss: 0.9840 - val_loss: 1.5250 - val_act_output_loss: 0.5668 - val_time_output_loss: 0.9582\n",
      "Epoch 68/500\n",
      "15s - loss: 1.5885 - act_output_loss: 0.6024 - time_output_loss: 0.9861 - val_loss: 1.5212 - val_act_output_loss: 0.5670 - val_time_output_loss: 0.9543\n",
      "Epoch 69/500\n",
      "15s - loss: 1.5839 - act_output_loss: 0.5983 - time_output_loss: 0.9856 - val_loss: 1.5215 - val_act_output_loss: 0.5662 - val_time_output_loss: 0.9553\n",
      "Epoch 70/500\n",
      "15s - loss: 1.5955 - act_output_loss: 0.6098 - time_output_loss: 0.9858 - val_loss: 1.5196 - val_act_output_loss: 0.5651 - val_time_output_loss: 0.9545\n",
      "Epoch 71/500\n",
      "15s - loss: 1.5831 - act_output_loss: 0.5992 - time_output_loss: 0.9838 - val_loss: 1.5226 - val_act_output_loss: 0.5666 - val_time_output_loss: 0.9559\n",
      "Epoch 72/500\n",
      "15s - loss: 1.5849 - act_output_loss: 0.6017 - time_output_loss: 0.9832 - val_loss: 1.5221 - val_act_output_loss: 0.5672 - val_time_output_loss: 0.9548\n",
      "Epoch 73/500\n",
      "15s - loss: 1.5820 - act_output_loss: 0.5987 - time_output_loss: 0.9833 - val_loss: 1.5193 - val_act_output_loss: 0.5663 - val_time_output_loss: 0.9530\n",
      "Epoch 74/500\n",
      "15s - loss: 1.5824 - act_output_loss: 0.5999 - time_output_loss: 0.9825 - val_loss: 1.5185 - val_act_output_loss: 0.5643 - val_time_output_loss: 0.9543\n",
      "Epoch 75/500\n",
      "15s - loss: 1.5872 - act_output_loss: 0.6032 - time_output_loss: 0.9840 - val_loss: 1.5196 - val_act_output_loss: 0.5649 - val_time_output_loss: 0.9547\n",
      "Epoch 76/500\n",
      "15s - loss: 1.5805 - act_output_loss: 0.5988 - time_output_loss: 0.9817 - val_loss: 1.5199 - val_act_output_loss: 0.5658 - val_time_output_loss: 0.9541\n",
      "Epoch 77/500\n",
      "15s - loss: 1.5803 - act_output_loss: 0.5968 - time_output_loss: 0.9835 - val_loss: 1.5191 - val_act_output_loss: 0.5651 - val_time_output_loss: 0.9541\n",
      "Epoch 78/500\n",
      "15s - loss: 1.5756 - act_output_loss: 0.5941 - time_output_loss: 0.9815 - val_loss: 1.5225 - val_act_output_loss: 0.5666 - val_time_output_loss: 0.9558\n",
      "Epoch 79/500\n",
      "15s - loss: 1.5850 - act_output_loss: 0.6023 - time_output_loss: 0.9827 - val_loss: 1.5237 - val_act_output_loss: 0.5676 - val_time_output_loss: 0.9561\n",
      "Epoch 80/500\n",
      "15s - loss: 1.5843 - act_output_loss: 0.5975 - time_output_loss: 0.9869 - val_loss: 1.5228 - val_act_output_loss: 0.5662 - val_time_output_loss: 0.9566\n",
      "Epoch 81/500\n",
      "15s - loss: 1.5754 - act_output_loss: 0.5904 - time_output_loss: 0.9850 - val_loss: 1.5235 - val_act_output_loss: 0.5673 - val_time_output_loss: 0.9562\n",
      "Epoch 82/500\n",
      "15s - loss: 1.5820 - act_output_loss: 0.5980 - time_output_loss: 0.9840 - val_loss: 1.5226 - val_act_output_loss: 0.5672 - val_time_output_loss: 0.9555\n",
      "Epoch 83/500\n",
      "15s - loss: 1.5852 - act_output_loss: 0.6015 - time_output_loss: 0.9836 - val_loss: 1.5230 - val_act_output_loss: 0.5668 - val_time_output_loss: 0.9562\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f5f97247090>"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# build the model: \n",
    "print('Build model...')\n",
    "main_input = Input(shape=(maxlen, num_features), name='main_input')\n",
    "\n",
    "# train a 2-layer LSTM with one shared layer\n",
    "l1 = LSTM(100, consume_less='gpu', init='glorot_uniform', return_sequences=True, dropout_W=0.2)(main_input) # the shared layer\n",
    "b1 = BatchNormalization()(l1)\n",
    "\n",
    "l2_1 = LSTM(100, consume_less='gpu', init='glorot_uniform', return_sequences=False, dropout_W=0.2)(b1) # the layer specialized in activity prediction\n",
    "b2_1 = BatchNormalization()(l2_1)\n",
    "l2_2 = LSTM(100, consume_less='gpu', init='glorot_uniform', return_sequences=False, dropout_W=0.2)(b1) # the layer specialized in time prediction\n",
    "b2_2 = BatchNormalization()(l2_2)\n",
    "\n",
    "act_output = Dense(len(targetchartoindice), activation='softmax', init='glorot_uniform', name='act_output')(b2_1)\n",
    "time_output = Dense(1, init='glorot_uniform', name='time_output')(b2_2)\n",
    "\n",
    "model = Model(input=[main_input], output=[act_output, time_output])\n",
    "\n",
    "opt = Nadam(lr=0.002, beta_1=0.9, beta_2=0.999, epsilon=1e-08, schedule_decay=0.004, clipvalue=3)\n",
    "\n",
    "model.compile(loss={'act_output':'categorical_crossentropy', 'time_output':'mae'}, optimizer=opt)\n",
    "early_stopping = EarlyStopping(monitor='val_loss', patience=42)\n",
    "model_checkpoint = ModelCheckpoint(args.outputdir + 'model_{epoch:02d}-{val_loss:.2f}.h5', \n",
    "                                   monitor='val_loss', verbose=0, save_best_only=True, save_weights_only=False, mode='auto')\n",
    "lr_reducer = ReduceLROnPlateau(monitor='val_loss', factor=0.5, patience=10, verbose=0, mode='auto', epsilon=0.0001, cooldown=0, min_lr=0)\n",
    "\n",
    "model.fit(X, {'act_output':y_a, 'time_output':y_t}, validation_split=0.2, verbose=2, \n",
    "          callbacks=[early_stopping, model_checkpoint, lr_reducer], batch_size=maxlen, nb_epoch=500)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "____________________________________________________________________________________________________\n",
      "Layer (type)                     Output Shape          Param #     Connected to                     \n",
      "====================================================================================================\n",
      "main_input (InputLayer)          (None, 15, 14)        0                                            \n",
      "____________________________________________________________________________________________________\n",
      "lstm_1 (LSTM)                    (None, 15, 100)       46000       main_input[0][0]                 \n",
      "____________________________________________________________________________________________________\n",
      "batchnormalization_1 (BatchNorma (None, 15, 100)       400         lstm_1[0][0]                     \n",
      "____________________________________________________________________________________________________\n",
      "lstm_2 (LSTM)                    (None, 100)           80400       batchnormalization_1[0][0]       \n",
      "____________________________________________________________________________________________________\n",
      "lstm_3 (LSTM)                    (None, 100)           80400       batchnormalization_1[0][0]       \n",
      "____________________________________________________________________________________________________\n",
      "batchnormalization_2 (BatchNorma (None, 100)           400         lstm_2[0][0]                     \n",
      "____________________________________________________________________________________________________\n",
      "batchnormalization_3 (BatchNorma (None, 100)           400         lstm_3[0][0]                     \n",
      "____________________________________________________________________________________________________\n",
      "act_output (Dense)               (None, 10)            1010        batchnormalization_2[0][0]       \n",
      "____________________________________________________________________________________________________\n",
      "time_output (Dense)              (None, 1)             101         batchnormalization_3[0][0]       \n",
      "====================================================================================================\n",
      "Total params: 209,111\n",
      "Trainable params: 208,511\n",
      "Non-trainable params: 600\n",
      "____________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  },
  "toc": {
   "colors": {
    "hover_highlight": "#DAA520",
    "running_highlight": "#FF0000",
    "selected_highlight": "#FFD700"
   },
   "moveMenuLeft": true,
   "nav_menu": {
    "height": "66px",
    "width": "252px"
   },
   "navigate_menu": true,
   "number_sections": true,
   "sideBar": true,
   "threshold": 4,
   "toc_cell": false,
   "toc_section_display": "block",
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
