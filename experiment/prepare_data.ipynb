{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from utils import * "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.preprocessing import StandardScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "data = pd.read_csv('../input/new_data.csv')\n",
    "train = pd.read_csv('../input/train.csv')\n",
    "test = pd.read_csv('../input/test.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "data = transformDf(data)\n",
    "train = transformDf(train)\n",
    "test = transformDf(test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['1.0', '8.0', '6.0', '3.0', '9.0', '2.0', '4.0', '5.0', '7.0'], dtype=object)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data['ActivityID'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 60938.,  60953.,  62152., ...,  77531.,   1811.,   7660.])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data['TimeSinceMidnight'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((13710, 7), (9181, 7), (4529, 7))"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.shape, train.shape, test.shape #13710, 9181, 4529"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Parameters"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Parameters for preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "groupByCase = data.groupby(['CaseID'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# define the denominator for normalization\n",
    "divisor = data['Duration'].mean()\n",
    "divisor2 = data['CumDuration'].mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "15"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#find len of longest case\n",
    "maxlen = findLongestLength(groupByCase)\n",
    "maxlen"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "14"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#define number of features\n",
    "num_features = len(data['ActivityID'].unique()) + 5\n",
    "num_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "unique_chars = data['ActivityID'].unique().tolist()\n",
    "target_chars = unique_chars + ['EOS']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "chartoindice = char_indice_dict(unique_chars)\n",
    "targetchartoindice = char_indice_dict(target_chars)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'1.0': 0,\n",
       " '2.0': 5,\n",
       " '3.0': 3,\n",
       " '4.0': 6,\n",
       " '5.0': 7,\n",
       " '6.0': 2,\n",
       " '7.0': 8,\n",
       " '8.0': 1,\n",
       " '9.0': 4,\n",
       " 'EOS': 9}"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "targetchartoindice"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_groupByCase = train.groupby(['CaseID'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "sentences, sentences_t, sentences_t2, sentences_t3, sentences_t4 = getFeature(train_groupByCase)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(9181, 9181, 9181, 9181, 9181)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(sentences), len(sentences_t), len(sentences_t2), len(sentences_t3), len(sentences_t4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X = vectorizeInput(train_groupByCase, maxlen, num_features, chartoindice, divisor, divisor2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(9181, 15, 14)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "next_chars, next_chars_t, next_chars_t2, next_chars_t3, next_chars_t4 = getOutput(train_groupByCase)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(9181, 9181, 9181, 9181, 9181)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(next_chars), len(next_chars_t), len(next_chars_t2), len(next_chars_t3), len(next_chars_t4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### y_a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['8.0', '6.0', 'EOS', '8.0', '6.0', 'EOS', '8.0', '6.0', 'EOS', '8.0']"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "next_chars[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "y_a = one_hot_encode(train_groupByCase, targetchartoindice)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(9181, 10)"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_a.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.,  1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.],\n",
       "       [ 0.,  0.,  1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.],\n",
       "       [ 0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  1.],\n",
       "       [ 0.,  1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.],\n",
       "       [ 0.,  0.,  1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.],\n",
       "       [ 0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  1.],\n",
       "       [ 0.,  1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.],\n",
       "       [ 0.,  0.,  1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.],\n",
       "       [ 0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  1.],\n",
       "       [ 0.,  1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.]], dtype=float32)"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_a[:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### y_t "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "next_chars_t = np.asarray(next_chars_t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_t = normalize(train_groupByCase, divisor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([  7.11185218e-05,   8.24970111e-01,   0.00000000e+00, ...,\n",
       "         7.11185218e-05,   4.12487426e-04,   0.00000000e+00])"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_t"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(9181,)"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_t.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "test_groupByCase = test.groupby(['CaseID'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df_test = pd.DataFrame(columns=['CaseID', 'ActivityID', 'CompleteTimestamp', 'Duration', 'CumDuration', 'TimeSinceMidnight', 'WeekDay'])\n",
    "for case, group in test_groupByCase:\n",
    "    if group.shape[0] > 1:     \n",
    "        df_test = df_test.append(group)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(4529, 7)"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_test.shape #No case with one activity"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "sentences, sentences_t, sentences_t2, sentences_t3, sentences_t4 = getFeature(test_groupByCase)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(4529, 4529, 4529, 4529, 4529)"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(sentences), len(sentences_t), len(sentences_t2), len(sentences_t3), len(sentences_t4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X_test = vectorizeInput(test_groupByCase, maxlen, num_features, chartoindice, divisor, divisor2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(9181, 15, 14)"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "next_chars, next_chars_t, next_chars_t2, next_chars_t3, next_chars_t4 = getOutput(test_groupByCase)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(4529, 4529, 4529, 4529, 4529)"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(next_chars), len(next_chars_t), len(next_chars_t2), len(next_chars_t3), len(next_chars_t4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### y_a"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "One-hot encode for y_a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['8.0', '6.0', 'EOS', '1.0', '8.0', '9.0', '8.0', '6.0', 'EOS', '8.0']"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "next_chars[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "y_a_test = one_hot_encode(test_groupByCase, targetchartoindice)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(4529, 10)"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_a_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.,  1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.],\n",
       "       [ 0.,  0.,  1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.],\n",
       "       [ 0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  1.],\n",
       "       [ 0.,  1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.],\n",
       "       [ 0.,  0.,  1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.],\n",
       "       [ 0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  1.],\n",
       "       [ 0.,  1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.],\n",
       "       [ 0.,  0.,  1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.],\n",
       "       [ 0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  1.],\n",
       "       [ 0.,  1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.]], dtype=float32)"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_a[:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### y_t"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Scale/Normalize data. This can be done by using [sklearn](http://scikit-learn.org/stable/modules/preprocessing.html#preprocessing-scaler)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_t_test = normalize(test_groupByCase, divisor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 1.3322443 ,  1.21594656,  0.        , ...,  2.96890433,\n",
       "        0.02773148,  0.        ])"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_t_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(4529,)"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_t_test.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Save data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "with open('../input/parameters.pkl', 'wb') as f:\n",
    "    pickle.dump(maxlen, f, protocol=2)\n",
    "    pickle.dump(num_features, f, protocol=2)\n",
    "    pickle.dump(chartoindice, f, protocol=2)\n",
    "    pickle.dump(targetchartoindice, f, protocol=2)\n",
    "    pickle.dump(divisor, f, protocol=2)\n",
    "    pickle.dump(divisor2, f, protocol=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "with open('../input/preprocessed_data.pkl', 'wb') as f:\n",
    "    pickle.dump(X, f, protocol=2)\n",
    "    pickle.dump(y_a, f, protocol=2)\n",
    "    pickle.dump(y_t, f, protocol=2)\n",
    "    pickle.dump(X_test, f, protocol=2)\n",
    "    pickle.dump(y_a_test, f, protocol=2)\n",
    "    pickle.dump(y_t_test, f, protocol=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Test model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using Theano backend.\n"
     ]
    }
   ],
   "source": [
    "from keras.models import Sequential, Model\n",
    "from keras.layers.core import Dense\n",
    "from keras.layers.recurrent import LSTM, GRU, SimpleRNN\n",
    "from keras.layers import Input\n",
    "from keras.utils.data_utils import get_file\n",
    "from keras.regularizers import WeightRegularizer\n",
    "from keras.optimizers import Nadam\n",
    "from keras.callbacks import EarlyStopping, ModelCheckpoint, ReduceLROnPlateau\n",
    "from keras.layers.normalization import BatchNormalization\n",
    "from theano.ifelse import ifelse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Build model...\n",
      "Train on 7344 samples, validate on 1837 samples\n",
      "Epoch 1/500\n",
      "19s - loss: 2.1553 - act_output_loss: 0.9735 - time_output_loss: 1.1818 - val_loss: 1.7406 - val_act_output_loss: 0.6893 - val_time_output_loss: 1.0513\n",
      "Epoch 2/500\n",
      "18s - loss: 1.7593 - act_output_loss: 0.7159 - time_output_loss: 1.0434 - val_loss: 1.5959 - val_act_output_loss: 0.5990 - val_time_output_loss: 0.9969\n",
      "Epoch 3/500\n",
      "18s - loss: 1.7187 - act_output_loss: 0.6954 - time_output_loss: 1.0232 - val_loss: 1.5521 - val_act_output_loss: 0.5806 - val_time_output_loss: 0.9716\n",
      "Epoch 4/500\n",
      "18s - loss: 1.6923 - act_output_loss: 0.6757 - time_output_loss: 1.0166 - val_loss: 1.6068 - val_act_output_loss: 0.5818 - val_time_output_loss: 1.0249\n",
      "Epoch 5/500\n",
      "18s - loss: 1.6821 - act_output_loss: 0.6723 - time_output_loss: 1.0098 - val_loss: 1.5755 - val_act_output_loss: 0.5953 - val_time_output_loss: 0.9803\n",
      "Epoch 6/500\n",
      "18s - loss: 1.6637 - act_output_loss: 0.6590 - time_output_loss: 1.0047 - val_loss: 1.5628 - val_act_output_loss: 0.5835 - val_time_output_loss: 0.9793\n",
      "Epoch 7/500\n",
      "18s - loss: 1.6556 - act_output_loss: 0.6540 - time_output_loss: 1.0016 - val_loss: 1.5810 - val_act_output_loss: 0.5748 - val_time_output_loss: 1.0062\n",
      "Epoch 8/500\n",
      "18s - loss: 1.6561 - act_output_loss: 0.6543 - time_output_loss: 1.0018 - val_loss: 1.5694 - val_act_output_loss: 0.5774 - val_time_output_loss: 0.9920\n",
      "Epoch 9/500\n",
      "18s - loss: 1.6677 - act_output_loss: 0.6671 - time_output_loss: 1.0006 - val_loss: 1.5557 - val_act_output_loss: 0.5797 - val_time_output_loss: 0.9759\n",
      "Epoch 10/500\n",
      "18s - loss: 1.6639 - act_output_loss: 0.6630 - time_output_loss: 1.0009 - val_loss: 1.5213 - val_act_output_loss: 0.5610 - val_time_output_loss: 0.9603\n",
      "Epoch 11/500\n",
      "18s - loss: 1.6475 - act_output_loss: 0.6544 - time_output_loss: 0.9930 - val_loss: 1.5430 - val_act_output_loss: 0.5597 - val_time_output_loss: 0.9833\n",
      "Epoch 12/500\n",
      "18s - loss: 1.6379 - act_output_loss: 0.6434 - time_output_loss: 0.9944 - val_loss: 1.5327 - val_act_output_loss: 0.5656 - val_time_output_loss: 0.9671\n",
      "Epoch 13/500\n",
      "18s - loss: 1.6327 - act_output_loss: 0.6430 - time_output_loss: 0.9897 - val_loss: 1.5262 - val_act_output_loss: 0.5681 - val_time_output_loss: 0.9581\n",
      "Epoch 14/500\n",
      "18s - loss: 1.6251 - act_output_loss: 0.6309 - time_output_loss: 0.9942 - val_loss: 1.5112 - val_act_output_loss: 0.5667 - val_time_output_loss: 0.9445\n",
      "Epoch 15/500\n",
      "18s - loss: 1.6454 - act_output_loss: 0.6520 - time_output_loss: 0.9934 - val_loss: 1.5068 - val_act_output_loss: 0.5536 - val_time_output_loss: 0.9532\n",
      "Epoch 16/500\n",
      "19s - loss: 1.6445 - act_output_loss: 0.6480 - time_output_loss: 0.9965 - val_loss: 1.5308 - val_act_output_loss: 0.5668 - val_time_output_loss: 0.9640\n",
      "Epoch 17/500\n",
      "19s - loss: 1.6320 - act_output_loss: 0.6391 - time_output_loss: 0.9929 - val_loss: 1.5586 - val_act_output_loss: 0.5797 - val_time_output_loss: 0.9789\n",
      "Epoch 18/500\n",
      "18s - loss: 1.6435 - act_output_loss: 0.6512 - time_output_loss: 0.9923 - val_loss: 1.5283 - val_act_output_loss: 0.5668 - val_time_output_loss: 0.9615\n",
      "Epoch 19/500\n",
      "18s - loss: 1.6400 - act_output_loss: 0.6463 - time_output_loss: 0.9937 - val_loss: 1.5423 - val_act_output_loss: 0.5778 - val_time_output_loss: 0.9645\n",
      "Epoch 20/500\n",
      "18s - loss: 1.6272 - act_output_loss: 0.6320 - time_output_loss: 0.9952 - val_loss: 1.5341 - val_act_output_loss: 0.5769 - val_time_output_loss: 0.9572\n",
      "Epoch 21/500\n",
      "18s - loss: 1.6333 - act_output_loss: 0.6361 - time_output_loss: 0.9972 - val_loss: 1.5333 - val_act_output_loss: 0.5655 - val_time_output_loss: 0.9677\n",
      "Epoch 22/500\n",
      "19s - loss: 1.6321 - act_output_loss: 0.6380 - time_output_loss: 0.9941 - val_loss: 1.5391 - val_act_output_loss: 0.5765 - val_time_output_loss: 0.9626\n",
      "Epoch 23/500\n",
      "18s - loss: 1.6330 - act_output_loss: 0.6409 - time_output_loss: 0.9922 - val_loss: 1.5218 - val_act_output_loss: 0.5634 - val_time_output_loss: 0.9584\n",
      "Epoch 24/500\n",
      "18s - loss: 1.6276 - act_output_loss: 0.6317 - time_output_loss: 0.9959 - val_loss: 1.5441 - val_act_output_loss: 0.5806 - val_time_output_loss: 0.9635\n",
      "Epoch 25/500\n",
      "18s - loss: 1.6320 - act_output_loss: 0.6394 - time_output_loss: 0.9927 - val_loss: 1.5591 - val_act_output_loss: 0.5996 - val_time_output_loss: 0.9595\n",
      "Epoch 26/500\n",
      "18s - loss: 1.6260 - act_output_loss: 0.6345 - time_output_loss: 0.9914 - val_loss: 1.5393 - val_act_output_loss: 0.5661 - val_time_output_loss: 0.9732\n",
      "Epoch 27/500\n",
      "18s - loss: 1.6169 - act_output_loss: 0.6251 - time_output_loss: 0.9917 - val_loss: 1.5079 - val_act_output_loss: 0.5576 - val_time_output_loss: 0.9502\n",
      "Epoch 28/500\n",
      "18s - loss: 1.6083 - act_output_loss: 0.6201 - time_output_loss: 0.9882 - val_loss: 1.5200 - val_act_output_loss: 0.5600 - val_time_output_loss: 0.9600\n",
      "Epoch 29/500\n",
      "18s - loss: 1.6113 - act_output_loss: 0.6228 - time_output_loss: 0.9885 - val_loss: 1.5168 - val_act_output_loss: 0.5617 - val_time_output_loss: 0.9552\n",
      "Epoch 30/500\n",
      "18s - loss: 1.6121 - act_output_loss: 0.6260 - time_output_loss: 0.9861 - val_loss: 1.5203 - val_act_output_loss: 0.5669 - val_time_output_loss: 0.9533\n",
      "Epoch 31/500\n",
      "18s - loss: 1.6158 - act_output_loss: 0.6282 - time_output_loss: 0.9876 - val_loss: 1.5201 - val_act_output_loss: 0.5695 - val_time_output_loss: 0.9506\n",
      "Epoch 32/500\n",
      "21s - loss: 1.5992 - act_output_loss: 0.6096 - time_output_loss: 0.9896 - val_loss: 1.5194 - val_act_output_loss: 0.5612 - val_time_output_loss: 0.9582\n",
      "Epoch 33/500\n",
      "18s - loss: 1.6083 - act_output_loss: 0.6230 - time_output_loss: 0.9853 - val_loss: 1.5183 - val_act_output_loss: 0.5657 - val_time_output_loss: 0.9526\n",
      "Epoch 34/500\n",
      "19s - loss: 1.6074 - act_output_loss: 0.6174 - time_output_loss: 0.9900 - val_loss: 1.5268 - val_act_output_loss: 0.5692 - val_time_output_loss: 0.9576\n",
      "Epoch 35/500\n",
      "18s - loss: 1.6054 - act_output_loss: 0.6183 - time_output_loss: 0.9871 - val_loss: 1.5228 - val_act_output_loss: 0.5689 - val_time_output_loss: 0.9539\n",
      "Epoch 36/500\n",
      "18s - loss: 1.6083 - act_output_loss: 0.6191 - time_output_loss: 0.9893 - val_loss: 1.5150 - val_act_output_loss: 0.5609 - val_time_output_loss: 0.9541\n",
      "Epoch 37/500\n",
      "18s - loss: 1.6090 - act_output_loss: 0.6228 - time_output_loss: 0.9862 - val_loss: 1.5133 - val_act_output_loss: 0.5610 - val_time_output_loss: 0.9523\n",
      "Epoch 38/500\n",
      "17s - loss: 1.5977 - act_output_loss: 0.6136 - time_output_loss: 0.9841 - val_loss: 1.5101 - val_act_output_loss: 0.5616 - val_time_output_loss: 0.9485\n",
      "Epoch 39/500\n",
      "18s - loss: 1.5894 - act_output_loss: 0.6032 - time_output_loss: 0.9862 - val_loss: 1.5110 - val_act_output_loss: 0.5612 - val_time_output_loss: 0.9498\n",
      "Epoch 40/500\n",
      "18s - loss: 1.6046 - act_output_loss: 0.6161 - time_output_loss: 0.9885 - val_loss: 1.5177 - val_act_output_loss: 0.5662 - val_time_output_loss: 0.9515\n",
      "Epoch 41/500\n",
      "18s - loss: 1.6052 - act_output_loss: 0.6186 - time_output_loss: 0.9866 - val_loss: 1.5158 - val_act_output_loss: 0.5657 - val_time_output_loss: 0.9500\n",
      "Epoch 42/500\n",
      "18s - loss: 1.5967 - act_output_loss: 0.6107 - time_output_loss: 0.9860 - val_loss: 1.5183 - val_act_output_loss: 0.5647 - val_time_output_loss: 0.9536\n",
      "Epoch 43/500\n",
      "18s - loss: 1.5942 - act_output_loss: 0.6115 - time_output_loss: 0.9827 - val_loss: 1.5163 - val_act_output_loss: 0.5648 - val_time_output_loss: 0.9514\n",
      "Epoch 44/500\n",
      "17s - loss: 1.5883 - act_output_loss: 0.6056 - time_output_loss: 0.9827 - val_loss: 1.5117 - val_act_output_loss: 0.5626 - val_time_output_loss: 0.9491\n",
      "Epoch 45/500\n",
      "17s - loss: 1.5875 - act_output_loss: 0.6042 - time_output_loss: 0.9833 - val_loss: 1.5171 - val_act_output_loss: 0.5642 - val_time_output_loss: 0.9529\n",
      "Epoch 46/500\n",
      "18s - loss: 1.5898 - act_output_loss: 0.6086 - time_output_loss: 0.9812 - val_loss: 1.5145 - val_act_output_loss: 0.5656 - val_time_output_loss: 0.9490\n",
      "Epoch 47/500\n",
      "18s - loss: 1.5992 - act_output_loss: 0.6112 - time_output_loss: 0.9881 - val_loss: 1.5188 - val_act_output_loss: 0.5655 - val_time_output_loss: 0.9533\n",
      "Epoch 48/500\n",
      "18s - loss: 1.5919 - act_output_loss: 0.6070 - time_output_loss: 0.9848 - val_loss: 1.5182 - val_act_output_loss: 0.5644 - val_time_output_loss: 0.9539\n",
      "Epoch 49/500\n",
      "18s - loss: 1.5977 - act_output_loss: 0.6141 - time_output_loss: 0.9836 - val_loss: 1.5234 - val_act_output_loss: 0.5679 - val_time_output_loss: 0.9554\n",
      "Epoch 50/500\n",
      "19s - loss: 1.5831 - act_output_loss: 0.6032 - time_output_loss: 0.9799 - val_loss: 1.5157 - val_act_output_loss: 0.5670 - val_time_output_loss: 0.9488\n",
      "Epoch 51/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "18s - loss: 1.5820 - act_output_loss: 0.6014 - time_output_loss: 0.9806 - val_loss: 1.5134 - val_act_output_loss: 0.5632 - val_time_output_loss: 0.9502\n",
      "Epoch 52/500\n",
      "17s - loss: 1.5802 - act_output_loss: 0.6026 - time_output_loss: 0.9776 - val_loss: 1.5156 - val_act_output_loss: 0.5633 - val_time_output_loss: 0.9523\n",
      "Epoch 53/500\n",
      "18s - loss: 1.5793 - act_output_loss: 0.5980 - time_output_loss: 0.9812 - val_loss: 1.5165 - val_act_output_loss: 0.5648 - val_time_output_loss: 0.9517\n",
      "Epoch 54/500\n",
      "18s - loss: 1.5767 - act_output_loss: 0.5941 - time_output_loss: 0.9826 - val_loss: 1.5166 - val_act_output_loss: 0.5632 - val_time_output_loss: 0.9534\n",
      "Epoch 55/500\n",
      "18s - loss: 1.5807 - act_output_loss: 0.6007 - time_output_loss: 0.9801 - val_loss: 1.5141 - val_act_output_loss: 0.5638 - val_time_output_loss: 0.9503\n",
      "Epoch 56/500\n",
      "18s - loss: 1.5949 - act_output_loss: 0.6067 - time_output_loss: 0.9882 - val_loss: 1.5211 - val_act_output_loss: 0.5656 - val_time_output_loss: 0.9555\n",
      "Epoch 57/500\n",
      "18s - loss: 1.5759 - act_output_loss: 0.5968 - time_output_loss: 0.9791 - val_loss: 1.5155 - val_act_output_loss: 0.5634 - val_time_output_loss: 0.9521\n",
      "Epoch 58/500\n",
      "18s - loss: 1.5766 - act_output_loss: 0.6002 - time_output_loss: 0.9764 - val_loss: 1.5157 - val_act_output_loss: 0.5634 - val_time_output_loss: 0.9523\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7fa069930990>"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# build the model: \n",
    "print('Build model...')\n",
    "main_input = Input(shape=(maxlen, num_features), name='main_input')\n",
    "# train a 2-layer LSTM with one shared layer\n",
    "l1 = LSTM(100, consume_less='gpu', init='glorot_uniform', return_sequences=True, dropout_W=0.2)(main_input) # the shared layer\n",
    "b1 = BatchNormalization()(l1)\n",
    "l2_1 = LSTM(100, consume_less='gpu', init='glorot_uniform', return_sequences=False, dropout_W=0.2)(b1) # the layer specialized in activity prediction\n",
    "b2_1 = BatchNormalization()(l2_1)\n",
    "l2_2 = LSTM(100, consume_less='gpu', init='glorot_uniform', return_sequences=False, dropout_W=0.2)(b1) # the layer specialized in time prediction\n",
    "b2_2 = BatchNormalization()(l2_2)\n",
    "act_output = Dense(len(target_chars), activation='softmax', init='glorot_uniform', name='act_output')(b2_1)\n",
    "time_output = Dense(1, init='glorot_uniform', name='time_output')(b2_2)\n",
    "\n",
    "model = Model(input=[main_input], output=[act_output, time_output])\n",
    "\n",
    "opt = Nadam(lr=0.002, beta_1=0.9, beta_2=0.999, epsilon=1e-08, schedule_decay=0.004, clipvalue=3)\n",
    "\n",
    "model.compile(loss={'act_output':'categorical_crossentropy', 'time_output':'mae'}, optimizer=opt)\n",
    "early_stopping = EarlyStopping(monitor='val_loss', patience=42)\n",
    "model_checkpoint = ModelCheckpoint('output_files/models/model_{epoch:02d}-{val_loss:.2f}.h5', monitor='val_loss', verbose=0, save_best_only=True, save_weights_only=False, mode='auto')\n",
    "lr_reducer = ReduceLROnPlateau(monitor='val_loss', factor=0.5, patience=10, verbose=0, mode='auto', epsilon=0.0001, cooldown=0, min_lr=0)\n",
    "\n",
    "model.fit(X, {'act_output':y_a, 'time_output':y_t}, validation_split=0.2, verbose=2, callbacks=[early_stopping, model_checkpoint, lr_reducer], batch_size=maxlen, nb_epoch=500)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "____________________________________________________________________________________________________\n",
      "Layer (type)                     Output Shape          Param #     Connected to                     \n",
      "====================================================================================================\n",
      "main_input (InputLayer)          (None, 15, 14)        0                                            \n",
      "____________________________________________________________________________________________________\n",
      "lstm_1 (LSTM)                    (None, 15, 100)       46000       main_input[0][0]                 \n",
      "____________________________________________________________________________________________________\n",
      "batchnormalization_1 (BatchNorma (None, 15, 100)       400         lstm_1[0][0]                     \n",
      "____________________________________________________________________________________________________\n",
      "lstm_2 (LSTM)                    (None, 100)           80400       batchnormalization_1[0][0]       \n",
      "____________________________________________________________________________________________________\n",
      "lstm_3 (LSTM)                    (None, 100)           80400       batchnormalization_1[0][0]       \n",
      "____________________________________________________________________________________________________\n",
      "batchnormalization_2 (BatchNorma (None, 100)           400         lstm_2[0][0]                     \n",
      "____________________________________________________________________________________________________\n",
      "batchnormalization_3 (BatchNorma (None, 100)           400         lstm_3[0][0]                     \n",
      "____________________________________________________________________________________________________\n",
      "act_output (Dense)               (None, 10)            1010        batchnormalization_2[0][0]       \n",
      "____________________________________________________________________________________________________\n",
      "time_output (Dense)              (None, 1)             101         batchnormalization_3[0][0]       \n",
      "====================================================================================================\n",
      "Total params: 209,111\n",
      "Trainable params: 208,511\n",
      "Non-trainable params: 600\n",
      "____________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  },
  "toc": {
   "colors": {
    "hover_highlight": "#DAA520",
    "running_highlight": "#FF0000",
    "selected_highlight": "#FFD700"
   },
   "moveMenuLeft": true,
   "nav_menu": {
    "height": "66px",
    "width": "252px"
   },
   "navigate_menu": true,
   "number_sections": true,
   "sideBar": true,
   "threshold": 4,
   "toc_cell": false,
   "toc_section_display": "block",
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
